{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["(huggingface.co)","6b","6b.md","6b:","7b","alpaca","chatglm","chatglm)","chines","entail","gpt与知识图谱","hi/huatuo","https://github.com/imclumsypanda/langchain","instruct自动生成微调数据","introduct","lamini","langchain:","llama","llm三种微调技术对比","llm三种训练技术对比","llm引擎学习","lora","main","med","merg","metgen论文学习笔记","minlik/chines","optimalscale/lmflow","pengxiao","plu","scir","self","song/lawgpt","thudm/chatglm","trees论文学习笔记","windows+6gb显+cpu本地部署chatglm","yanqiangmiffy/chines","中文langchain项目","天工gpt调研","学习相关项目代码","学术问答数据集调研","思维链简介","本地知识库问答","根据自己数据库让gpt作答","模型底座","模型微调","毕设技术框架","相关gpt调研","相关技术调研","第一章：训练微调相关技术","第三章：数据底座方法与调研","第二章：如何定制化gpt","第四章：其他相关知识","节省显存的微调推理技术对比","训练部署自己的chatglm","训练部署自己的羊驼","调研报告"],"天工GPT调研/天工GPT调研.html":["(tiangong.world)【开源chatpdf套壳】","ask","chatgpt","chat【领域微调是重点】","convers","gpt","https://www.chatpdf.com","interact","pdf","power","tiangong","一、天工chat：tiangong","主要特点：从提问中抽取出关键信息，然后进行知识库匹配。","主要的实现原理：将文章进行分割，然后与query进行查询匹配，将相关段落返回，输入到gpt中得到最后的答案。","二、天工gpt：天宫","天工chat上新了","天工gpt调研","实测体验：速度较慢，生成效果如下，可以看到主要包括文本信息+相关扩展链接。","概述：一个典型的chatpdf类似应用，类似相关项目很多如：","概述：主体是一个基于环境工程、生态学相关领域","相关链接：","语料微调训练得到的一个gpt模型，提供chat页面。"],"相关GPT调研/相关GPT调研.html":["\"偏头痛\",","\"内科\"],","\"发病部位\":","\"头部及眼后部疼痛并能听到连续不断的隆隆声\",","\"恶寒发热\"],","\"所属科室\":","\"晨起头痛加重\"],","\"相关疾病\":","\"相关症状\":","\"问题：一位年轻男性长期使用可卡因，突然出现胸痛、呕吐、出汗等症状，经检查发现心电图反映心肌急性损伤，请问可能患的是什么疾病？治疗方式是什么？\"","',","'多少钱呢',","'大概金额多少？',","'律师费诉讼费都非常少都很合理，一定要起诉。',","'您好，建议尽量协商处理，协商不成可起诉']","'需要看标的额和案情复杂程度，建议细致面谈']","(https://github.com/k","*******************************************************","./scripts/finetune.sh","/","12h","2.对特定法律知识的问答。","24h","32gb","7b模型，由哈尔滨工业大学社会计算与信息检索研究中心健康智能组完成。项目组通过","8","80gb显卡上进行了训练，训练总轮次10轮，耗时大约2h17m。batch_size=128的情况下显存占用了40g左右。也可以使用3090/4090显卡，显存在24gb以上时，可以获得较好的效果。","[\"中西医结合科\",","[\"头部\"]}","[\"妊娠合并偏头痛\",","[\"皮肤变硬\",","['您好，建议协商处理，如果对方告了你们，就只能积极应诉了。',","['欠款金额是多少","answers:","api","bash","chines","epoch","epoch，微调阶段耗时约","github链接：https://github.com/pengxiao","github链接：https://github.com/scir","gpt3.5","gpt3.5接口围绕医学知识库构建问答数据，设置了多种prompt形式来充分利用知识。医学知识库围绕疾病、药物、检查指标等构建，字段包括并发症，高危因素，组织学检查，临床症状，药物治疗，辅助治疗等。知识库示例如下：","hi/huatuo","instruction：通过提供具体的法律知识文本，先让chatgpt生成与该段法律知识内容与逻辑关系相关的若干问题，再通过“文本段","instruct的可靠性和安全性漏洞，使用了基于特定知识的reli","lawgpt","llama","llama、chatglm","med","question:昨天把人家车刮了,要赔多少","question:朋友欠钱不还咋办","self","song/lawgpt/","sxm","sxm2","tesla","tuning)","v100","yyf/cmekg_tools)，并利用","{\"中心词\":","​","一、本草医学gpt模型：基于中文医学知识的llama微调模型","中文法律知识模型","二、lawgpt","使用展示","医学知识图谱","可能患的是心肌梗塞，需要进行维拉帕米、依普利酮、硝酸甘油、ß阻滞剂、吗啡等药物治疗，并进行溶栓治疗、低分子量肝素、钙通道阻滞剂等辅助治疗。此外需要及时停用可卡因等药物，以防止病情加重。\"","和","回答:","垂直领域gpt微调模型介绍","张","指令微调数据集：qa数据集","支持使用自己的数据集进行微调，只需要按照./data/llama_data.json的格式构建自己的数据集，然后执行命令：","数据集","是一系列基于中文法律知识的开源大语言模型，该系列模型在通用中文基座模型（如","是经过中文医学指令精调/指令微调(instruct","本草","构建了中文医学指令数据集，并在此基础上对llama进行了指令微调，提高了llama在医疗领域的问答效果。","概述","概述：","模型训练【后续可参考】","模型训练与微调【后续进行微调可借鉴】","此外，项目组还收集了2023年关于肝癌疾病的中文医学文献，利用gpt3.5接口围绕医学文献多轮问答数据（1k条左右）。","的llama","相关gpt调研","知识问答数据集包括针对self","第一阶段：扩充法律领域词表，在大规模法律文书及法典数据上预训练","第二阶段：构造法律领域对话问答数据集，在预训练模型基础上指令精调。","等）的基础上扩充法律领域专有词表、大规模中文法律语料预训练，增强了大模型在法律领域的基础语义理解能力。在此基础上，构造法律领域对话问答数据集、中国司法考试数据集进行指令精调，提升了模型对法律内容的理解和执行能力。","系列模型的训练过程分为两个阶段：","计算资源","训练数据主要分为两个部分：1.律师和用户之间的情景对话；","问题”对的方式让chatgpt回答问题，从而使chatgpt能够生成含有法律信息的回答，保证回答的准确性。【后续可参考该方法构建问答数据集】","项目组在一张a100","项目组采用了公开和自建的中文医学知识库方式，主要参考了cmekg","（1）lawgpt","：二次训练阶段耗时约"],"Chapter2/微调范式对比.html":["(huggingface.co)","*","+",".","1","1.","1.3gb","12","128～127","1343","16","2","2.","2048）计算中间变量内存。","24gb内存","25.3gb","3.","32","32,","4","4.","4096,","48","5.","50","6.5b","6b","6b*1","6b*2","6b*4","6b*8","6b，adamw","6gb","6gb+6gb+12gb+1.3gb","8","=","=11008,",">","[(hidden_size+intermediate_size)context_length\\num_hidden_layers]/1024","a100（80gb","acceler","adamw","adapt","api/","back","batch_size，设置模型精度，选择微调方法和参数分布方法等。","batch数","bit","bits,","bitsandbyt","bitsandbytes量化方法","byte","byte.","bytes.","checkpoint","checkpointing.html","context_length","cpu","cpu,","cpu，从而允许更多内容适应","cuda","cuda内核1.3","custom","data","ddp","decompasition：混合精度反编译","deepspe","effici","explor","fairscal","fp16","fp16=true","fp32","fp32。","fp32，llama","fsdp","fsdp+cpu","fsdpwarp","fsdp，只需要将","fsdp：","fulli","function","g","gb","gentl","gpu","gpu。","gradient","https://arxiv.org/pdf/2106.09685.pdf","https://github.com/huggingface/peft/blob/main/examples/conditional_generation/peft_lora_seq2seq.ipynb","https://github.com/huggingface/peft/blob/main/examples/int8_training/finetune_opt_bnb_peft.ipynb","https://huggingface.co/blog/zero","https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer#transformers.trainin","https://huggingface.co/docs/transformers/v4.27.2/en/perf_train_gpu_one#gradi","https://pytorch.org/blog/introduc","https://pytorch.org/docs/stable/fsdp.html","https://qywu.github.io/2019/05/22/explor","huggingfac","infer","int8","int8，llama","intermediate_s","introduct","kernel","llama","llm","lora","matrix","mb","memori","mix","model","model.half()","mt0：","multipl","num_hidden_lay","occupied:","offload","offload【分布式】","opt","parallel","paralle（fsdp）和","peft","peft，使用","precis","print_gpu","propag","pytorch","quantization：矢量量化","ram","ram）大概可以在","ram，大概","ram，进而通过估算设置","rank","scale","scalehttps://arxiv.org/abs/2208.07339*","shard","torch","torch.ones((1，1)).to(\"cuda\")","torch实现：torch","trainingargu","transform","transformers,","transformers：在","us","utilization()","wise","zero","zero零冗余优化器","●","。","一、memori","一下；同样，cpu_offload","一样，在每个","七、torch","三、fp16","上保留完整副本。","上平均划分参数、梯度和优化器状态，并为每个","上，而非像","中使用","中使用这个数据类型，bitsandbyt","中使用：","中，将参数动态地从","为了在训练和","之间的数据存储零重叠。在运行时，每个","也会占据一些","也只需要一行代码：","二、估算模型所需的ram：参数个数","五、lora：low","仅对优化器状态和梯度执行分区（分片）。模型参数分片应该很快就会在deepspeed和fairscale中推出。","优化器参数：不同的优化器所储存的参数量不同。对于常用的","使用","使用了两个方法最大程度地降低了其带来的误差：","例子：借助","借助","六、gradient","其次，考虑模型需要的","内存。","再根据llama的架构（hidden_s","则允许在一个","包装一下即可，详见：","卸载（cpu）。此功能将一些处理和内存需求卸载到主机的","原理：fulli","参考论文：llm.int8():","参考链接：有哪些省内存的大语言模型训练/微调/推理方法？","发送它所缺少的信息来动态构建每一层的数据。","和","四、int8","在","在这个可以查看","大致分三个部分：","大致思路：在前向反馈","实现","对于","将模型转换为fp16。","左右","左右。","微调","微调范式对比","所以lora","所以一张","把","推理直接使用","提供一个分区（也称为分片）。这导致","支持的模型：","是个很极端的数据类型，它最多只能表示","是微调","最常用的省内存方法之一【低秩转换】","来加速，但是在更新参数时使用","来说，需要储存两倍的模型参数","根据参数量估计模型大致所需的","框架，使用","梯度计算","梯度：等于参数量*每个梯度参数所需内存。","模型为例估算其大致需要的内存：","模型参数：模型参数：等于参数量*每个参数所需内存。","模型部分大致需要","用","用一个","的","的作者根据这一特点将更新矩阵变成两个低秩矩阵的积积b","的大致实现方法：","的完整流程：","的巧妙方法是在所有","的数字，并且完全没有精度。","的时候使用","的训练/微调/推理方法，包括：","的设定下进行全参数训练【25.3+990/1024*50】。","等分布优化算法，减少内存的占用量。其将模型参数，梯度和优化器状态分布至多个","简述原理：微调llm时，更新矩阵往往是低秩矩阵。（低秩矩阵是指矩阵中包含的信息可以用较低维度的子空间进行近似表示的矩阵，由于低秩矩阵在储存和计算方面都有优势，所以它们被广泛应用于压缩、降噪、特征提取、模型压缩等任务）（矩阵的秩是指矩阵中线性无关的行或列的最大数目）","类似，均通过","精度","精度的","精度，一个参数需要","精度；batch_siz","综合1、2、3步骤，int8","节省显存的微调推理技术对比","训练","这篇博文解释了","进行转移，从而节省","通过要求参与的","里声明","需要","首先考虑精度对所需内存的影响：","（1）vector","（1）用","（2）mix","（用来储存一阶和二阶momentum）。"],"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":["bert出现之后，fin","continu","down","effici","fine","gener","generation”（2021）中提出。前缀调整涉及学习特定任务的连续提示，在推理过程中将其添加到输入之前。通过优化这个连续提示，模型可以适应特定任务而不修改底层模型参数，这节省了计算资源并实现了高效的精调。","gpt","gpt（生成式预训练变压器）模型。gpt模型在大量文本上进行了预训练，然后在各种任务上进行了微调，例如语言建模，问答和摘要。经过微调的模型在这些任务上取得了最先进的性能。","guid","language”（2021）中提出。p","learns,","llm三种微调技术对比","optim","p","paramet","peft综述：scal","prefix","prompt","prompt）而非修改模型参数。这意味着预训练模型保持不变，只有输入提示被修改以适应下游的任务。通过设计和优化一组提示，可以使预训练模型执行特定任务。","scale","shrinking)，它由kaplan等人于2020年引入。这种技术涉及在fin","training)，它由houlsby等人于2019年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。","tune","tune、paramet","tune和prompt","tuning:","tuning。","tuning。如果两者不相似，则可能需要更多的fin","tuning修改模型的权重，而prompt","tuning只修改模型的输入。因此，prompt","tuning和prompt","tuning和传统的fin","tuning技术","tuning技术[peft]","tuning技术也随之流行，即将预训练模型的权重冻结，然后根据具体任务进行微调变得十分有效且被应用在很多场景。随着chatgpt的火热，paramet","tuning技术似乎也有替代传统fin","tuning技术包括：","tuning技术而非手工调整可能是未来很重要的方向。毕竟在文本摘要、代码debug等需要大量的输入来让模型认识问题的场景，如何有效的将过长的输入prompt给模型是一个很重要的问题，现在的大模型在长输入方面推理成本很高且有很大限制，因此这种技术也是未来很重要的一个方向！","tuning方法包括将预训练模型与少量特定任务数据一起继续训练。在这个过程中，预训练模型的权重被更新，以更好地适应任务。所需的fin","tuning方法更少。","tuning是一种更近期的精调预训练语言模型的方法，重点是调整输入提示（input","tuning最著名的例子之一是由openai开发的openai","tuning期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。","tuning比精调更灵活，因为它允许创建特定任务的提示，可以适应各种任务。","tuning涉及训练可学习的称为“提示记号”的参数，这些参数与输入序列连接。这些提示记号是特定于任务的，在精调过程中进行优化，使得模型可以在保持原始模型参数不变的情况下在新任务上表现良好。","tuning的主要区别在于预训练模型被修改的程度。fin","tuning的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。","tuning的趋势，本篇论文将简单描述预训练模型领域这三种微调技术及其差别。","tuning调整比精调的计算成本低，需要的资源和训练时间也更少。此外，prompt","tuning量取决于预训练语料库和任务特定语料库之间的相似性。如果两者相似，可能只需要少量的fin","tuning（前缀调整）：由li和liang在论文“prefix","tuning，简称peft，旨在在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。它是自然语言处理（nlp）中一组用于将预训练语言模型适应特定任务的方法，其所需参数和计算资源比传统的fin","tuning：由liu等人在论文“p","understands,","up:","一、fine","一些值得注意的prompt","三、prompt","二、paramet","其中一种peft技术称为蒸馏(distillation)，它由hinton等人于2015年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。【教师","参数高效的fine","参考链接：大模型微调技术：fine","另一种技术称为适配器训练(adapt","在nlp中，fine","学生】","微调范式对比","总结：将除了输出层以外的所有权重“冻结”（freeze）。然后随机初始化输出层参数，再以迁移学习的方式训练。仅仅更新全连接输出层，其它层的权重不变。","总结：当大模型开始涉及更加复杂和现实的问题时候，如果可以出现自动prompt","第三种技术称为渐进收缩(progress","经典的fine","通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数。"],"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":["3为例，以下是一些步骤，可以用chain","3模型：","4","4生成的使用instruct","4的案例","4）的方法，可以让模型根据特定任务提供指令来执行任务。在这个具体的情感分类案例中，我们将使用","chain","gpt","imdb","instruct","llm三种训练技术对比","prompt","shot中表现更好！","thought","thought介绍","thought方法训练一个更先进的gpt","thought是一种通过分解训练过程为较小的相互关联的任务来训练模型的方法。这种方法的目的是使模型能够理解和维护文本中的思维链，从而生成连贯的、上下文相关的响应。与其他方法不同，chain","thought的重点在于将训练过程分解为一系列逐步更复杂的任务，并使用注意机制来帮助模型集中于相关的部分。","thought训练中，将数据集中的输入分解为一系列任务是非常关键的一步。一般来说，这个过程需要根据特定的任务和数据集来进行定制。以下是一些通用的方法：","thought通常用于提高模型的生成能力和上下文理解能力。","thought都是用于训练大型语言模型的方法，它们都有助于提高模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。","thought：chain","tune","tuning、instruct","tuning。在训练过程中，模型将学习如何根据输入文本预测相应的情感标签。","tuning介绍：更为详细流程化","tuning和chain","tuning和instruct","tuning微调gpt","tuning是一种使用自然语言提示（prompt）的方法，以指导模型生成特定的输出。这种方法的目的是通过对模型进行定向训练，使其在特定任务上表现出更好的性能。与其他方法不同，prompt","tuning是一种通过为模型提供任务相关的指令来指导模型学习的方法。这种方法的目的是使模型更好地理解任务的要求，并提高其生成能力和上下文理解能力。instruct","tuning的一种想法！","tuning的重点在于设计良好的提示，这些提示可以引导模型生成准确、上下文相关的响应。","tuning通常用于特定任务的优化，而chain","tuning通常需要较少的训练数据，并且可以提高模型的泛化性能。","tuning，gpt","tuning：instruct","tuning：prompt","tuning：加上“prompt”，变成填空题","“|||”）分隔。如下所示：","一、prompt","三、chain","与prompt不同，instruction通常是一种更详细的文本，用于指导模型执行特定操作或完成任务。instruction可以是计算机程序或脚本，也可以是人类编写的指导性文本。instruction的目的是告诉模型如何处理数据或执行某个操作，而不是简单地提供上下文或任务相关信息。","与输出相关的tokens组成的上下文信息即可理解为是一个prompt。prompt通常是一种短文本字符串，用于指导语言模型生成响应。prompt提供上下文和任务相关信息，以帮助模型更好地理解要求，并生成正确的输出。","二、instruct","五、gpt","以gpt","以instructgpt为例，其基本流程如下：","使用准备好的数据集和拼接格式，对","使用微调后的模型进行情感分类：","例如，为了训练模型理解上下文，可以定义一个损失函数，它评估模型生成的响应与上下文的相关性。","例如，可以将训练过程分解为理解语法和词汇、生成单词和短语、生成连贯的句子和段落、理解上下文等子任务。","例如，在自然语言生成任务中，可以将其分解为理解输入的语义、确定输出的语法结构、生成文本等子任务。","例如，在自然语言生成任务中，输入可能是一组与上下文相关的单词，输出可能是下一个单词或整个句子。","例如，如果目标任务是自然语言生成，那么数据集中的输入可能是一句话或一个段落，模型需要将其转化为自然语言响应。","例如：对于问答任务，instruction可以提供具体的指令，例如“请回答下列问题：谁是美国第一位总统？”，并将文本段落作为输入提供给模型。","允许模型在多个步骤中生成连贯的回答，从而更好地解决问题或完成任务。通过思维链式方法训练大型语言模型需要将训练过程分解成较小、相互关联的任务，以帮助模型理解和生成连贯、上下文感知的响应。","准备数据集：","区别：prompt和instruction都是用于指导模型生成输出的文本，但它们的目的和使用方式是不同的。prompt更多地用于帮助模型理解任务和上下文，而instruction则更多地用于指导模型执行具体操作或完成任务。","参考链接：大语言模型三种训练技术及区别：prompt","只要我们把希望输出的部分删除掉，然后尽量构造与该输出有关的其它tokens即可。这就是prompt","四、对比总结","在","在chain","在实际应用中，当你需要对给定的文本进行情感分类时，可以这样使用微调后的","在微调后，使用测试数据集（不包含在训练数据集中的数据）对模型进行测试。输入文本并观察模型生成的情感标签，然后与实际标签进行比较，计算准确率、召回率等性能指标。","将文本和情感标签转换为适用于","微调","总之，这些方法都有助于提高大型语言模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。prompt","指令微调的动机是提高语言模型对自然语言处理指令的响应能力。","数据预处理：","文本1|||标签1","文本2|||标签2","文本3|||标签3","方法中，模型的输出被视为一个序列，每个部分都是一个独立的“思考链”或步骤。模型通过将先前的输出作为后续输入的一部分来迭代地生成这些部分，这样可以让模型在一定程度上模拟人类解决问题的过程。","是一种微调大型预训练语言模型（如","是一种有效的技巧，可以帮助大型预训练语言模型在多步骤任务和复杂问题中生成连贯的输出。然而，在实际应用中，可能需要结合其他技巧来克服其局限性，以实现更好的性能。","来对给定的文本进行情感分析。我们的目标是根据文本内容，判断其情感是正面、负面还是中性。以下是一个简单的指南：","模型测试和评估：","模型的格式。例如，将文本和情感标签拼接在一起，用特定的分隔符（如","模型能够根据输入文本生成对应的情感标签，从而实现情感分类任务。","模型进行","模型：","电影评论数据集，也可以是你自己收集和标注的数据。","简单总结就是说prompt就是利用语言模型的生成能力帮我们完成任务。","而openai在instructgpt中也是类似的想法！instructgpt就是chatgpt的前身！","训练技术：prompt","输入：这部电影的剧情令人惊叹，特效也非常出色，我非常喜欢。","输出：正面","这个想法是，通过使用监督来教授语言模型执行通过指令描述的任务，模型将学会遵循指令，即使是对于未见过的任务也能如此。","这些子任务应该是相互关联的，每个子任务的输出都可以作为下一个子任务的输入。","这些目标和损失函数应该与任务相关，并帮助模型学习与该任务相关的知识。","这样的方式训练了出来的模型可以让模型更好地识别输入的意图，同时也在zero","通过","首先，你需要一个带有标签的文本数据集，以便在情感分类任务上微调模型。数据集应该包含多个实例，每个实例都有一段文本和一个对应的情感标签（正面、负面或中性）。数据集可以是开源的，如","（1）准备自然语言指令集：针对特定任务，准备一组自然语言指令，描述任务类型和任务目标，例如情感分类任务的指令可以是“该文本的情感是正面的还是负面的？”。","（1）收集大量的语料库，包括各种主题和风格的文本。可以从各种来源获取数据，如网站、社交媒体、新闻、书籍等。","（1）首先，需要定义一个目标任务，即要求模型完成的最终任务。","（2）准备训练数据集：针对特定任务，准备一个标记化的数据集，其中每个数据样本都包含输入文本和标签，例如情感分类任务的标签可以是“正面”或“负面”。","（2）对语料库进行预处理，包括分词、标记化、去除停用词、处理语法结构等。","（2）然后，需要将目标任务分解为一系列子任务。","（3）定义一个上下文窗口，即模型需要考虑的前面和后面的文本内容。","（3）将自然语言指令和数据集转换为模型输入：将自然语言指令和数据集转换为模型输入，例如对于情感分类任务，将自然语言指令和文本拼接作为输入，例如：“该文本的情感是正面的还是负面的？这家餐厅的食物很好吃。”","（3）每个子任务的输入和输出都需要定义。","（4）在指令上进行微调：在指令上进行微调，以适应特定任务的需求，提高模型在任务上的性能。","（4）将训练过程分解为一系列逐步更复杂的子任务。","（4）每个子任务都需要为其定义一个训练目标和相应的损失函数。","（5）为每个子任务定义适当的训练目标和损失函数，并使用训练数据来训练模型。","（5）最后，需要将所有子任务组合起来，构建一个完整的模型。每个子任务的输出都将成为下一个子任务的输入，直到完成目标任务。","（6）在训练完成后，使用测试数据来评估模型的性能。例如，检查模型是否能够生成连贯的响应，以及是否能够维护文本中的思维链。","（7）迭代地对模型进行微调和优化。"],"Chapter2/思维链.html":["step","step”","think","thought，cot)，指的是一系列有逻辑关系的思考步骤，形成一个完整的思考过程。","《精准学习》中提出，缓慢地、理智地、符号化地运作，是人脑的特权。它可以在任何可能的时候，提取具有普遍性、逻辑性的、明确的原则。","使有了思维链，大语言模型还是没有真正理解数学逻辑，不知道加减乘除的真实意义，只是通过更精细的叠加来“照葫芦画瓢”，所以，对于有精确要求的任务，还要进一步探索新的技术。","原理：思维链(chain","四、思维链——“let’","大模型“涌现”的思维链，究竟是一种什么能力？","局限：","思维链必须在模型规模足够大时才能涌现。","思维链提示会在给出答案之前，还会自动给出推理步骤","思维链暴露了它，依然是鹦鹉学舌，而非真的产生了意识。","思维链简介","总结：就是把一个多步骤推理问题，分解成很多个中间步骤，分配给更多的计算量，生成更多的token，再把这些答案拼接在一起进行求解。【因式分解】","概述：思维链将一个逻辑推理问题，分解成了多个步骤，来一步步进行，这样生成的结果就有着更加清晰的逻辑链路，提供了一定的可解释性，让人知道答案是怎么来的。","相当于让ai做分析题，而不是“填空题”，要把推理过程详细说清楚，按步骤得分，最后给出答案。","策略问题需要大量的世界知识，而小型模型没有足够的参数来记忆这些世界知识，所以也不太可能产生正确的推理步骤。","这种步骤分解的方式用在提示学习中，就被称为思维链提示，将大语言模型的推理过程，分解成一个个步骤，直观地展现出来，这样开发人员可以在llm推理出现错误时，就及时地修复。"],"Chapter1/根据自己数据库让GPT作答.html":["1","2","3","4","5","6","api的token的最大是4096","embeddings（嵌入）","embeddings（嵌入）无需训练模型，是将自己的预设pormpt+数据+问题打包，当作一整段话发送给gpt。让gpt根据这个预设的prompt和灌给的数据再加问题做回答。适合数据量超大且实时更新的一些数据。","embedding作用","fine","openai的文本嵌入测量文本字符串的相关性。嵌入通常用于：","tuning（微调）","tuning（微调）目前仅适用于以下基本型号：davinci、curie、babbage和ada，是预训练模型，一次训练终身受益，适合很久知识都不变且数据集较小的情况；你的训练示例越多越好。我们建议至少有几百个例子。一般来说，我们发现数据集大小的每一次翻倍都会导致模型质量的线性增加","使用你的微调模型","准备和上传培训数据","分类（其中文本字符串按其最相似的标签进行分类）","多样性测量（分析相似性分布）","官方两种解决方案：embeddings（嵌入）；fin","建议（其中建议包含相关文本字符串的项目）","异常检测（其中识别出相关性很小的离群值）","微调作用","微调步骤","搜索（其中结果按与查询字符串的相关性进行排名）","根据自己数据库让gpt作答","步骤：","比即时设计更高质量的结果","由于更短的提示而节省令牌","目前市场上出现的实时搜索基本也是先在网页搜索后将网页的内容提取出来后，一起打包发给gpt,让其回复，并没有真正的实现联网功能。","简而言之：在外面包了一层语义搜索，先搜索再打包，最后发给gpt回答。","聚类（其中文本字符串按相似性分组）","能够训练更多的例子比可以在提示","解决方案：矢量数据库","训练一个新的微调模型","通过提供以下功能，微调可让您从api提供的模型中获得更多信息：","降低延迟请求"],"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":["#","#下载源代码","#下载脚本","#关启shell，创建虚拟环境","#初始化shell，以便直接运行conda","#安装依赖","#测试pytorch","#激活","#网址：https://conda.io/en/latest/miniconda.html","'./lora","'./trans_chinese_alpaca_data.json'","'decapoda","'llama","'tloen/alpaca","(generate.py)","1","2","3","4","5","6","7","7b","7b'","\\","activ","adaptation,","alpaca","base_model","cd","chines","clone","conda","creat","data_path","finetune.pi","generate.pi","git","github.com/lc1332/chines","github.com/tloen/alpaca","hf","hf'","hf/tree/main","https://github.com/tloen/alpaca","https://repo.anaconda.com/miniconda/miniconda3","huggingface.co/decapoda","import","infer","init","instal","linux","load_8bit","lora","lora(羊驼模型):","lora)方法。","lora.git","lora/blob/main/data/trans_chinese_alpaca_data.json","lora:大型语言模型的低秩适配器;简单来说就是微调模型的另一种方式，来调试模型在具体场景下的准确度；假设模型适应过程中的权重变化也","lora_weight","lora（开源的中文数据集）","lora）","lora，链接开头已经给出，下载后放到项目根目录下。","miniconda3","name","output_dir","pip","py310_23.1.0","py39_4.12.0","python","python=3.9","python环境","r","rank","requirements.txt","research/llama","sh","torch","torch.cuda.is_available()","wget","x86_64.sh","zh","zh'","~/miniconda3/bin/conda","下就有模型生成了","下载llama基础模型：下载完成后放到根目录下/llama","下载羊驼代码","云端部署","使用kaggle部署模型，访问web交互","其他具体参数可以git链接","具有较低的“内在秩”，从而提出了低秩适应(low","准备数据集","参考链接：gpt进阶（二）:训练部署自己的chatgpt模型(羊驼","地址：www.kaggle.com/model","执行","构造指令数据集结构，类似于instruct的方法，可参考使用开源的中文数据集：chines","模型推理","模型训练后，lora","训练模型","训练部署自己的羊驼","论文地址（github）:https://github.com/microsoft/lora"],"Chapter1/训练部署自己的ChatGLM-6B.html":["\"../../../pre_model/chatglm/chatglm","\"./output/adgen","\"epoch\":","\"predict\":","\"pytorch_model.bin\"))","\"summary\":","\"train_loss\":","\"train_runtime\":","\"train_samples\":","\"train_samples_per_second\":","\"train_steps_per_second\":","\"你是谁\"))","\"修身修身的unk>,这款unk>感感,加上加上性感的面料,展现气质,整体整体整体性感,展现彰显修饰修饰的unk>。加上加上气质,让简约设计,穿着穿着设计,搭配搭配。\"}","\"宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。\"}","\"简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。\",","\"简约而不简单的牛仔外套，白色的衣身十分百搭。衣身多处有做旧破洞设计，打破单调乏味，增加一丝造型看点。衣身后背处有趣味刺绣装饰，丰富层次感，彰显别样时尚。\"}","\"类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞\",","\"类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤\",","#","#显示环境列表","$","$lr","$pre_seq_len","$step","&","'epoch':","'learning_rate':","'train_loss':","'train_samples_per_second':","'train_steps_per_second':","(glm)","*****","***.sh","../../../pre_model/chatglm/chatglm","./output/$checkpoint","./output/$checkpoint/checkpoint","./output/adgen","/data/pre_model/chatglm","/data/train_data/chatglm","0.0,","0.42","0.42,","0.42}","05,","0:40:02.13","1","1.249","1.249,","10","1000","105145,","114599","114599,","130001,","130004]","16","19.982","19.982,","1e","1t","1、执行部署脚本","1、模型文件","1、训练脚本train.sh如下：","2","2/checkpoint","2/generated_predictions.txt。","2000","2402.1329,","2e","2、开始训练,后台执行：","2、执行评测脚本，","2、查看部署脚本","3","3,","3000","3000\"","3000，训练40分钟完成","32,","3、查看评测脚本","3、训练结束，查看结果，max_step","4","4、查看训练生成的模型文件及模型结果","4、查看评测结果：","5","5,","6","6,","6.666666666666667e","61,","62","63823,","63832,","63912,","64","64051,","64131,","64257,","64290,","64555,","64622,","64703,","64880,","65107,","65173,","65209,","65347,","65388,","65421,","65509,","65594,","66069,","66261,","66268,","66561,","67061,","68554,","69418,","69768,","6b","6b\"","6b.git","6b/ptune","6b/ptuning/output/adgen","6b模型的训练，需要准备相应的数据集。使用adgen数据集，其任务为根据输入（content）生成一段广告词（summary）。下载adgen数据集，从","6b模型训练完整流程详解","6b，然后通过p","7","7.088,","7.1214,","70936,","70984,","71319,","71689,","72194,","72265,","73412,","73416,","73942,","74197,","75898,","77257,","78598,","8","8.5971","8.597134847005208,","81549,","83343,","85428,","87019,","87834,","=","[3,","[5,","\\","activ","adgen","advertisegen","advertisegen/dev.json","advertisegen/train.json","all_results.json","autoconfig","autoconfig.from_pretrained(model_name,","automodel,","automodel.from_pretrained(model_name,","autotokenizer,","autotokenizer.from_pretrained(model_name,","base","bit","cat","cd","chatglm","chatgpt","checkpoint","checkpoint=adgen","checkpoint_path","clone","cloud","conda","conda环境","config","config.json","config.pre_seq_len","config=config,","configuration_chatglm.pi","content","creat","cuda_visible_devices=0","dataset","deploy.pi","dev.json","do_predict","do_train","drive","env","epoch","evaluate.sh","evaluate.sh。","face","fp16","gener","generated_predictions.txt","generation_config.json","git","googl","gradient_accumulation_step","head","https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1","https://github.com/thudm/chatglm","https://huggingface.co/thudm/chatglm","hub","hug","ice_text.model","import","input","input_id","instal","jieba","k,","label","label_id","languag","latest","learning_r","lf","lfs，然后运行","list","logging_step","lr","lr=2e","ls","main.pi","max_source_length","max_step","max_target_length","metric","miniconda3","model","model.half().cuda()","model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)","model_nam","model_name_or_path","modeling_chatglm.pi","n","new_prefix_state_dict","new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]]","nltk","nohup","nohup.out","optimizer.pt","os","output_dir","overwrite_cach","overwrite_output_dir","p","per_device_eval_batch_s","per_device_train_batch_s","pip","pre_seq_len","pre_seq_len=8","predict_with_gener","prefix_state_dict","prefix_state_dict.items():","print(model.chat(tokenizer,","prompt","prompt_column","pt","ptuning_checkpoint","python","python3","pytorch_model.bin","quantiz","quantization.pi","quantization_bit","r","requirements.txt","response_column","rng_state.pth","rouge_chines","save_step","scheduler.pt","sh","soft","sourc","special_tokens_map.json","step=3000","summari","tail","test_fil","thudm/chatglm","token","tokenization_chatglm.pi","tokenizer_config.json","torch","torch.load(os.path.join(checkpoint_path,","train","train.json","train.sh","train_fil","train_loss","train_results.json","train_runtim","train_sampl","train_samples_per_second","train_steps_per_second","trainer_state.json","training_args.bin","transform","trust_remote_code=true)","tsinghua","tune","v","v2","validation_fil","wget","yum","{","{\"content\":","{\"labels\":","{'loss':","{'train_runtime':","{}","}","下载miniconda，选择匹配的操作系统的版本，","下载代码&安装依赖","下载处理好的","下载模型需要先安装git","中的","亿参数。","亿参数的","从","从官网ttps://docs.conda.io/en/latest/miniconda.html下载。","使用了和","分别是","创建新环境","参考链接：【实战讲解】chatglm","名称，","和","在部署时，可以考虑到模型的可用性、可扩展性和性能等因素。","如果你想要从本地加载模型，可以将","安装依赖","对于chatglm","将","已经能生成相当符合人类偏好的回答。","当模型训练和评估完成后，可以将它部署到适当的平台上。","或","或者","改为你本地的模型路径。","改成你训练时的实际值，具体部署验证演示代码如下：","数据集，将解压后的","方法会冻结全部的模型参数，可通过调整","是一个开源的、支持中英双语的对话语言模型，基于","更改为训练时保存的","本文实现了基于","本次只是演示，使用部署脚本加载本地模型,并加载新的checkpoint。","来被原始模型的量化等级，不加此选项则默认为","构建虚拟环境","架构，具有","标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62","模型checkpoint路径","模型下载,","模型前缀长度","模型名","模型和数据准备","模型训练可以使用一些机器学习框架，pytorch。使用预训练模型来初始化chatglm","模型评估","模型路径","模型部署","注意需要将","激活环境","生成的结果保存在","的高效参数微调方法，通过实际动手操作，提升对大模型的理解和应用能力。","的高效参数微调进行训练。需要考虑到训练时间和硬件资源的因素","目录放到本目录下。","相似的技术，针对中文问答和对话进行了优化。经过约","简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。","类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞","精度加载。","训练完成后，需要进行模型评估和调整。可以使用一些指标来评估模型的性能。","训练数据下载存放路径：","训练数据示例：","训练模型","训练部署自己的chatglm","评估数据示例：","评测样本示例：","跟你训练的pre_seq_len一致","运行以下指令进行模型推理和评测：bash","长度和训练的学习率，可以进行调节以取得最佳的效果。"],"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":["'int4weightextractionfloat'","1.","10.3.0","1、windows+cpu方案的必备条件","1、windows+gpu方案的必备条件","1、下载官方代码，安装python依赖的库","2","2.","2、下载int4量化后的预训练结果文件","2、运行部署cpu版本的int4量化的chatglm","2、运行部署gpu版本的int4量化的chatglm","2分钟，实在是太慢了，基本不适合使用。有机会还是搞gpu版本吧！","2秒即可获得结果","3","3.","4","6b","6b.md","6b依赖torch，如果你有gpu，且高于6g内存，那么建议部署gpu版本，","6b有3个版本可以使用，","6b模型","6b模型——windows+6gb显卡版本和cpu版本的本地部署","6b模型的训练，需要准备相应的数据集。使用adgen数据集，其任务为根据输入（content）生成一段广告词（summary）。下载adgen数据集，从","6b的运行需要模型的配置文件，即config.json等。","6b部署比gpu版本稍微麻烦一点，主要涉及到一个kernel的编译问题。","6b需要安装cuda版本的torch，",":","=","=automodel.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm","=autotokenizer.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm","adgen","advertisegen","appli","attribut","attributeerror:'nonetype'object","autotokenizer.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm","bit","c:\\users\\dufei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm","cach","cloud","compil","cpu","cpu.","cpu版本的chatglm","don't","drive","fopenmp","found.","fpic","gcc","gcc/","gcc编译环境配置+kernel编译","gcc，下载地址：https://jmeubank.github.io/tdm","glm","googl","gpu版本的模型部署很简单，上述两个步骤完成之后即可运行。代码如下：","histori","history=[])","import","importautotokenizer,automodel","instal","int4","int4\",","int4\",trust_remote_code=true,","int4/tree/main","int4\\\\quantization_kernels.so\")","int4\\\\quantization_kernels.so\")一行手动加载的内容。","int4\\quantization_kernels_parallel.c","int4\\quantization_kernels_parallel.so","int4本地目录下进入cmd，运行如下两个编译命令：","int4目录下看到下面两个新的文件：","int4量化的预训练文件下载地址：https://huggingface.co/thudm/chatglm","kernel","kernel,","kernel_file=\"d:\\\\data\\\\llm\\\\chatglm","layer","load","model","model.chat(tokenizer,\"你好\",","model.eval()","model.quantize(bits=4,","o","o3","pip","print(response)","print(torch.cuda.is_available())","pthread","quantiz","quantization_kernels.c","quantization_kernels.so","quantization_kernels_parallel.c","quantization_kernels_parallel.so","quantization_kernels_parallel.so和quantization_kernels.so。说明编译成功，后面我们手动载入即可。","r","release下载安装即可，注意安装的时候直接选择全部安装就好。","requirements.txt","response,","revision=\"\")","revision=\"\").float()","revision=\"\").half().cuda()","share","std=c99","token","torch","transform","trust_remote_code=true,","tsinghua","us","v”测试是否成功即可。","windows+6gb显+cpu本地部署chatglm","windows+cpu部署方案","windows+gpu部署方案","一、windows+gpu6g","上述文件全部下载之后保存到本地的一个目录下即可，我们保存在：d:\\\\chatglm","下载int4量化后的预训练结果文件","下载处理好的","二、windows+cpu","但实际上chatglm","但是需要下载支持cuda的torch，而不是默认的cpu版本的torch。","但是，除了这些cpu版本的安装还需要在本地的windows下安装好c/c++的编译环境。推荐安装tdm","其中","即在上面下载的d:\\\\data\\\\llm\\\\chatglm","参考链接：手把手教你本地部署清华大学keg的chatglm","另外，chatglm","因此建议全部从huggingface上下载所有文件到本地。","在","在github上下载requirements.txt即可。下载地址：https://github.com/thudm/chatglm","在安装之前，除了上面需要安装好requirements.txt中所有的python依赖外，torch需要安装好正常的cpu版本即可。","如果以上代码输出的是true，那么恭喜你，你安装的是cuda版本的torch","如果你运行上面的代码出现如下错误","如果在运行中遇到了如下错误提示：","安装依赖：","安装前说明","安装完在cmd中运行”gcc","对于chatglm","库版本必须是4.27.1及以上的版本才可以","总结","或者","数据集，将解压后的","比原来的代码多了model","没有量化的版本做推理需要13g的gpu显存，int8量化需要8gb的显存，而int4量化的版本需要6gb的显存。","注意，其实就是第三行代码最后的float()有差异：gpu版本后面是.half().cuda()，而这里是float()。","注意，目前chatglm","注意：模型量化会带来一定的性能损失，经过测试，chatglm","注：cpu版本的模型推理运行一次约1","注：安装这个主要是为了编译之前下载的文件中的quantization_kernels.c和quantization_kernels_parallel.c这两个文件。","然后就可以在d:\\\\data\\\\llm\\\\chatglm","目录放到本目录下。","直接点击上述页面中tdm","训练部署自己的chatglm","运行部署cpu版本的int4量化的chatglm","运行部署gpu版本的int4量化的chatglm","通过以上步骤我们可以得到如下结果：gpu版本大约只需要1","那么就是前面说的编译文件出了问题，那么就必须做上面说的编译操作，得到那2个so文件，然后手动加载。新代码如下：","那么就是这两个文件编译出问题了。那么就需要我们手动去编译这两个文件：","部署gpu版本的chatglm","部署前安装环境","量化下仍然能够进行自然流畅的生成。","需要检测自己的torch是否正确，可以通过如下命令检查（下面是python代码）：","需要注意的是，在github上，官方提供了模型在清华云上的下载地址，但是那个只包含预训练结果文件即bin文件，","首先，我们需要从github上下载chatglm的requirements.txt来帮助我们安装依赖的库。","（注意，有显卡也需要下载cuda和cudann安装成功才可以，这部分可以去网上找教程）。"],"Chapter3/Self-Instruct数据.html":["003调优（即alpaca）和不调优（即llama）的性能更高；7b","1.3b的奖励模型，以对不同的回复进行评分：对一个提示和k个回复，gpt","3.5和opt","4","4(7b)和","4)进行比较。","4,","4/gpt","4为每个回复提供一个1到10之间的评分。","4创建了对比数据；为了评估数据质量，研究人员训练一个基于opt","4和gpt","4对llama进行指令调优，往往比用text","4对两个模型之间的回复质量进行评分，评分范围从1到10，并将结果与其他强竞争模型(chatgpt","4对自己的回复提供从1到10的评分，并对gpt","4是在比中文更丰富的英文语料库中训练的，所以具有更强的英文instruct","4来评估不同聊天机器人模型对80个未见过的问题所生成回答的质量，从","4模型中收集回复，并从以前的研究中获得其他模型的答案，然后要求gpt","4模型来自动生成语言模型所需的微调指令数据。gpt","4生成的5.2万条英文instruct","4生成的instruct","4用中文回答这些指令，并以此建立一个基于llama的中文instruct","4的5.2万条中文instruct","4的结果而言，翻译后的回复比中文生成的回复表现得更好，可能是因为gpt","4等大型商业聊天机器人相比，仍有差距。","4自动评估：受","4！微软开源微调指令集：效果不输原版，中英双语都能用","4，可以注意到，llama","7b","alpaca和llama，但和gpt","checkpoint有监督微调后训练得到了两个模型：llama","cn是在gpt","data）：要求gpt","data：使用chatgpt将5.2万条指令翻译成中文，并要求gpt","davinci","evaluation）：从平均roug","follow","following数据上训练的。","following数据上训练的；llama","following数据表现出更强大的对齐性能。","following模型，并研究指令调优的跨语言泛化能力。","following能力。","gpt","gpt4","gpt4和gpt4在ground","gpt4是在gpt","gpt4的性能超过了13b","iml这三个模型的回复进行评分，以训练奖励模型。","instruct","instruct自动生成微调数据","llama","llm","l得分来看，alpaca优于llama","mechan","self","truth回复长度增加时逐渐表现得更好，最终在长度超过4时表现出更高的性能，意味着当场景更具创造性时，可以更好地遵循指令。","tune","turk对模型生成结果进行人工评估。","vicuna","三、self","中文instruct","仅就gpt","使用gpt","参考链接：","和","奖励模型：研究人员使用gpt","对比数据（comparison","帮助性（helpfulness）：是否能帮助人类实现他们的目标，一个能够准确回答问题的模型是有帮助的。","微调数据链接：https://github.com/instruct","效果评估：人类评估3h标准。基于hhh对齐标准，研究人员使用众包平台amazon","无害性（harmlessness）：是否不会对人类造成伤害，一个产生仇恨言论或提倡暴力的模型不是无害的。","的启发，研究人员也选择用gpt","的性能是有效的；用gpt","研究人员基于llama","结果显示：反馈数据和奖励模型对提高","论文链接：https://arxiv.org/pdf/2304.03277.pdf","诚实性（honesty）：是否提供真实信息，并在必要时表达其不确定性以避免误导人类用户，一个提供虚假信息的模型是不诚实的。","轻松打造家用版gpt","非自然指令评估（unnatur"],"Chapter3/学术问答数据集调研.html":["\"antioxidants\",","\"compound","\"correct_answer\":","\"distractor1\":","\"distractor2\":","\"distractor3\":","\"oxid","\"oxidants\",","\"oxygen\",","\"question\":","\"residues\",","\"support\":","(allenai.org)","(baidu.com)","(c6h12),","(codalab.org)","(or","(rajpurkar.github.io)","12b生成。","1585","1k","2","2.amazonaws.com/qasp","211.3k","3.30","3.30:","3的对话生成模型，使用了openai","4","4数据集。","5049","[","]","accept","agents)","ai","all.jsonl.gz]","alpaca","alpaca：一个包含20k个代码生成任务的数据集。","anoth","answer","api提供。","api提供的数据集和模型来训练。根据openai","api生成的问题和freebase实体作为答案。webquest","api的文档，chatgpt使用的训练数据集有：","benchmark","blended_skill_talk：一个包含7k个对话的数据集，设计为展示多种对话模式，如展示个性、表达同理心和展示知识。","call","calledoxid","calledreduct","capabl","caus","cc_sbu_align：一个包含4k个对话的数据集，基于minigpt","challenge/cail2019","chatalpaca：一个包含10k个对话的数据集，由chatgpt生成。","chatgpt是一个基于gpt","china","code","compound","compound.","compounds.","comprehens","cyclohexan","dataset.s3.u","datasets.s3.amazonaws.com/sciq/sciq.zip","dataset（squad）是一个阅读理解数据集，由众包工作者在一组维基百科条目上提出的问题组成，其中每个问题的答案是相应阅读段落中的一段文本或跨度，或者问题可能无法回答。【英文】【维基百科】","dataset：一个包含52k个指令的数据集，由openai","dataset：一个包含75k个对话的数据集，基于sharegpt对话。","dataset：科学问答数据集","dev","dolly：一个包含15k个对话的数据集，由databricks员工生成，用于训练大型语言模型。","donat","dureader：一个大规模的中文阅读理解数据集，包含三个子任务：机器阅读理解、搜索式问答和多文档阅读理解。数据来源于百度搜索引擎和百度知道。【百度】【中文】machin","electrons,","equat","evol：一个包含70k个对话的数据集，是wizardlm的训练数据。","explorer/dataset/dev","explorer/dataset/train","f2,","finance：一个包含69k个金融相关指令的数据集。","github","gsm","hc3：一个包含37k个指令的数据集，由chatgpt和人类生成，涉及中英文。","hh","homepag","http://www.","ic：一个包含8k个对话的数据集，涉及到小学数学问题和无关上下文。","instruct","instructiontranslation：一个包含80k个多语言指令翻译任务的数据集，由m2m","instruct：一个包含82k个指令输入输出实例的数据集。","law","master","metal","nlp","nq","o","oasst1：一个包含89k个多语言助理风格对话的数据集，由人类生成和标注。","org/books.\"","oxid","oxidized.","process","public","qa","qa对","question","read","reduc","reduced.","reduct","relationship","rlhf：一个包含91k个对话的数据集，用于从人类反馈中进行强化学习。","saylor","saylor.","self","simplified/nq","simplified/simplifi","sodium","studio","such","suggest","summar","todo——构建数据集：构建retrieval数据集；匹配模型优化——对比学习预训练、度量学习；大模型prompt【用户查询】","train","train.jsonl.gz]、开发集[https://storage.cloud.google.com/natural_questions/v1.0","triviaqa：一个问答数据集，包含65万多个问题和答案，基于维基百科和网络搜索结果。每个问题都是一个有趣的事实，每个答案都是一个实体或数字。http://nlp.cs.washington.edu/triviaqa/","url:","v0.3.tgz","v2.0.json]","v2.0.json]；开发集[https://rajpurkar.github.io/squad","vicuna","webgpt：一个包含20k个对话的数据集，由webgpt项目生成。","webquestions：一个开放领域问答数据集，包含5,810个问题和答案，基于googl","west","what?\",","{","}","·","一、hotpotqa：hotpotqa","七、sciq","三、natualquestions：https://ai.google.com/research/naturalquestions/visu","个qa问题","个专家标记、61.2k","个人工生成的","个未标记和","个答案选项","九、chatgpt使用的训练数据集——来自b","二、squad2数据集：斯坦福问答数据集","五、pubmedqa：医学问答数据集","全面的中文开源数据集合","八、其他公开领域的数据集链接：","六、qasper：卡斯珀","千言（luge）|","四、中文法律问答数据集：cail2019","学术问答数据集调研","它由卡内基梅隆大学、斯坦福大学和蒙特利尔大学的","实例。","成为一项比以前的","数据描述：hotpotqa","数据描述：nq语料库包含来自真实用户的问题，它要求qa系统阅读和理解整个维基百科文章，其中可能包含也可能不包含问题的答案。包含真实的用户问题，以及解决方案应阅读整个页面以找到答案的要求，使","数据描述：pubmedqa的任务是使用相应的摘要回答是/否/也许的研究问题（例如：术前他汀类药物是否会减少冠状动脉旁路移植术后的心房颤动？","数据描述：stanford","数据描述：一个包含","数据描述：包含13679个关于物理，化学和生物学等的众包科学考试问题。这些问题采用多项选择题格式，每个选项有","数据描述：数据集是来自“中国裁判文书网”公开的法律文书，主要涉及民事和刑事的一审判决书，总共约1万份数据，并按比例划分训练、开发和测试。每份数据包括若干个问题，对于训练集，每个问题只包含一个标准回答，对于开发和测试集，每个问题包含3个标准回答。回答内容可以是案情片段，可以是yes或no，也可以拒答即回答内容为空。数据格式参考squad2.0的数据格式，整体为json格式的数据。并增设案由\"casename\"字段和领域\"domain\"字段，\"domain\"字段只有\"civil\"和\"criminal\"两种类型。\"context\"抽取自裁判文书的案情描述或原告诉称部分。【裁判文书网】【中文】","数据格式","数据格式：","数据规模：","数据规模：15万+","数据规模：30m左右","数据规模：41gb","数据规模：一个包含","数据规模：不大","数据规模：训练集535m，测试集46m，开发集100m","数据集更现实、更具挑战性的任务。【维基百科】【英文】","数据集链接：cail2019/阅读理解/data","数据集链接：http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json","数据集链接：https://ai2","数据集链接：https://qasper","数据集链接：pubmedqa","数据集链接：训练集[https://rajpurkar.github.io/squad","数据集链接：训练集[https://storage.cloud.google.com/natural_questions/v1.0","是一个问答数据集，具有自然的多跳问题，对支持事实进行强有力的监督，以实现更可解释的问答系统。","根据已有的样本，摘要喂给gpt4进行self","知识类问答数据集资源对外开放：百万级百度知道、社区问答及六大领域级小规模语料概述","研究人员团队收集。【英文】","篇论文的数据集，其中包含","训练集、1gb开发集","飞桨ai"],"Chapter4/Lamini.html":["1.","100","2.","3","3.","3直接调成chatgpt","4.","5","5.","50k","alpaca。这个生成","api","chatgpt","chatgpt。供开发人员使用很多公司、机构的基础模型快速构建定制化模型。","gpt","gpu。","gpu。lamini","gpu，并且生成的数据是商业可用的。用户可以自定义最初的","lamini","llm","llm引擎学习","llm，以生成不同但相似的指令","llm，后续他们将发布执行此操作的功能和代码。","ml","openai","pipelin","pipeline，其灵感来自斯坦福的开源模型","prompt","prompt。","prompt，以便于用户根据模型设置不同格式的","rlhf。","rlhf。lamini","万条符合要求的指令，最终得到一个大型指令遵循数据集。","个数据点生成","个样本变成超过","个样本，而不需要启动任何","也提供了一个","产品定位：","作用","使用","和人工标记团队来运行","响应对。","在数据集上微调基础模型。","在经过微调的模型上运行","多条指令，以便生成的","对","将微调封装成一种服务，使开发人员可以轻松将","库中的几行代码，用户就能训练自己的大型语言模型（llm）及其权重，而无需使用任何","库来定义和调用","库的","库让用户不再需要大型","库还提供了优化之后的正确","引擎，用户可以仅用几行代码就快速从","微调成","或其他模型进行","提供了一个托管数据生成器，只需几行代码即可将","提供了一种托管化的数据生成器，只需执行","提供快速调优功能，只需一行代码即可在","数据点，而无需启动任何","数据生成器","方便用户将模型部署到云端。","构建一个输入输出对的大型数据集。","的开源数据集。","的开源数据集上微调出一个","的数据生成器是一个","的模型和其他开源模型之间切换。lamini","的研究团队在其","相关链接：神奇llm引擎上线！帮你把gpt","简介","该数据集将让模型理解它应如何响应其输入。使用","调整。","项目地址：https://lamini.ai/","（1）lamini","（2）lamini"],"Chapter4/GPT与知识图谱.html":["1.","gpt与知识图谱","lamini","llm引擎学习","不同点：","大模型，可以通过prompt，来执行相应信息提取以及思维链的推理任务，形式化成不同形式的知识【例如三元组，多元组或者事件链条】。","相关链接：再谈知识图谱与chatgpt如何结合：参数化与形式化知识库的现实问题、结合要素和具体路线","相同点：知识图谱vs大语言模型本质上都是一种知识库；chatgpt遇到的事实性错误和时效性，知识图谱同样存在，知识图谱也需要解决知识更新的问题。","知识图谱vs大语言模型","知识图谱是一种知识的形式化表示方式，大语言模型(chatgpt)是参数化的知识。","知识图谱，可以利用prompt，参与到大模型的训练前的数据构造，训练中的任务，以及训练后推理结果的约束生成，提升大模型的性能。","结构化知识很难构建(因为要设计知识的结构体系)，但易于推理(因为有体系结构)，非结构化知识易于构建(直接存","起来就行)，但很难用于推理(没有体系结构)。"],"Chapter4/Entailment Trees论文学习笔记.html":["(te)","1","1,840","1.今天的解释系统擅长为答案提供一两句话的支持证据（“基本原理”）（dey","1.在开放域文本问答的背景下，的目标是通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。","1840个随机选择的问题（arc中的7787个问题）总共包括5881个离散蕴涵步骤。总的来说，大约600（带薪）工作小时用于构建数据集。平均而言，每个蕴涵树包括跨越3.2个蕴涵步骤的7.6个节点，其中每个蕴涵步骤通常涉及3个事实（两片叶子，组合起来得出一个结论）。","2.7","2.本文方法是以多步蕴涵树的形式生成解释，如图","2.的方法是以蕴涵树的形式生成解释，即多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设（即问题+答案）。","25","2）链上。在这里，推广到需要多步蕴涵树的任务。","3.为了用这种技能训练模型，创建了","3.因此本文的一个重要贡献是构建了这样一个数据集，称为","35%","4.本文还在这个数据集上定义了三个解释任务，即：为给定的","40k","5.研究结果表明，强大的语言模型可以部分解决这些任务，特别是当相关句子包含在输入中时，并且有泛化到其他领域的迹象。这项工作意义重大，因为它提供了一种新型数据集（多步蕴涵）和基线，为社区提供了一条新途径，以产生更丰富、更系统的解释。","5.研究重点是生成推理线，以显示证据如何生成的答案，而不是决定将哪些部分显示给用户。这使能够将两个解释要求，即推导的正确性与效用分开，使能够以更客观的度量评估推导。","6.6","8）进行微调，选择开发分数最高的检查点。","analysis：确定了6种常见的高级推理类别：替代类型是指需要模型来执行分类、子项或其他形式的链接的蕴涵，这些链接将一个输入句子中的一个实体替换为另一个实体。从规则蕴涵中进行推理需要将指定为一个输入句子的特定规则应用于另一个输入句子。分析表明，大约三分之一（33%）的所有蕴涵需要应用特定领域的规则才能完成。进一步的规范或连接蕴涵需要一个模型将两个输入事实的细节合并到单个输出事实中。不太常见的类型需要从对象的属性推断对象的类、继承对象的属性或确定顺序推理的顺序。总的来说，该分析表明，要成功完成蕴涵库中的蕴涵步骤，需要多种形式的推理。","answer","bank","bank。","bank，第一个用于","c","dataset","dataset：用户首先填充“解释性工作表”，用少量特定类别（例如，“核心事实”、“基础事实”）标记他们预期将包含在树中的事实。然后，用户从该工作表开始构建蕴涵树","entail","entailmentbank","entailmentwrit","entailmentwriters。使用","evalu","explain","h：假设；q：问题；a：回答；c","introduct","metrics：......","once”序列到序列模型的启发，作者训练了三个基于","oung","proofwrit","qa","roberta","t5","t511b","t5）。","tgold","tree","trees论文学习笔记","t，近似为黄金蕴涵树","worldtre","•","一、摘要","七、实验","三、贡献","三个task：","个句子（使用","个用于伴随","个节点和","个蕴涵步骤，包含","中检索","为这项任务定义和训练称为","二、","五、数据集","作为查询从","使用","使用最先进的生成模型基线结果表明可以生成合理树，特别是当提供必要的原始事实作为模型输入时（导致","六、模型构建","包含","受","四、综述","在","太大而无法直接输入到","完整的语料库。","对于需要推理的问题，本文的重点，有时将解释视为导致答案的步骤链（通常是句子）。因为众包这样的链很困难，现有的数据集通常会简化任务，例如，收集支持答案的句子而不是它们如何组合，和/或主要集中在单跳（长度为","对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c)","对的多步蕴涵树，使用专家注释器构建，是同类数据集中的首个。","将解释表述为多步骤、多前提的文本蕴涵。","年）。这些方法主要设计用于“查找”问题的答案，以解释在语料库中何处/如何找到答案。","年），或用于定位答案的句法模式（ye","年；hancock","库中的默认超参数（包括优化器）对训练集上的模型进行微调。我们使用最大的","所示，由单个多前提文本蕴涵","是","棵树的完整数据集，包括一系列小型和大型多步蕴涵问题。","模型输入是前面描述的三个任务的模型输入，除了插入检索步骤的任务3（语料库","模型，针对","步骤组成，尽管有许多可用的单步蕴涵数据集，但是目前不存在多步蕴涵数据集，","步（批量大小","生成模型，采用早期技术来生成演绎证明。发现这些模型部分地解决了数据集，并具有泛化到其他领域的迹象。因此，的贡献是：","的上下文中，有多种解释/理由的概念，包括显示权威的、有答案的句子（perez","的多步蕴涵树数据集，支持基于蕴涵的解释。每棵树平均包含","的树的错误为零）。还提出迹象表明，entailmentbank","的生成模型（每个任务一个），称为","的蕴涵树。","等人，2016）、综合连接问题和答案的短语（rajani","等人，2018","等人，2019","等人，2019）、段落上的注意力图（seo","等人，2019），但它们很少从什么解释推理链已知答案，即在给出证据的情况下，答案是如何得出的——这项工作的目标。","等人，2020","系统中的“all","给定一个假设（问题+答案），定义了三个越来越难的解释任务：为给定的","训练的模型可以推广到其他领域。","训练的相关句子排序器），并将它们输入到模型中。所有情况下的输出都是解释qa","语料库加上注释器创建的所有其他科学事实；所需的输出都是有效的蕴涵树","通常从最底部的叶节点开始，从它们中创作中间结论，然后逐步在树的更高层次上工作，直到他们创作出直接回答问题的结论。","，这是第一个包含多步蕴涵树的数据集。"],"Chapter4/METGEN论文学习笔记.html":["answer","base","entail","explan","framework","gener","metgen:","metgen论文学习笔记","modul","tree","一、摘要","之前解释qa的相关方法与技术：","二、综述","在段落上显示一个注意力地图","多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设【转去看了看多前提蕴涵树的相关论文】","学习从知识到预测答案的推理链—>帮助构建可解释的qa问答系统。【方法】用由多个隐含步骤组成的隐含树来解释答案。【现状】目前的工作建议使用端到端生成模型来生成蕴涵树，但生成的树中的步骤不受约束，而且可能不可靠。【方法/创新】本文提出了一个基于模块的蕴涵树生成枚举框架metgen，它具有“多个模块和一个推理控制器”。给定一个问题和一些支持知识，metgen可以通过对单独的模块进行单步隐含，用控制器选择推理流，迭代生成隐含树。由于每个模块都被引导去执行一种特定类型的隐含推理，因此由metgen生成的步骤更加可靠和有效。【结果】在标准基准测试上的实验结果表明，metgen仅使用9%的参数就可以优于以前的最先进的模型。","总结：通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。","给出一个文本证据的片段","选择支撑答案的句子"],"技术框架/技术框架.html":["llm模型：","①选取某一领域","②继续训练部分：无监督学习","③关键：指令微调部分：构建高质量的领域问答数据集。","④对齐微调：符合用户价值观和说话习惯等（主要借鉴lmflow项目尝试开展，不是必做项）","二、解释","分为两类：针对单篇事实性问题进行总结的问答数据集（bing等chatpdf工具进行文档提问）","技术框架整体图","更为宽泛、总结性的跨篇章问答数据集（gpt自生成）","本地领域知识库部分：由于token长度限制问题，所以需要将多个pdf进行拆分成段落（segment），然后利用langchain+faiss向量库建立向量数据库和文档索引。","毕设技术框架","用户提问部分：将用户提出的query进行同义词+历史信息扩充，然后选取目前词嵌入效果最佳的相关embedding模型进行词向量建模，将得到的词向量与本地知识库的向量数据库进行匹配检索，将匹配结果进行聚类，扩充得到与该问题相关的更全回答信息，并基于相似度进行排序得到喂给llm模型的信息。","（1）input：prompt[用户提问+相关检索信息]","（2）output：带有标引信息的回答结果","（3）垂直领域llm模型微调部分：根据已有的开源微调项目进行改动、参考"]},"length":18},"tokenStore":{"root":{"0":{"0":{"3":{"docs":{},"调":{"docs":{},"优":{"docs":{},"（":{"docs":{},"即":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"）":{"docs":{},"和":{"docs":{},"不":{"docs":{},"调":{"docs":{},"优":{"docs":{},"（":{"docs":{},"即":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"）":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"更":{"docs":{},"高":{"docs":{},"；":{"7":{"docs":{},"b":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"5":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{},".":{"0":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"4":{"2":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}},"docs":{}},"docs":{}},":":{"4":{"0":{"docs":{},":":{"0":{"2":{"docs":{},".":{"1":{"3":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}},"1":{"0":{"0":{"0":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}},"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.03488372093023256}}},"5":{"1":{"4":{"5":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},".":{"3":{"docs":{},".":{"0":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"docs":{}}},"docs":{}}},"1":{"4":{"5":{"9":{"9":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"2":{"8":{"docs":{},"～":{"1":{"2":{"7":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"h":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"b":{"docs":{},"生":{"docs":{},"成":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"3":{"0":{"0":{"0":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"4":{"docs":{},"]":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"4":{"3":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}},"docs":{}},"5":{"8":{"5":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}},"docs":{}},"docs":{}},"6":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}},"8":{"4":{"0":{"docs":{},"个":{"docs":{},"随":{"docs":{},"机":{"docs":{},"选":{"docs":{},"择":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"（":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"中":{"docs":{},"的":{"7":{"7":{"8":{"7":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"）":{"docs":{},"总":{"docs":{},"共":{"docs":{},"包":{"docs":{},"括":{"5":{"8":{"8":{"1":{"docs":{},"个":{"docs":{},"离":{"docs":{},"散":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"。":{"docs":{},"总":{"docs":{},"的":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"大":{"docs":{},"约":{"6":{"0":{"0":{"docs":{},"（":{"docs":{},"带":{"docs":{},"薪":{"docs":{},"）":{"docs":{},"工":{"docs":{},"作":{"docs":{},"小":{"docs":{},"时":{"docs":{},"用":{"docs":{},"于":{"docs":{},"构":{"docs":{},"建":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{},"平":{"docs":{},"均":{"docs":{},"而":{"docs":{},"言":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"包":{"docs":{},"括":{"docs":{},"跨":{"docs":{},"越":{"3":{"docs":{},".":{"2":{"docs":{},"个":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"的":{"7":{"docs":{},".":{"6":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"通":{"docs":{},"常":{"docs":{},"涉":{"docs":{},"及":{"3":{"docs":{},"个":{"docs":{},"事":{"docs":{},"实":{"docs":{},"（":{"docs":{},"两":{"docs":{},"片":{"docs":{},"叶":{"docs":{},"子":{"docs":{},"，":{"docs":{},"组":{"docs":{},"合":{"docs":{},"起":{"docs":{},"来":{"docs":{},"得":{"docs":{},"出":{"docs":{},"一":{"docs":{},"个":{"docs":{},"结":{"docs":{},"论":{"docs":{},"）":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"9":{"docs":{},".":{"9":{"8":{"2":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.06666666666666667},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.005488474204171241},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},".":{"2":{"4":{"9":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"3":{"docs":{},"g":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"b":{"docs":{},"的":{"docs":{},"奖":{"docs":{},"励":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"以":{"docs":{},"对":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"进":{"docs":{},"行":{"docs":{},"评":{"docs":{},"分":{"docs":{},"：":{"docs":{},"对":{"docs":{},"一":{"docs":{},"个":{"docs":{},"提":{"docs":{},"示":{"docs":{},"和":{"docs":{},"k":{"docs":{},"个":{"docs":{},"回":{"docs":{},"复":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186},"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}},"今":{"docs":{},"天":{"docs":{},"的":{"docs":{},"解":{"docs":{},"释":{"docs":{},"系":{"docs":{},"统":{"docs":{},"擅":{"docs":{},"长":{"docs":{},"为":{"docs":{},"答":{"docs":{},"案":{"docs":{},"提":{"docs":{},"供":{"docs":{},"一":{"docs":{},"两":{"docs":{},"句":{"docs":{},"话":{"docs":{},"的":{"docs":{},"支":{"docs":{},"持":{"docs":{},"证":{"docs":{},"据":{"docs":{},"（":{"docs":{},"“":{"docs":{},"基":{"docs":{},"本":{"docs":{},"原":{"docs":{},"理":{"docs":{},"”":{"docs":{},"）":{"docs":{},"（":{"docs":{},"d":{"docs":{},"e":{"docs":{},"y":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"开":{"docs":{},"放":{"docs":{},"域":{"docs":{},"文":{"docs":{},"本":{"docs":{},"问":{"docs":{},"答":{"docs":{},"的":{"docs":{},"背":{"docs":{},"景":{"docs":{},"下":{"docs":{},"，":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"显":{"docs":{},"示":{"docs":{},"从":{"docs":{},"已":{"docs":{},"知":{"docs":{},"到":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"线":{"docs":{},"来":{"docs":{},"解":{"docs":{},"释":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"简":{"docs":{},"单":{"docs":{},"地":{"docs":{},"显":{"docs":{},"示":{"docs":{},"文":{"docs":{},"本":{"docs":{},"证":{"docs":{},"据":{"docs":{},"的":{"docs":{},"片":{"docs":{},"段":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"、":{"docs":{},"执":{"docs":{},"行":{"docs":{},"部":{"docs":{},"署":{"docs":{},"脚":{"docs":{},"本":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"模":{"docs":{},"型":{"docs":{},"文":{"docs":{},"件":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"训":{"docs":{},"练":{"docs":{},"脚":{"docs":{},"本":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"+":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"方":{"docs":{},"案":{"docs":{},"的":{"docs":{},"必":{"docs":{},"备":{"docs":{},"条":{"docs":{},"件":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"方":{"docs":{},"案":{"docs":{},"的":{"docs":{},"必":{"docs":{},"备":{"docs":{},"条":{"docs":{},"件":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"载":{"docs":{},"官":{"docs":{},"方":{"docs":{},"代":{"docs":{},"码":{"docs":{},"，":{"docs":{},"安":{"docs":{},"装":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"的":{"docs":{},"库":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},",":{"8":{"4":{"0":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}}},"docs":{}},"docs":{}},"docs":{}}},"2":{"0":{"0":{"0":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}},"docs":{}},"4":{"8":{"docs":{},"）":{"docs":{},"计":{"docs":{},"算":{"docs":{},"中":{"docs":{},"间":{"docs":{},"变":{"docs":{},"量":{"docs":{},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}},"docs":{}},"docs":{}},"1":{"1":{"docs":{},".":{"3":{"docs":{},"k":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"docs":{}}},"docs":{}},"4":{"0":{"2":{"docs":{},".":{"1":{"3":{"2":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{},"h":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"g":{"docs":{},"b":{"docs":{},"内":{"docs":{},"存":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"5":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},".":{"3":{"docs":{},"g":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"docs":{}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.06666666666666667},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.007683863885839737},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}},".":{"7":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"对":{"docs":{},"特":{"docs":{},"定":{"docs":{},"法":{"docs":{},"律":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"z":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"w":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"q":{"docs":{},"a":{"docs":{},"s":{"docs":{},"p":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"文":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"以":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"生":{"docs":{},"成":{"docs":{},"解":{"docs":{},"释":{"docs":{},"，":{"docs":{},"如":{"docs":{},"图":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"以":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"生":{"docs":{},"成":{"docs":{},"解":{"docs":{},"释":{"docs":{},"，":{"docs":{},"即":{"docs":{},"多":{"docs":{},"前":{"docs":{},"提":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"，":{"docs":{},"从":{"docs":{},"已":{"docs":{},"知":{"docs":{},"的":{"docs":{},"事":{"docs":{},"实":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"论":{"docs":{},"，":{"docs":{},"到":{"docs":{},"感":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"的":{"docs":{},"假":{"docs":{},"设":{"docs":{},"（":{"docs":{},"即":{"docs":{},"问":{"docs":{},"题":{"docs":{},"+":{"docs":{},"答":{"docs":{},"案":{"docs":{},"）":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.008781558726673985}}},"、":{"docs":{},"开":{"docs":{},"始":{"docs":{},"训":{"docs":{},"练":{"docs":{},",":{"docs":{},"后":{"docs":{},"台":{"docs":{},"执":{"docs":{},"行":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}},"执":{"docs":{},"行":{"docs":{},"评":{"docs":{},"测":{"docs":{},"脚":{"docs":{},"本":{"docs":{},"，":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"查":{"docs":{},"看":{"docs":{},"部":{"docs":{},"署":{"docs":{},"脚":{"docs":{},"本":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"下":{"docs":{},"载":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"后":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"结":{"docs":{},"果":{"docs":{},"文":{"docs":{},"件":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}},"docs":{}}}}}},"运":{"docs":{},"行":{"docs":{},"部":{"docs":{},"署":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}},"docs":{}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}},"分":{"docs":{},"钟":{"docs":{},"，":{"docs":{},"实":{"docs":{},"在":{"docs":{},"是":{"docs":{},"太":{"docs":{},"慢":{"docs":{},"了":{"docs":{},"，":{"docs":{},"基":{"docs":{},"本":{"docs":{},"不":{"docs":{},"适":{"docs":{},"合":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{},"有":{"docs":{},"机":{"docs":{},"会":{"docs":{},"还":{"docs":{},"是":{"docs":{},"搞":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"吧":{"docs":{},"！":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"秒":{"docs":{},"即":{"docs":{},"可":{"docs":{},"获":{"docs":{},"得":{"docs":{},"结":{"docs":{},"果":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"）":{"docs":{},"链":{"docs":{},"上":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"里":{"docs":{},"，":{"docs":{},"推":{"docs":{},"广":{"docs":{},"到":{"docs":{},"需":{"docs":{},"要":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}},"3":{"0":{"0":{"0":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.007683863885839737}},"\"":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"，":{"docs":{},"训":{"docs":{},"练":{"4":{"0":{"docs":{},"分":{"docs":{},"钟":{"docs":{},"完":{"docs":{},"成":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}},"docs":{}},"docs":{}}}}},"docs":{}},"docs":{}},"2":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"g":{"docs":{},"b":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}},"5":{"docs":{},"%":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}},"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.06666666666666667},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},".":{"3":{"0":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"docs":{}},"5":{"docs":{},"和":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"为":{"docs":{},"了":{"docs":{},"用":{"docs":{},"这":{"docs":{},"种":{"docs":{},"技":{"docs":{},"能":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"创":{"docs":{},"建":{"docs":{},"了":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}},"因":{"docs":{},"此":{"docs":{},"本":{"docs":{},"文":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"贡":{"docs":{},"献":{"docs":{},"是":{"docs":{},"构":{"docs":{},"建":{"docs":{},"了":{"docs":{},"这":{"docs":{},"样":{"docs":{},"一":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"称":{"docs":{},"为":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{},"例":{"docs":{},"，":{"docs":{},"以":{"docs":{},"下":{"docs":{},"是":{"docs":{},"一":{"docs":{},"些":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.031833150384193196}}},"、":{"docs":{},"查":{"docs":{},"看":{"docs":{},"评":{"docs":{},"测":{"docs":{},"脚":{"docs":{},"本":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"训":{"docs":{},"练":{"docs":{},"结":{"docs":{},"束":{"docs":{},"，":{"docs":{},"查":{"docs":{},"看":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"对":{"docs":{},"话":{"docs":{},"生":{"docs":{},"成":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}},"直":{"docs":{},"接":{"docs":{},"调":{"docs":{},"成":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}},"4":{"0":{"9":{"6":{"docs":{},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"docs":{}},"docs":{},"k":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}},"8":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.03731343283582089},"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.044444444444444446},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},".":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"本":{"docs":{},"文":{"docs":{},"还":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"上":{"docs":{},"定":{"docs":{},"义":{"docs":{},"了":{"docs":{},"三":{"docs":{},"个":{"docs":{},"解":{"docs":{},"释":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"即":{"docs":{},"：":{"docs":{},"为":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"的":{"5":{"docs":{},".":{"2":{"docs":{},"万":{"docs":{},"条":{"docs":{},"英":{"docs":{},"文":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}},"docs":{}}},"docs":{},"使":{"docs":{},"用":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}},"的":{"5":{"docs":{},".":{"2":{"docs":{},"万":{"docs":{},"条":{"docs":{},"中":{"docs":{},"文":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}},"docs":{}}},"docs":{},"案":{"docs":{},"例":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}},"结":{"docs":{},"果":{"docs":{},"而":{"docs":{},"言":{"docs":{},"，":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"后":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"比":{"docs":{},"中":{"docs":{},"文":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"表":{"docs":{},"现":{"docs":{},"得":{"docs":{},"更":{"docs":{},"好":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"让":{"docs":{},"模":{"docs":{},"型":{"docs":{},"根":{"docs":{},"据":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"提":{"docs":{},"供":{"docs":{},"指":{"docs":{},"令":{"docs":{},"来":{"docs":{},"执":{"docs":{},"行":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"具":{"docs":{},"体":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"案":{"docs":{},"例":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"将":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"、":{"docs":{},"查":{"docs":{},"看":{"docs":{},"训":{"docs":{},"练":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"文":{"docs":{},"件":{"docs":{},"及":{"docs":{},"模":{"docs":{},"型":{"docs":{},"结":{"docs":{},"果":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}},"评":{"docs":{},"测":{"docs":{},"结":{"docs":{},"果":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}},"(":{"7":{"docs":{},"b":{"docs":{},")":{"docs":{},"和":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}},"docs":{}},")":{"docs":{},"进":{"docs":{},"行":{"docs":{},"比":{"docs":{},"较":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}},",":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}},"/":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}},"为":{"docs":{},"每":{"docs":{},"个":{"docs":{},"回":{"docs":{},"复":{"docs":{},"提":{"docs":{},"供":{"docs":{},"一":{"docs":{},"个":{"1":{"docs":{},"到":{"1":{"0":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"评":{"docs":{},"分":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}},"创":{"docs":{},"建":{"docs":{},"了":{"docs":{},"对":{"docs":{},"比":{"docs":{},"数":{"docs":{},"据":{"docs":{},"；":{"docs":{},"为":{"docs":{},"了":{"docs":{},"评":{"docs":{},"估":{"docs":{},"数":{"docs":{},"据":{"docs":{},"质":{"docs":{},"量":{"docs":{},"，":{"docs":{},"研":{"docs":{},"究":{"docs":{},"人":{"docs":{},"员":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}},"对":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"进":{"docs":{},"行":{"docs":{},"指":{"docs":{},"令":{"docs":{},"调":{"docs":{},"优":{"docs":{},"，":{"docs":{},"往":{"docs":{},"往":{"docs":{},"比":{"docs":{},"用":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}},"两":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"质":{"docs":{},"量":{"docs":{},"进":{"docs":{},"行":{"docs":{},"评":{"docs":{},"分":{"docs":{},"，":{"docs":{},"评":{"docs":{},"分":{"docs":{},"范":{"docs":{},"围":{"docs":{},"从":{"1":{"docs":{},"到":{"1":{"0":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"结":{"docs":{},"果":{"docs":{},"与":{"docs":{},"其":{"docs":{},"他":{"docs":{},"强":{"docs":{},"竞":{"docs":{},"争":{"docs":{},"模":{"docs":{},"型":{"docs":{},"(":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"提":{"docs":{},"供":{"docs":{},"从":{"1":{"docs":{},"到":{"1":{"0":{"docs":{},"的":{"docs":{},"评":{"docs":{},"分":{"docs":{},"，":{"docs":{},"并":{"docs":{},"对":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}},"是":{"docs":{},"在":{"docs":{},"比":{"docs":{},"中":{"docs":{},"文":{"docs":{},"更":{"docs":{},"丰":{"docs":{},"富":{"docs":{},"的":{"docs":{},"英":{"docs":{},"文":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"中":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"具":{"docs":{},"有":{"docs":{},"更":{"docs":{},"强":{"docs":{},"的":{"docs":{},"英":{"docs":{},"文":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"评":{"docs":{},"估":{"docs":{},"不":{"docs":{},"同":{"docs":{},"聊":{"docs":{},"天":{"docs":{},"机":{"docs":{},"器":{"docs":{},"人":{"docs":{},"模":{"docs":{},"型":{"docs":{},"对":{"8":{"0":{"docs":{},"个":{"docs":{},"未":{"docs":{},"见":{"docs":{},"过":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"所":{"docs":{},"生":{"docs":{},"成":{"docs":{},"回":{"docs":{},"答":{"docs":{},"的":{"docs":{},"质":{"docs":{},"量":{"docs":{},"，":{"docs":{},"从":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"收":{"docs":{},"集":{"docs":{},"回":{"docs":{},"复":{"docs":{},"，":{"docs":{},"并":{"docs":{},"从":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{},"研":{"docs":{},"究":{"docs":{},"中":{"docs":{},"获":{"docs":{},"得":{"docs":{},"其":{"docs":{},"他":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"要":{"docs":{},"求":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"自":{"docs":{},"动":{"docs":{},"生":{"docs":{},"成":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"指":{"docs":{},"令":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"中":{"docs":{},"文":{"docs":{},"回":{"docs":{},"答":{"docs":{},"这":{"docs":{},"些":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"并":{"docs":{},"以":{"docs":{},"此":{"docs":{},"建":{"docs":{},"立":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"等":{"docs":{},"大":{"docs":{},"型":{"docs":{},"商":{"docs":{},"业":{"docs":{},"聊":{"docs":{},"天":{"docs":{},"机":{"docs":{},"器":{"docs":{},"人":{"docs":{},"相":{"docs":{},"比":{"docs":{},"，":{"docs":{},"仍":{"docs":{},"有":{"docs":{},"差":{"docs":{},"距":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"动":{"docs":{},"评":{"docs":{},"估":{"docs":{},"：":{"docs":{},"受":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}},"！":{"docs":{},"微":{"docs":{},"软":{"docs":{},"开":{"docs":{},"源":{"docs":{},"微":{"docs":{},"调":{"docs":{},"指":{"docs":{},"令":{"docs":{},"集":{"docs":{},"：":{"docs":{},"效":{"docs":{},"果":{"docs":{},"不":{"docs":{},"输":{"docs":{},"原":{"docs":{},"版":{"docs":{},"，":{"docs":{},"中":{"docs":{},"英":{"docs":{},"双":{"docs":{},"语":{"docs":{},"都":{"docs":{},"能":{"docs":{},"用":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"注":{"docs":{},"意":{"docs":{},"到":{"docs":{},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"5":{"0":{"4":{"9":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}},"docs":{}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"k":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.046511627906976744}}}},"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},".":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"研":{"docs":{},"究":{"docs":{},"结":{"docs":{},"果":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"docs":{},"强":{"docs":{},"大":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"部":{"docs":{},"分":{"docs":{},"解":{"docs":{},"决":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"特":{"docs":{},"别":{"docs":{},"是":{"docs":{},"当":{"docs":{},"相":{"docs":{},"关":{"docs":{},"句":{"docs":{},"子":{"docs":{},"包":{"docs":{},"含":{"docs":{},"在":{"docs":{},"输":{"docs":{},"入":{"docs":{},"中":{"docs":{},"时":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"有":{"docs":{},"泛":{"docs":{},"化":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"迹":{"docs":{},"象":{"docs":{},"。":{"docs":{},"这":{"docs":{},"项":{"docs":{},"工":{"docs":{},"作":{"docs":{},"意":{"docs":{},"义":{"docs":{},"重":{"docs":{},"大":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"它":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"一":{"docs":{},"种":{"docs":{},"新":{"docs":{},"型":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"（":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"）":{"docs":{},"和":{"docs":{},"基":{"docs":{},"线":{"docs":{},"，":{"docs":{},"为":{"docs":{},"社":{"docs":{},"区":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"一":{"docs":{},"条":{"docs":{},"新":{"docs":{},"途":{"docs":{},"径":{"docs":{},"，":{"docs":{},"以":{"docs":{},"产":{"docs":{},"生":{"docs":{},"更":{"docs":{},"丰":{"docs":{},"富":{"docs":{},"、":{"docs":{},"更":{"docs":{},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"解":{"docs":{},"释":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"重":{"docs":{},"点":{"docs":{},"是":{"docs":{},"生":{"docs":{},"成":{"docs":{},"推":{"docs":{},"理":{"docs":{},"线":{"docs":{},"，":{"docs":{},"以":{"docs":{},"显":{"docs":{},"示":{"docs":{},"证":{"docs":{},"据":{"docs":{},"如":{"docs":{},"何":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"决":{"docs":{},"定":{"docs":{},"将":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"部":{"docs":{},"分":{"docs":{},"显":{"docs":{},"示":{"docs":{},"给":{"docs":{},"用":{"docs":{},"户":{"docs":{},"。":{"docs":{},"这":{"docs":{},"使":{"docs":{},"能":{"docs":{},"够":{"docs":{},"将":{"docs":{},"两":{"docs":{},"个":{"docs":{},"解":{"docs":{},"释":{"docs":{},"要":{"docs":{},"求":{"docs":{},"，":{"docs":{},"即":{"docs":{},"推":{"docs":{},"导":{"docs":{},"的":{"docs":{},"正":{"docs":{},"确":{"docs":{},"性":{"docs":{},"与":{"docs":{},"效":{"docs":{},"用":{"docs":{},"分":{"docs":{},"开":{"docs":{},"，":{"docs":{},"使":{"docs":{},"能":{"docs":{},"够":{"docs":{},"以":{"docs":{},"更":{"docs":{},"客":{"docs":{},"观":{"docs":{},"的":{"docs":{},"度":{"docs":{},"量":{"docs":{},"评":{"docs":{},"估":{"docs":{},"推":{"docs":{},"导":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"6":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.007683863885839737}}}},"2":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"3":{"8":{"2":{"3":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}},"docs":{}},"3":{"2":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"9":{"1":{"2":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"4":{"0":{"5":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"1":{"3":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"2":{"5":{"7":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"5":{"5":{"5":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"6":{"2":{"2":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"7":{"0":{"3":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"8":{"8":{"0":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}},"5":{"1":{"0":{"7":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"7":{"3":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.005488474204171241}}}},"docs":{}},"docs":{}},"2":{"0":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"3":{"4":{"7":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"8":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"4":{"2":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"5":{"0":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"9":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"6":{"0":{"6":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"2":{"6":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"5":{"6":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"7":{"0":{"6":{"1":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"8":{"5":{"5":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"9":{"4":{"1":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"7":{"6":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"b":{"docs":{"./":{"ref":"./","tf":0.034482758620689655},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":5.023051591657519},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.07434944237918216}},".":{"docs":{},"m":{"docs":{},"d":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":5}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},":":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}},"*":{"1":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"2":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"4":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"8":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}},"，":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"m":{"docs":{},"w":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}}}},"然":{"docs":{},"后":{"docs":{},"通":{"docs":{},"过":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"\"":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"/":{"docs":{},"p":{"docs":{},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"/":{"docs":{},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"准":{"docs":{},"备":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"其":{"docs":{},"任":{"docs":{},"务":{"docs":{},"为":{"docs":{},"根":{"docs":{},"据":{"docs":{},"输":{"docs":{},"入":{"docs":{},"（":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"生":{"docs":{},"成":{"docs":{},"一":{"docs":{},"段":{"docs":{},"广":{"docs":{},"告":{"docs":{},"词":{"docs":{},"（":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"）":{"docs":{},"。":{"docs":{},"下":{"docs":{},"载":{"docs":{},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"从":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"训":{"docs":{},"练":{"docs":{},"完":{"docs":{},"整":{"docs":{},"流":{"docs":{},"程":{"docs":{},"详":{"docs":{},"解":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}},"—":{"docs":{},"—":{"docs":{},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"+":{"6":{"docs":{},"g":{"docs":{},"b":{"docs":{},"显":{"docs":{},"卡":{"docs":{},"版":{"docs":{},"本":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"本":{"docs":{},"地":{"docs":{},"部":{"docs":{},"署":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"依":{"docs":{},"赖":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"有":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"且":{"docs":{},"高":{"docs":{},"于":{"6":{"docs":{},"g":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"建":{"docs":{},"议":{"docs":{},"部":{"docs":{},"署":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"，":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"有":{"3":{"docs":{},"个":{"docs":{},"版":{"docs":{},"本":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"，":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}},"docs":{}},"的":{"docs":{},"运":{"docs":{},"行":{"docs":{},"需":{"docs":{},"要":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"配":{"docs":{},"置":{"docs":{},"文":{"docs":{},"件":{"docs":{},"，":{"docs":{},"即":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"等":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"比":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"稍":{"docs":{},"微":{"docs":{},"麻":{"docs":{},"烦":{"docs":{},"一":{"docs":{},"点":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"的":{"docs":{},"编":{"docs":{},"译":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"安":{"docs":{},"装":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}},".":{"5":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"6":{"7":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"docs":{}},"g":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"+":{"6":{"docs":{},"g":{"docs":{},"b":{"docs":{},"+":{"1":{"2":{"docs":{},"g":{"docs":{},"b":{"docs":{},"+":{"1":{"docs":{},".":{"3":{"docs":{},"g":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"docs":{}}},"docs":{}}}}},"docs":{}},"docs":{}}}}},"docs":{}}}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.005488474204171241}}}},"7":{"0":{"9":{"3":{"6":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"8":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"1":{"3":{"1":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"6":{"8":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"2":{"1":{"9":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"2":{"6":{"5":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"3":{"4":{"1":{"2":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"6":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"9":{"4":{"2":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"4":{"1":{"9":{"7":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"5":{"8":{"9":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"7":{"2":{"5":{"7":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"8":{"5":{"9":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"b":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.03125},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"由":{"docs":{},"哈":{"docs":{},"尔":{"docs":{},"滨":{"docs":{},"工":{"docs":{},"业":{"docs":{},"大":{"docs":{},"学":{"docs":{},"社":{"docs":{},"会":{"docs":{},"计":{"docs":{},"算":{"docs":{},"与":{"docs":{},"信":{"docs":{},"息":{"docs":{},"检":{"docs":{},"索":{"docs":{},"研":{"docs":{},"究":{"docs":{},"中":{"docs":{},"心":{"docs":{},"健":{"docs":{},"康":{"docs":{},"智":{"docs":{},"能":{"docs":{},"组":{"docs":{},"完":{"docs":{},"成":{"docs":{},"。":{"docs":{},"项":{"docs":{},"目":{"docs":{},"组":{"docs":{},"通":{"docs":{},"过":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"'":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},".":{"0":{"8":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"1":{"2":{"1":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"8":{"0":{"docs":{},"g":{"docs":{},"b":{"docs":{},"显":{"docs":{},"卡":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"训":{"docs":{},"练":{"docs":{},"总":{"docs":{},"轮":{"docs":{},"次":{"1":{"0":{"docs":{},"轮":{"docs":{},"，":{"docs":{},"耗":{"docs":{},"时":{"docs":{},"大":{"docs":{},"约":{"2":{"docs":{},"h":{"1":{"7":{"docs":{},"m":{"docs":{},"。":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"=":{"1":{"2":{"8":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"显":{"docs":{},"存":{"docs":{},"占":{"docs":{},"用":{"docs":{},"了":{"4":{"0":{"docs":{},"g":{"docs":{},"左":{"docs":{},"右":{"docs":{},"。":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"3":{"0":{"9":{"0":{"docs":{},"/":{"4":{"0":{"9":{"0":{"docs":{},"显":{"docs":{},"卡":{"docs":{},"，":{"docs":{},"显":{"docs":{},"存":{"docs":{},"在":{"2":{"4":{"docs":{},"g":{"docs":{},"b":{"docs":{},"以":{"docs":{},"上":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"获":{"docs":{},"得":{"docs":{},"较":{"docs":{},"好":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"docs":{}},"docs":{}}},"docs":{}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}},"1":{"5":{"4":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"3":{"3":{"4":{"3":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"5":{"4":{"2":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}},"docs":{}},"docs":{}},"7":{"0":{"1":{"9":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"8":{"3":{"4":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.010976948408342482}},".":{"5":{"9":{"7":{"1":{"3":{"4":{"8":{"4":{"7":{"0":{"0":{"5":{"2":{"0":{"8":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"）":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"，":{"docs":{},"选":{"docs":{},"择":{"docs":{},"开":{"docs":{},"发":{"docs":{},"分":{"docs":{},"数":{"docs":{},"最":{"docs":{},"高":{"docs":{},"的":{"docs":{},"检":{"docs":{},"查":{"docs":{},"点":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}},"docs":{},"(":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},")":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"k":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"l":{"docs":{},"d":{"docs":{},")":{"docs":{},"【":{"docs":{},"开":{"docs":{},"源":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"套":{"docs":{},"壳":{"docs":{},"】":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},")":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"y":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}},"l":{"docs":{},"m":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},")":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},")":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"c":{"6":{"docs":{},"h":{"1":{"2":{"docs":{},")":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"docs":{}},"docs":{}}},"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},")":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}},"r":{"docs":{},"a":{"docs":{},"j":{"docs":{},"p":{"docs":{},"u":{"docs":{},"r":{"docs":{},"k":{"docs":{},"a":{"docs":{},"r":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},")":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}},"a":{"1":{"0":{"0":{"docs":{},"（":{"8":{"0":{"docs":{},"g":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{"./":{"ref":"./","tf":0.034482758620689655},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":3.419270833333333},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"和":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"，":{"docs":{},"但":{"docs":{},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"2":{"0":{"docs":{},"k":{"docs":{},"个":{"docs":{},"代":{"docs":{},"码":{"docs":{},"生":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"生":{"docs":{},"成":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}}}}},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"l":{"docs":{},".":{"docs":{},"g":{"docs":{},"z":{"docs":{},"]":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}},"s":{"docs":{},"k":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}},"n":{"docs":{},"s":{"docs":{},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}},"s":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.019230769230769232}}}}}}}},"o":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"a":{"docs":{},"l":{"docs":{},"y":{"docs":{},"s":{"docs":{},"i":{"docs":{},"s":{"docs":{},"：":{"docs":{},"确":{"docs":{},"定":{"docs":{},"了":{"6":{"docs":{},"种":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"高":{"docs":{},"级":{"docs":{},"推":{"docs":{},"理":{"docs":{},"类":{"docs":{},"别":{"docs":{},"：":{"docs":{},"替":{"docs":{},"代":{"docs":{},"类":{"docs":{},"型":{"docs":{},"是":{"docs":{},"指":{"docs":{},"需":{"docs":{},"要":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"执":{"docs":{},"行":{"docs":{},"分":{"docs":{},"类":{"docs":{},"、":{"docs":{},"子":{"docs":{},"项":{"docs":{},"或":{"docs":{},"其":{"docs":{},"他":{"docs":{},"形":{"docs":{},"式":{"docs":{},"的":{"docs":{},"链":{"docs":{},"接":{"docs":{},"的":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"链":{"docs":{},"接":{"docs":{},"将":{"docs":{},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"句":{"docs":{},"子":{"docs":{},"中":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"实":{"docs":{},"体":{"docs":{},"替":{"docs":{},"换":{"docs":{},"为":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"实":{"docs":{},"体":{"docs":{},"。":{"docs":{},"从":{"docs":{},"规":{"docs":{},"则":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"中":{"docs":{},"进":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"指":{"docs":{},"定":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"句":{"docs":{},"子":{"docs":{},"的":{"docs":{},"特":{"docs":{},"定":{"docs":{},"规":{"docs":{},"则":{"docs":{},"应":{"docs":{},"用":{"docs":{},"于":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"句":{"docs":{},"子":{"docs":{},"。":{"docs":{},"分":{"docs":{},"析":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"docs":{},"大":{"docs":{},"约":{"docs":{},"三":{"docs":{},"分":{"docs":{},"之":{"docs":{},"一":{"docs":{},"（":{"3":{"3":{"docs":{},"%":{"docs":{},"）":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"需":{"docs":{},"要":{"docs":{},"应":{"docs":{},"用":{"docs":{},"特":{"docs":{},"定":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"规":{"docs":{},"则":{"docs":{},"才":{"docs":{},"能":{"docs":{},"完":{"docs":{},"成":{"docs":{},"。":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"的":{"docs":{},"规":{"docs":{},"范":{"docs":{},"或":{"docs":{},"连":{"docs":{},"接":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"将":{"docs":{},"两":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"事":{"docs":{},"实":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"合":{"docs":{},"并":{"docs":{},"到":{"docs":{},"单":{"docs":{},"个":{"docs":{},"输":{"docs":{},"出":{"docs":{},"事":{"docs":{},"实":{"docs":{},"中":{"docs":{},"。":{"docs":{},"不":{"docs":{},"太":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"从":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"属":{"docs":{},"性":{"docs":{},"推":{"docs":{},"断":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"类":{"docs":{},"、":{"docs":{},"继":{"docs":{},"承":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"属":{"docs":{},"性":{"docs":{},"或":{"docs":{},"确":{"docs":{},"定":{"docs":{},"顺":{"docs":{},"序":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"顺":{"docs":{},"序":{"docs":{},"。":{"docs":{},"总":{"docs":{},"的":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"该":{"docs":{},"分":{"docs":{},"析":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"docs":{},"要":{"docs":{},"成":{"docs":{},"功":{"docs":{},"完":{"docs":{},"成":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"库":{"docs":{},"中":{"docs":{},"的":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"多":{"docs":{},"种":{"docs":{},"形":{"docs":{},"式":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"p":{"docs":{},"i":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"/":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"是":{"4":{"0":{"9":{"6":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}},"文":{"docs":{},"档":{"docs":{},"，":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"有":{"docs":{},"：":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}},"提":{"docs":{},"供":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"和":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{},"根":{"docs":{},"据":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"实":{"docs":{},"体":{"docs":{},"作":{"docs":{},"为":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"p":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}}}}}},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"d":{"docs":{},"a":{"docs":{},"m":{"docs":{},"w":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"p":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"s":{"docs":{},"e":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}},"\"":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"e":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{},"'":{"docs":{},"n":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},"'":{"docs":{},"o":{"docs":{},"b":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}}}},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"c":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.018660812294182216}},")":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}},"p":{"docs":{},"t":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"。":{"docs":{},"供":{"docs":{},"开":{"docs":{},"发":{"docs":{},"人":{"docs":{},"员":{"docs":{},"使":{"docs":{},"用":{"docs":{},"很":{"docs":{},"多":{"docs":{},"公":{"docs":{},"司":{"docs":{},"、":{"docs":{},"机":{"docs":{},"构":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"模":{"docs":{},"型":{"docs":{},"快":{"docs":{},"速":{"docs":{},"构":{"docs":{},"建":{"docs":{},"定":{"docs":{},"制":{"docs":{},"化":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"【":{"docs":{},"领":{"docs":{},"域":{"docs":{},"微":{"docs":{},"调":{"docs":{},"是":{"docs":{},"重":{"docs":{},"点":{"docs":{},"】":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"1":{"0":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"生":{"docs":{},"成":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.022388059701492536}}}},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"2":{"0":{"1":{"9":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.028846153846153848},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.008781558726673985}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"=":{"docs":{},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"有":{"docs":{},"监":{"docs":{},"督":{"docs":{},"微":{"docs":{},"调":{"docs":{},"后":{"docs":{},"训":{"docs":{},"练":{"docs":{},"得":{"docs":{},"到":{"docs":{},"了":{"docs":{},"两":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"n":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}},"i":{"docs":{},"n":{"docs":{},"u":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}},"d":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}},"=":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"p":{"docs":{},"i":{"docs":{},"l":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}}}},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"s":{"docs":{},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"r":{"docs":{},"e":{"docs":{},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"d":{"docs":{},"e":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"p":{"docs":{},"u":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"允":{"docs":{},"许":{"docs":{},"更":{"docs":{},"多":{"docs":{},"内":{"docs":{},"容":{"docs":{},"适":{"docs":{},"应":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}},".":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"内":{"docs":{},"核":{"1":{"docs":{},".":{"3":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}}},"docs":{}}},"_":{"docs":{},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"=":{"0":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}},"docs":{}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"d":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}},"u":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"a":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.009879253567508232}}},"c":{"docs":{},"h":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}},"l":{"docs":{},"l":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"e":{"docs":{},"d":{"docs":{},"o":{"docs":{},"x":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}}}}}},"u":{"docs":{},"s":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},":":{"docs":{},"\\":{"docs":{},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"u":{"docs":{},"f":{"docs":{},"e":{"docs":{},"i":{"docs":{},"\\":{"docs":{},".":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"\\":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"\\":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"是":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}},"c":{"docs":{},"_":{"docs":{},"s":{"docs":{},"b":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"4":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"y":{"docs":{},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"h":{"docs":{},"e":{"docs":{},"x":{"docs":{},"a":{"docs":{},"n":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":5.040650406504065},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"b":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}},"w":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}},"v":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"，":{"docs":{},"微":{"docs":{},"调":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"耗":{"docs":{},"时":{"docs":{},"约":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}},"f":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.04819277108433735}}}}}}},"x":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"e":{"docs":{},"r":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}},"n":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"（":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}},"无":{"docs":{},"需":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"是":{"docs":{},"将":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"预":{"docs":{},"设":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"+":{"docs":{},"数":{"docs":{},"据":{"docs":{},"+":{"docs":{},"问":{"docs":{},"题":{"docs":{},"打":{"docs":{},"包":{"docs":{},"，":{"docs":{},"当":{"docs":{},"作":{"docs":{},"一":{"docs":{},"整":{"docs":{},"段":{"docs":{},"话":{"docs":{},"发":{"docs":{},"送":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"。":{"docs":{},"让":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"根":{"docs":{},"据":{"docs":{},"这":{"docs":{},"个":{"docs":{},"预":{"docs":{},"设":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"和":{"docs":{},"灌":{"docs":{},"给":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"再":{"docs":{},"加":{"docs":{},"问":{"docs":{},"题":{"docs":{},"做":{"docs":{},"回":{"docs":{},"答":{"docs":{},"。":{"docs":{},"适":{"docs":{},"合":{"docs":{},"数":{"docs":{},"据":{"docs":{},"量":{"docs":{},"超":{"docs":{},"大":{"docs":{},"且":{"docs":{},"实":{"docs":{},"时":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"一":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"作":{"docs":{},"用":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"：":{"docs":{},"从":{"docs":{},"平":{"docs":{},"均":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"l":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"7":{"0":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"是":{"docs":{},"w":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.022222222222222223}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}}},"g":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"p":{"docs":{},"t":{"3":{"docs":{},".":{"5":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}},"接":{"docs":{},"口":{"docs":{},"围":{"docs":{},"绕":{"docs":{},"医":{"docs":{},"学":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"构":{"docs":{},"建":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"设":{"docs":{},"置":{"docs":{},"了":{"docs":{},"多":{"docs":{},"种":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"形":{"docs":{},"式":{"docs":{},"来":{"docs":{},"充":{"docs":{},"分":{"docs":{},"利":{"docs":{},"用":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{},"医":{"docs":{},"学":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"围":{"docs":{},"绕":{"docs":{},"疾":{"docs":{},"病":{"docs":{},"、":{"docs":{},"药":{"docs":{},"物":{"docs":{},"、":{"docs":{},"检":{"docs":{},"查":{"docs":{},"指":{"docs":{},"标":{"docs":{},"等":{"docs":{},"构":{"docs":{},"建":{"docs":{},"，":{"docs":{},"字":{"docs":{},"段":{"docs":{},"包":{"docs":{},"括":{"docs":{},"并":{"docs":{},"发":{"docs":{},"症":{"docs":{},"，":{"docs":{},"高":{"docs":{},"危":{"docs":{},"因":{"docs":{},"素":{"docs":{},"，":{"docs":{},"组":{"docs":{},"织":{"docs":{},"学":{"docs":{},"检":{"docs":{},"查":{"docs":{},"，":{"docs":{},"临":{"docs":{},"床":{"docs":{},"症":{"docs":{},"状":{"docs":{},"，":{"docs":{},"药":{"docs":{},"物":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"，":{"docs":{},"辅":{"docs":{},"助":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"等":{"docs":{},"。":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"示":{"docs":{},"例":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"4":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"4":{"docs":{},"在":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}},"docs":{}}}}},"是":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"超":{"docs":{},"过":{"docs":{},"了":{"1":{"3":{"docs":{},"b":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}},"docs":{}},"docs":{}}}}}}}},"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.03731343283582089},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.08235294117647059},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"与":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":10}}}}}}},"（":{"docs":{},"生":{"docs":{},"成":{"docs":{},"式":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"变":{"docs":{},"压":{"docs":{},"器":{"docs":{},"）":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"大":{"docs":{},"量":{"docs":{},"文":{"docs":{},"本":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"各":{"docs":{},"种":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"微":{"docs":{},"调":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"语":{"docs":{},"言":{"docs":{},"建":{"docs":{},"模":{"docs":{},"，":{"docs":{},"问":{"docs":{},"答":{"docs":{},"和":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"。":{"docs":{},"经":{"docs":{},"过":{"docs":{},"微":{"docs":{},"调":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"取":{"docs":{},"得":{"docs":{},"了":{"docs":{},"最":{"docs":{},"先":{"docs":{},"进":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.031073446327683617}},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"部":{"docs":{},"署":{"docs":{},"很":{"docs":{},"简":{"docs":{},"单":{"docs":{},"，":{"docs":{},"上":{"docs":{},"述":{"docs":{},"两":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"完":{"docs":{},"成":{"docs":{},"之":{"docs":{},"后":{"docs":{},"即":{"docs":{},"可":{"docs":{},"运":{"docs":{},"行":{"docs":{},"。":{"docs":{},"代":{"docs":{},"码":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"是":{"docs":{},"商":{"docs":{},"业":{"docs":{},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"。":{"docs":{},"用":{"docs":{},"户":{"docs":{},"可":{"docs":{},"以":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"最":{"docs":{},"初":{"docs":{},"的":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"x":{"docs":{},"i":{"docs":{},"a":{"docs":{},"o":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"i":{"docs":{},"r":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"l":{"docs":{},"c":{"1":{"3":{"3":{"2":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"t":{"docs":{},"l":{"docs":{},"o":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"e":{"docs":{},"r":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"”":{"docs":{},"（":{"2":{"0":{"2":{"1":{"docs":{},"）":{"docs":{},"中":{"docs":{},"提":{"docs":{},"出":{"docs":{},"。":{"docs":{},"前":{"docs":{},"缀":{"docs":{},"调":{"docs":{},"整":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"学":{"docs":{},"习":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"连":{"docs":{},"续":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"在":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"将":{"docs":{},"其":{"docs":{},"添":{"docs":{},"加":{"docs":{},"到":{"docs":{},"输":{"docs":{},"入":{"docs":{},"之":{"docs":{},"前":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"优":{"docs":{},"化":{"docs":{},"这":{"docs":{},"个":{"docs":{},"连":{"docs":{},"续":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"适":{"docs":{},"应":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"而":{"docs":{},"不":{"docs":{},"修":{"docs":{},"改":{"docs":{},"底":{"docs":{},"层":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"这":{"docs":{},"节":{"docs":{},"省":{"docs":{},"了":{"docs":{},"计":{"docs":{},"算":{"docs":{},"资":{"docs":{},"源":{"docs":{},"并":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"高":{"docs":{},"效":{"docs":{},"的":{"docs":{},"精":{"docs":{},"调":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"d":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644}},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"c":{"docs":{},"u":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"c":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}},"/":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"编":{"docs":{},"译":{"docs":{},"环":{"docs":{},"境":{"docs":{},"配":{"docs":{},"置":{"docs":{},"+":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"编":{"docs":{},"译":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}},"，":{"docs":{},"下":{"docs":{},"载":{"docs":{},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"j":{"docs":{},"m":{"docs":{},"e":{"docs":{},"u":{"docs":{},"b":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"t":{"docs":{},"d":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}},"s":{"docs":{},"m":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"h":{"docs":{},"i":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"o":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}},"y":{"docs":{},"=":{"docs":{},"[":{"docs":{},"]":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"i":{"docs":{},"m":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"s":{"docs":{},"y":{"docs":{},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"/":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"/":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"/":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"/":{"docs":{},"e":{"docs":{},"x":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"/":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"2":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},".":{"docs":{},"i":{"docs":{},"p":{"docs":{},"y":{"docs":{},"n":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"8":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"_":{"docs":{},"b":{"docs":{},"n":{"docs":{},"b":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},".":{"docs":{},"i":{"docs":{},"p":{"docs":{},"y":{"docs":{},"n":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"l":{"docs":{},"o":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}},"h":{"docs":{},"u":{"docs":{},"d":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"/":{"2":{"1":{"0":{"6":{"docs":{},".":{"0":{"9":{"6":{"8":{"5":{"docs":{},".":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"/":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"/":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"/":{"docs":{},"v":{"4":{"docs":{},".":{"2":{"7":{"docs":{},".":{"2":{"docs":{},"/":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"s":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"#":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"f":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"#":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"d":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"/":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},"/":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"/":{"docs":{},"f":{"docs":{},"s":{"docs":{},"d":{"docs":{},"p":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"y":{"docs":{},"w":{"docs":{},"u":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"2":{"0":{"1":{"9":{"docs":{},"/":{"0":{"5":{"docs":{},"/":{"2":{"2":{"docs":{},"/":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"o":{"docs":{},".":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"3":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"u":{"docs":{},"d":{"docs":{},".":{"docs":{},"t":{"docs":{},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"h":{"docs":{},"u":{"docs":{},"a":{"docs":{},".":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},".":{"docs":{},"c":{"docs":{},"n":{"docs":{},"/":{"docs":{},"f":{"docs":{},"/":{"docs":{},"b":{"3":{"docs":{},"f":{"1":{"1":{"9":{"docs":{},"a":{"0":{"0":{"8":{"2":{"6":{"4":{"docs":{},"b":{"1":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"d":{"1":{"docs":{},"/":{"docs":{},"?":{"docs":{},"d":{"docs":{},"l":{"docs":{},"=":{"1":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"docs":{}}}}}}},"docs":{}}}}}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"u":{"docs":{},"g":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.01694915254237288}},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"f":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}},"'":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625}}},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"/":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}},"c":{"3":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"3":{"7":{"docs":{},"k":{"docs":{},"个":{"docs":{},"指":{"docs":{},"令":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"和":{"docs":{},"人":{"docs":{},"类":{"docs":{},"生":{"docs":{},"成":{"docs":{},"，":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"中":{"docs":{},"英":{"docs":{},"文":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}},"docs":{}},"h":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}}}},"：":{"docs":{},"假":{"docs":{},"设":{"docs":{},"；":{"docs":{},"q":{"docs":{},"：":{"docs":{},"问":{"docs":{},"题":{"docs":{},"；":{"docs":{},"a":{"docs":{},"：":{"docs":{},"回":{"docs":{},"答":{"docs":{},"；":{"docs":{},"c":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.03731343283582089},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.023529411764705882},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"自":{"docs":{},"动":{"docs":{},"生":{"docs":{},"成":{"docs":{},"微":{"docs":{},"调":{"docs":{},"数":{"docs":{},"据":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":5}}}}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"通":{"docs":{},"过":{"docs":{},"提":{"docs":{},"供":{"docs":{},"具":{"docs":{},"体":{"docs":{},"的":{"docs":{},"法":{"docs":{},"律":{"docs":{},"知":{"docs":{},"识":{"docs":{},"文":{"docs":{},"本":{"docs":{},"，":{"docs":{},"先":{"docs":{},"让":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"生":{"docs":{},"成":{"docs":{},"与":{"docs":{},"该":{"docs":{},"段":{"docs":{},"法":{"docs":{},"律":{"docs":{},"知":{"docs":{},"识":{"docs":{},"内":{"docs":{},"容":{"docs":{},"与":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"关":{"docs":{},"系":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"若":{"docs":{},"干":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"再":{"docs":{},"通":{"docs":{},"过":{"docs":{},"“":{"docs":{},"文":{"docs":{},"本":{"docs":{},"段":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"8":{"0":{"docs":{},"k":{"docs":{},"个":{"docs":{},"多":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"m":{"2":{"docs":{},"m":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"可":{"docs":{},"靠":{"docs":{},"性":{"docs":{},"和":{"docs":{},"安":{"docs":{},"全":{"docs":{},"性":{"docs":{},"漏":{"docs":{},"洞":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"基":{"docs":{},"于":{"docs":{},"特":{"docs":{},"定":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"8":{"2":{"docs":{},"k":{"docs":{},"个":{"docs":{},"指":{"docs":{},"令":{"docs":{},"输":{"docs":{},"入":{"docs":{},"输":{"docs":{},"出":{"docs":{},"实":{"docs":{},"例":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}},"a":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"t":{"4":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"\"":{"docs":{},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01858736059479554}},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"=":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}}}}}}}}}}}}}}}}}}}}}}}}},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"/":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"\\":{"docs":{},"\\":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"o":{"docs":{},"\"":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"一":{"docs":{},"行":{"docs":{},"手":{"docs":{},"动":{"docs":{},"加":{"docs":{},"载":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}},"s":{"docs":{},"o":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"地":{"docs":{},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"进":{"docs":{},"入":{"docs":{},"c":{"docs":{},"m":{"docs":{},"d":{"docs":{},"，":{"docs":{},"运":{"docs":{},"行":{"docs":{},"如":{"docs":{},"下":{"docs":{},"两":{"docs":{},"个":{"docs":{},"编":{"docs":{},"译":{"docs":{},"命":{"docs":{},"令":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"看":{"docs":{},"到":{"docs":{},"下":{"docs":{},"面":{"docs":{},"两":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{},"文":{"docs":{},"件":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"文":{"docs":{},"件":{"docs":{},"下":{"docs":{},"载":{"docs":{},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"/":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"d":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"8":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.01694915254237288}},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}},"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":10},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"m":{"docs":{},"d":{"docs":{},"b":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"这":{"docs":{},"三":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"回":{"docs":{},"复":{"docs":{},"进":{"docs":{},"行":{"docs":{},"评":{"docs":{},"分":{"docs":{},"，":{"docs":{},"以":{"docs":{},"训":{"docs":{},"练":{"docs":{},"奖":{"docs":{},"励":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"8":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"到":{"docs":{},"小":{"docs":{},"学":{"docs":{},"数":{"docs":{},"学":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"无":{"docs":{},"关":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":5.093023255813954},"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}},"n":{"docs":{},"g":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},":":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}},"u":{"docs":{},"a":{"docs":{},"g":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"e":{"docs":{},"”":{"docs":{},"（":{"2":{"0":{"2":{"1":{"docs":{},"）":{"docs":{},"中":{"docs":{},"提":{"docs":{},"出":{"docs":{},"。":{"docs":{},"p":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}},"w":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.019230769230769232},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.03529411764705882}},"、":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}},"m":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"三":{"docs":{},"种":{"docs":{},"微":{"docs":{},"调":{"docs":{},"技":{"docs":{},"术":{"docs":{},"对":{"docs":{},"比":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":10}}}}}}}},"训":{"docs":{},"练":{"docs":{},"技":{"docs":{},"术":{"docs":{},"对":{"docs":{},"比":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":10}}}}}}}}}},"引":{"docs":{},"擎":{"docs":{},"学":{"docs":{},"习":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":5.011627906976744},"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}},"，":{"docs":{},"以":{"docs":{},"生":{"docs":{},"成":{"docs":{},"不":{"docs":{},"同":{"docs":{},"但":{"docs":{},"相":{"docs":{},"似":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}},"后":{"docs":{},"续":{"docs":{},"他":{"docs":{},"们":{"docs":{},"将":{"docs":{},"发":{"docs":{},"布":{"docs":{},"执":{"docs":{},"行":{"docs":{},"此":{"docs":{},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{},"功":{"docs":{},"能":{"docs":{},"和":{"docs":{},"代":{"docs":{},"码":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":3.364583333333333}},"(":{"docs":{},"羊":{"docs":{},"驼":{"docs":{},"模":{"docs":{},"型":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}},")":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"/":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"/":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"适":{"docs":{},"配":{"docs":{},"器":{"docs":{},";":{"docs":{},"简":{"docs":{},"单":{"docs":{},"来":{"docs":{},"说":{"docs":{},"就":{"docs":{},"是":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"来":{"docs":{},"调":{"docs":{},"试":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"具":{"docs":{},"体":{"docs":{},"场":{"docs":{},"景":{"docs":{},"下":{"docs":{},"的":{"docs":{},"准":{"docs":{},"确":{"docs":{},"度":{"docs":{},"；":{"docs":{},"假":{"docs":{},"设":{"docs":{},"模":{"docs":{},"型":{"docs":{},"适":{"docs":{},"应":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"变":{"docs":{},"化":{"docs":{},"也":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}},"（":{"docs":{},"开":{"docs":{},"源":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"）":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}},"）":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}},"，":{"docs":{},"链":{"docs":{},"接":{"docs":{},"开":{"docs":{},"头":{"docs":{},"已":{"docs":{},"经":{"docs":{},"给":{"docs":{},"出":{"docs":{},"，":{"docs":{},"下":{"docs":{},"载":{"docs":{},"后":{"docs":{},"放":{"docs":{},"到":{"docs":{},"项":{"docs":{},"目":{"docs":{},"根":{"docs":{},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"_":{"8":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"docs":{}}}},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"r":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"u":{"docs":{},"x":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625}}}}},"s":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"f":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"s":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"运":{"docs":{},"行":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"r":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"=":{"2":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}},"docs":{}}},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}},"得":{"docs":{},"分":{"docs":{},"来":{"docs":{},"看":{"docs":{},"，":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"优":{"docs":{},"于":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"x":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}}},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"e":{"docs":{},"d":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"r":{"docs":{},"g":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}},"t":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"论":{"docs":{},"文":{"docs":{},"学":{"docs":{},"习":{"docs":{},"笔":{"docs":{},"记":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":10}}}}}}}},":":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"s":{"docs":{},"：":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}},"i":{"docs":{},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{},"k":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"3":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"docs":{}}}}}}}},"x":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.03345724907063197}},".":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"f":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"(":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{},"\"":{"docs":{},"你":{"docs":{},"好":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},"=":{"4":{"docs":{},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}},"docs":{}}}}}}}}}}}}}}}},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}},"u":{"docs":{},"l":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}},"t":{"0":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"docs":{}},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{},"p":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}}}}},"l":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}},"o":{"3":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}},"p":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"i":{"docs":{},"m":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"/":{"docs":{},"l":{"docs":{},"m":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"测":{"docs":{},"量":{"docs":{},"文":{"docs":{},"本":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"性":{"docs":{},"。":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"：":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"c":{"docs":{},"u":{"docs":{},"p":{"docs":{},"i":{"docs":{},"e":{"docs":{},"d":{"docs":{},":":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"【":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"】":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}},"n":{"docs":{},"g":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"w":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"t":{"1":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"8":{"9":{"docs":{},"k":{"docs":{},"个":{"docs":{},"多":{"docs":{},"语":{"docs":{},"言":{"docs":{},"助":{"docs":{},"理":{"docs":{},"风":{"docs":{},"格":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"人":{"docs":{},"类":{"docs":{},"生":{"docs":{},"成":{"docs":{},"和":{"docs":{},"标":{"docs":{},"注":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}},"docs":{}}}}},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"s":{"docs":{},".":{"docs":{},"\"":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"x":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"”":{"docs":{},"序":{"docs":{},"列":{"docs":{},"到":{"docs":{},"序":{"docs":{},"列":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"启":{"docs":{},"发":{"docs":{},"，":{"docs":{},"作":{"docs":{},"者":{"docs":{},"训":{"docs":{},"练":{"docs":{},"了":{"docs":{},"三":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"x":{"docs":{},"i":{"docs":{},"a":{"docs":{},"o":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}},"f":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"综":{"docs":{},"述":{"docs":{},"：":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}},"r":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"u":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}},"d":{"docs":{},"f":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.08695652173913043}}}},"o":{"docs":{},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"（":{"docs":{},"f":{"docs":{},"s":{"docs":{},"d":{"docs":{},"p":{"docs":{},"）":{"docs":{},"和":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},".":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.007683863885839737}},"=":{"8":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}},"docs":{}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"_":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"e":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.03614457831325301},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.014925373134328358},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"）":{"docs":{},"而":{"docs":{},"非":{"docs":{},"修":{"docs":{},"改":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{},"这":{"docs":{},"意":{"docs":{},"味":{"docs":{},"着":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"保":{"docs":{},"持":{"docs":{},"不":{"docs":{},"变":{"docs":{},"，":{"docs":{},"只":{"docs":{},"有":{"docs":{},"输":{"docs":{},"入":{"docs":{},"提":{"docs":{},"示":{"docs":{},"被":{"docs":{},"修":{"docs":{},"改":{"docs":{},"以":{"docs":{},"适":{"docs":{},"应":{"docs":{},"下":{"docs":{},"游":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"设":{"docs":{},"计":{"docs":{},"和":{"docs":{},"优":{"docs":{},"化":{"docs":{},"一":{"docs":{},"组":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"执":{"docs":{},"行":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}},"，":{"docs":{},"以":{"docs":{},"便":{"docs":{},"于":{"docs":{},"用":{"docs":{},"户":{"docs":{},"根":{"docs":{},"据":{"docs":{},"模":{"docs":{},"型":{"docs":{},"设":{"docs":{},"置":{"docs":{},"不":{"docs":{},"同":{"docs":{},"格":{"docs":{},"式":{"docs":{},"的":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}},"o":{"docs":{},"f":{"docs":{},"w":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}},"y":{"3":{"1":{"0":{"docs":{},"_":{"2":{"3":{"docs":{},".":{"1":{"docs":{},".":{"0":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}},"9":{"docs":{},"_":{"4":{"docs":{},".":{"1":{"2":{"docs":{},".":{"0":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}},"h":{"docs":{},"o":{"docs":{},"n":{"3":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}},"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"=":{"3":{"docs":{},".":{"9":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}},"docs":{}}},"docs":{}},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}},"i":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"e":{"docs":{},"，":{"docs":{},"其":{"docs":{},"灵":{"docs":{},"感":{"docs":{},"来":{"docs":{},"自":{"docs":{},"斯":{"docs":{},"坦":{"docs":{},"福":{"docs":{},"的":{"docs":{},"开":{"docs":{},"源":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.012074643249176729}},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}},"u":{"docs":{},"b":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"s":{"docs":{},"c":{"docs":{},"i":{"docs":{},"r":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"a":{"docs":{},"b":{"docs":{},"s":{"docs":{},"/":{"2":{"2":{"0":{"8":{"docs":{},".":{"0":{"7":{"3":{"3":{"9":{"docs":{},"*":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":5},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"l":{"docs":{},"a":{"docs":{},"w":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}},"/":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}},"f":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"d":{"docs":{},"i":{"docs":{},"u":{"docs":{},"m":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"x":{"docs":{},"m":{"2":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}},"h":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}},"e":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"k":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{},"，":{"docs":{},"它":{"docs":{},"由":{"docs":{},"k":{"docs":{},"a":{"docs":{},"p":{"docs":{},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"等":{"docs":{},"人":{"docs":{},"于":{"2":{"0":{"2":{"0":{"docs":{},"年":{"docs":{},"引":{"docs":{},"入":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"在":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"t":{"docs":{},"中":{"docs":{},"表":{"docs":{},"现":{"docs":{},"更":{"docs":{},"好":{"docs":{},"！":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}},"”":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}},"=":{"3":{"0":{"0":{"0":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}},"d":{"docs":{},"=":{"docs":{},"c":{"9":{"9":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}},"docs":{}},"docs":{}}}},"u":{"docs":{},"d":{"docs":{},"i":{"docs":{},"o":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"a":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}},"y":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}},"c":{"docs":{},"h":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}}}},"g":{"docs":{},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"i":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{},"e":{"docs":{},"d":{"docs":{},"/":{"docs":{},"n":{"docs":{},"q":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"s":{"docs":{},"i":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}},"t":{"5":{"1":{"1":{"docs":{},"b":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}},"docs":{}},"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}},"）":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"docs":{},"h":{"docs":{},"u":{"docs":{},"d":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.029850746268656716}},"介":{"docs":{},"绍":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}},"方":{"docs":{},"法":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"个":{"docs":{},"更":{"docs":{},"先":{"docs":{},"进":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"通":{"docs":{},"过":{"docs":{},"分":{"docs":{},"解":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"为":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"相":{"docs":{},"互":{"docs":{},"关":{"docs":{},"联":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"使":{"docs":{},"模":{"docs":{},"型":{"docs":{},"能":{"docs":{},"够":{"docs":{},"理":{"docs":{},"解":{"docs":{},"和":{"docs":{},"维":{"docs":{},"护":{"docs":{},"文":{"docs":{},"本":{"docs":{},"中":{"docs":{},"的":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"的":{"docs":{},"、":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"。":{"docs":{},"与":{"docs":{},"其":{"docs":{},"他":{"docs":{},"方":{"docs":{},"法":{"docs":{},"不":{"docs":{},"同":{"docs":{},"，":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"重":{"docs":{},"点":{"docs":{},"在":{"docs":{},"于":{"docs":{},"将":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"逐":{"docs":{},"步":{"docs":{},"更":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{},"注":{"docs":{},"意":{"docs":{},"机":{"docs":{},"制":{"docs":{},"来":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"模":{"docs":{},"型":{"docs":{},"集":{"docs":{},"中":{"docs":{},"于":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"训":{"docs":{},"练":{"docs":{},"中":{"docs":{},"，":{"docs":{},"将":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"中":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"非":{"docs":{},"常":{"docs":{},"关":{"docs":{},"键":{"docs":{},"的":{"docs":{},"一":{"docs":{},"步":{"docs":{},"。":{"docs":{},"一":{"docs":{},"般":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"过":{"docs":{},"程":{"docs":{},"需":{"docs":{},"要":{"docs":{},"根":{"docs":{},"据":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"定":{"docs":{},"制":{"docs":{},"。":{"docs":{},"以":{"docs":{},"下":{"docs":{},"是":{"docs":{},"一":{"docs":{},"些":{"docs":{},"通":{"docs":{},"用":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"能":{"docs":{},"力":{"docs":{},"和":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"理":{"docs":{},"解":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}},"都":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"训":{"docs":{},"练":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"都":{"docs":{},"有":{"docs":{},"助":{"docs":{},"于":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"能":{"docs":{},"力":{"docs":{},"和":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"理":{"docs":{},"解":{"docs":{},"能":{"docs":{},"力":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"和":{"docs":{},"目":{"docs":{},"的":{"docs":{},"略":{"docs":{},"有":{"docs":{},"不":{"docs":{},"同":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}},"，":{"docs":{},"c":{"docs":{},"o":{"docs":{},"t":{"docs":{},")":{"docs":{},"，":{"docs":{},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"有":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"关":{"docs":{},"系":{"docs":{},"的":{"docs":{},"思":{"docs":{},"考":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"形":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"思":{"docs":{},"考":{"docs":{},"过":{"docs":{},"程":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"k":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}},"s":{"docs":{},"论":{"docs":{},"文":{"docs":{},"学":{"docs":{},"习":{"docs":{},"笔":{"docs":{},"记":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":5}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"u":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},")":{"docs":{},"，":{"docs":{},"它":{"docs":{},"由":{"docs":{},"h":{"docs":{},"o":{"docs":{},"u":{"docs":{},"l":{"docs":{},"s":{"docs":{},"b":{"docs":{},"y":{"docs":{},"等":{"docs":{},"人":{"docs":{},"于":{"2":{"0":{"1":{"9":{"docs":{},"年":{"docs":{},"引":{"docs":{},"入":{"docs":{},"。":{"docs":{},"适":{"docs":{},"配":{"docs":{},"器":{"docs":{},"是":{"docs":{},"添":{"docs":{},"加":{"docs":{},"到":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"的":{"docs":{},"小":{"docs":{},"型":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"适":{"docs":{},"配":{"docs":{},"器":{"docs":{},"只":{"docs":{},"占":{"docs":{},"原":{"docs":{},"始":{"docs":{},"模":{"docs":{},"型":{"docs":{},"大":{"docs":{},"小":{"docs":{},"的":{"docs":{},"一":{"docs":{},"小":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"这":{"docs":{},"使":{"docs":{},"得":{"docs":{},"训":{"docs":{},"练":{"docs":{},"更":{"docs":{},"快":{"docs":{},"，":{"docs":{},"内":{"docs":{},"存":{"docs":{},"需":{"docs":{},"求":{"docs":{},"更":{"docs":{},"低":{"docs":{},"。":{"docs":{},"适":{"docs":{},"配":{"docs":{},"器":{"docs":{},"可":{"docs":{},"以":{"docs":{},"针":{"docs":{},"对":{"docs":{},"多":{"docs":{},"种":{"docs":{},"任":{"docs":{},"务":{"docs":{},"进":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"插":{"docs":{},"入":{"docs":{},"到":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"以":{"docs":{},"执":{"docs":{},"行":{"docs":{},"新":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"l":{"docs":{},".":{"docs":{},"g":{"docs":{},"z":{"docs":{},"]":{"docs":{},"、":{"docs":{},"开":{"docs":{},"发":{"docs":{},"集":{"docs":{},"[":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"u":{"docs":{},"d":{"docs":{},".":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"/":{"docs":{},"v":{"1":{"docs":{},".":{"0":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}}},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}}}},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"：":{"docs":{},"在":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"=":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01858736059479554}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"回":{"docs":{},"复":{"docs":{},"长":{"docs":{},"度":{"docs":{},"增":{"docs":{},"加":{"docs":{},"时":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"表":{"docs":{},"现":{"docs":{},"得":{"docs":{},"更":{"docs":{},"好":{"docs":{},"，":{"docs":{},"最":{"docs":{},"终":{"docs":{},"在":{"docs":{},"长":{"docs":{},"度":{"docs":{},"超":{"docs":{},"过":{"4":{"docs":{},"时":{"docs":{},"表":{"docs":{},"现":{"docs":{},"出":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"，":{"docs":{},"意":{"docs":{},"味":{"docs":{},"着":{"docs":{},"当":{"docs":{},"场":{"docs":{},"景":{"docs":{},"更":{"docs":{},"具":{"docs":{},"创":{"docs":{},"造":{"docs":{},"性":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"遵":{"docs":{},"循":{"docs":{},"指":{"docs":{},"令":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"v":{"docs":{},"i":{"docs":{},"a":{"docs":{},"q":{"docs":{},"a":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"6":{"5":{"docs":{},"万":{"docs":{},"多":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{},"维":{"docs":{},"基":{"docs":{},"百":{"docs":{},"科":{"docs":{},"和":{"docs":{},"网":{"docs":{},"络":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"有":{"docs":{},"趣":{"docs":{},"的":{"docs":{},"事":{"docs":{},"实":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"答":{"docs":{},"案":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"实":{"docs":{},"体":{"docs":{},"或":{"docs":{},"数":{"docs":{},"字":{"docs":{},"。":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},".":{"docs":{},"c":{"docs":{},"s":{"docs":{},".":{"docs":{},"w":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"i":{"docs":{},"a":{"docs":{},"q":{"docs":{},"a":{"docs":{},"/":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}},"e":{"docs":{},"s":{"docs":{},"l":{"docs":{},"a":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}},"t":{"docs":{},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},":":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.024096385542168676}}},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}},"如":{"docs":{},"果":{"docs":{},"两":{"docs":{},"者":{"docs":{},"不":{"docs":{},"相":{"docs":{},"似":{"docs":{},"，":{"docs":{},"则":{"docs":{},"可":{"docs":{},"能":{"docs":{},"需":{"docs":{},"要":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"将":{"docs":{},"学":{"docs":{},"习":{"docs":{},"如":{"docs":{},"何":{"docs":{},"根":{"docs":{},"据":{"docs":{},"输":{"docs":{},"入":{"docs":{},"文":{"docs":{},"本":{"docs":{},"预":{"docs":{},"测":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"修":{"docs":{},"改":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"而":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}},"只":{"docs":{},"修":{"docs":{},"改":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.022388059701492536}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}},"技":{"docs":{},"术":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.024096385542168676}},"[":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"]":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}},"也":{"docs":{},"随":{"docs":{},"之":{"docs":{},"流":{"docs":{},"行":{"docs":{},"，":{"docs":{},"即":{"docs":{},"将":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"冻":{"docs":{},"结":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"根":{"docs":{},"据":{"docs":{},"具":{"docs":{},"体":{"docs":{},"任":{"docs":{},"务":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"变":{"docs":{},"得":{"docs":{},"十":{"docs":{},"分":{"docs":{},"有":{"docs":{},"效":{"docs":{},"且":{"docs":{},"被":{"docs":{},"应":{"docs":{},"用":{"docs":{},"在":{"docs":{},"很":{"docs":{},"多":{"docs":{},"场":{"docs":{},"景":{"docs":{},"。":{"docs":{},"随":{"docs":{},"着":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"的":{"docs":{},"火":{"docs":{},"热":{"docs":{},"，":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"似":{"docs":{},"乎":{"docs":{},"也":{"docs":{},"有":{"docs":{},"替":{"docs":{},"代":{"docs":{},"传":{"docs":{},"统":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}},"而":{"docs":{},"非":{"docs":{},"手":{"docs":{},"工":{"docs":{},"调":{"docs":{},"整":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"未":{"docs":{},"来":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"方":{"docs":{},"向":{"docs":{},"。":{"docs":{},"毕":{"docs":{},"竟":{"docs":{},"在":{"docs":{},"文":{"docs":{},"本":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"、":{"docs":{},"代":{"docs":{},"码":{"docs":{},"d":{"docs":{},"e":{"docs":{},"b":{"docs":{},"u":{"docs":{},"g":{"docs":{},"等":{"docs":{},"需":{"docs":{},"要":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"来":{"docs":{},"让":{"docs":{},"模":{"docs":{},"型":{"docs":{},"认":{"docs":{},"识":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"场":{"docs":{},"景":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"将":{"docs":{},"过":{"docs":{},"长":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"给":{"docs":{},"模":{"docs":{},"型":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"现":{"docs":{},"在":{"docs":{},"的":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"长":{"docs":{},"输":{"docs":{},"入":{"docs":{},"方":{"docs":{},"面":{"docs":{},"推":{"docs":{},"理":{"docs":{},"成":{"docs":{},"本":{"docs":{},"很":{"docs":{},"高":{"docs":{},"且":{"docs":{},"有":{"docs":{},"很":{"docs":{},"大":{"docs":{},"限":{"docs":{},"制":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"这":{"docs":{},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"也":{"docs":{},"是":{"docs":{},"未":{"docs":{},"来":{"docs":{},"很":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"方":{"docs":{},"向":{"docs":{},"！":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"方":{"docs":{},"法":{"docs":{},"包":{"docs":{},"括":{"docs":{},"将":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"与":{"docs":{},"少":{"docs":{},"量":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"数":{"docs":{},"据":{"docs":{},"一":{"docs":{},"起":{"docs":{},"继":{"docs":{},"续":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"被":{"docs":{},"更":{"docs":{},"新":{"docs":{},"，":{"docs":{},"以":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"适":{"docs":{},"应":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"更":{"docs":{},"少":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"更":{"docs":{},"近":{"docs":{},"期":{"docs":{},"的":{"docs":{},"精":{"docs":{},"调":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"重":{"docs":{},"点":{"docs":{},"是":{"docs":{},"调":{"docs":{},"整":{"docs":{},"输":{"docs":{},"入":{"docs":{},"提":{"docs":{},"示":{"docs":{},"（":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"提":{"docs":{},"示":{"docs":{},"（":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"）":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"以":{"docs":{},"指":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"定":{"docs":{},"向":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"使":{"docs":{},"其":{"docs":{},"在":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"表":{"docs":{},"现":{"docs":{},"出":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"与":{"docs":{},"其":{"docs":{},"他":{"docs":{},"方":{"docs":{},"法":{"docs":{},"不":{"docs":{},"同":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"为":{"docs":{},"模":{"docs":{},"型":{"docs":{},"提":{"docs":{},"供":{"docs":{},"任":{"docs":{},"务":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"来":{"docs":{},"指":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"使":{"docs":{},"模":{"docs":{},"型":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"理":{"docs":{},"解":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"要":{"docs":{},"求":{"docs":{},"，":{"docs":{},"并":{"docs":{},"提":{"docs":{},"高":{"docs":{},"其":{"docs":{},"生":{"docs":{},"成":{"docs":{},"能":{"docs":{},"力":{"docs":{},"和":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"理":{"docs":{},"解":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"著":{"docs":{},"名":{"docs":{},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{},"之":{"docs":{},"一":{"docs":{},"是":{"docs":{},"由":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"开":{"docs":{},"发":{"docs":{},"的":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}},"期":{"docs":{},"间":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"减":{"docs":{},"小":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{},"从":{"docs":{},"一":{"docs":{},"个":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"开":{"docs":{},"始":{"docs":{},"，":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"减":{"docs":{},"少":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"达":{"docs":{},"到":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"可":{"docs":{},"以":{"docs":{},"产":{"docs":{},"生":{"docs":{},"比":{"docs":{},"从":{"docs":{},"头":{"docs":{},"开":{"docs":{},"始":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"性":{"docs":{},"能":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"小":{"docs":{},"型":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"比":{"docs":{},"精":{"docs":{},"调":{"docs":{},"更":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"它":{"docs":{},"允":{"docs":{},"许":{"docs":{},"创":{"docs":{},"建":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"适":{"docs":{},"应":{"docs":{},"各":{"docs":{},"种":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"涉":{"docs":{},"及":{"docs":{},"训":{"docs":{},"练":{"docs":{},"可":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"称":{"docs":{},"为":{"docs":{},"“":{"docs":{},"提":{"docs":{},"示":{"docs":{},"记":{"docs":{},"号":{"docs":{},"”":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"参":{"docs":{},"数":{"docs":{},"与":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"连":{"docs":{},"接":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"提":{"docs":{},"示":{"docs":{},"记":{"docs":{},"号":{"docs":{},"是":{"docs":{},"特":{"docs":{},"定":{"docs":{},"于":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"，":{"docs":{},"在":{"docs":{},"精":{"docs":{},"调":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"进":{"docs":{},"行":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"保":{"docs":{},"持":{"docs":{},"原":{"docs":{},"始":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"不":{"docs":{},"变":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"在":{"docs":{},"新":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"表":{"docs":{},"现":{"docs":{},"良":{"docs":{},"好":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"主":{"docs":{},"要":{"docs":{},"区":{"docs":{},"别":{"docs":{},"在":{"docs":{},"于":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"被":{"docs":{},"修":{"docs":{},"改":{"docs":{},"的":{"docs":{},"程":{"docs":{},"度":{"docs":{},"。":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}},"基":{"docs":{},"本":{"docs":{},"思":{"docs":{},"想":{"docs":{},"是":{"docs":{},"采":{"docs":{},"用":{"docs":{},"已":{"docs":{},"经":{"docs":{},"在":{"docs":{},"大":{"docs":{},"量":{"docs":{},"文":{"docs":{},"本":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"小":{"docs":{},"规":{"docs":{},"模":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"特":{"docs":{},"定":{"docs":{},"文":{"docs":{},"本":{"docs":{},"上":{"docs":{},"继":{"docs":{},"续":{"docs":{},"训":{"docs":{},"练":{"docs":{},"它":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"趋":{"docs":{},"势":{"docs":{},"，":{"docs":{},"本":{"docs":{},"篇":{"docs":{},"论":{"docs":{},"文":{"docs":{},"将":{"docs":{},"简":{"docs":{},"单":{"docs":{},"描":{"docs":{},"述":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"领":{"docs":{},"域":{"docs":{},"这":{"docs":{},"三":{"docs":{},"种":{"docs":{},"微":{"docs":{},"调":{"docs":{},"技":{"docs":{},"术":{"docs":{},"及":{"docs":{},"其":{"docs":{},"差":{"docs":{},"别":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"种":{"docs":{},"想":{"docs":{},"法":{"docs":{},"！":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}},"重":{"docs":{},"点":{"docs":{},"在":{"docs":{},"于":{"docs":{},"设":{"docs":{},"计":{"docs":{},"良":{"docs":{},"好":{"docs":{},"的":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"提":{"docs":{},"示":{"docs":{},"可":{"docs":{},"以":{"docs":{},"引":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"准":{"docs":{},"确":{"docs":{},"、":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"整":{"docs":{},"比":{"docs":{},"精":{"docs":{},"调":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"成":{"docs":{},"本":{"docs":{},"低":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"和":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"间":{"docs":{},"也":{"docs":{},"更":{"docs":{},"少":{"docs":{},"。":{"docs":{},"此":{"docs":{},"外":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"量":{"docs":{},"取":{"docs":{},"决":{"docs":{},"于":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"和":{"docs":{},"任":{"docs":{},"务":{"docs":{},"特":{"docs":{},"定":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"性":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"两":{"docs":{},"者":{"docs":{},"相":{"docs":{},"似":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"少":{"docs":{},"量":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"前":{"docs":{},"缀":{"docs":{},"调":{"docs":{},"整":{"docs":{},"）":{"docs":{},"：":{"docs":{},"由":{"docs":{},"l":{"docs":{},"i":{"docs":{},"和":{"docs":{},"l":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"在":{"docs":{},"论":{"docs":{},"文":{"docs":{},"“":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.044444444444444446}},"目":{"docs":{},"前":{"docs":{},"仅":{"docs":{},"适":{"docs":{},"用":{"docs":{},"于":{"docs":{},"以":{"docs":{},"下":{"docs":{},"基":{"docs":{},"本":{"docs":{},"型":{"docs":{},"号":{"docs":{},"：":{"docs":{},"d":{"docs":{},"a":{"docs":{},"v":{"docs":{},"i":{"docs":{},"n":{"docs":{},"c":{"docs":{},"i":{"docs":{},"、":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"、":{"docs":{},"b":{"docs":{},"a":{"docs":{},"b":{"docs":{},"b":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"和":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"，":{"docs":{},"是":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"一":{"docs":{},"次":{"docs":{},"训":{"docs":{},"练":{"docs":{},"终":{"docs":{},"身":{"docs":{},"受":{"docs":{},"益":{"docs":{},"，":{"docs":{},"适":{"docs":{},"合":{"docs":{},"很":{"docs":{},"久":{"docs":{},"知":{"docs":{},"识":{"docs":{},"都":{"docs":{},"不":{"docs":{},"变":{"docs":{},"且":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"；":{"docs":{},"你":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"示":{"docs":{},"例":{"docs":{},"越":{"docs":{},"多":{"docs":{},"越":{"docs":{},"好":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"建":{"docs":{},"议":{"docs":{},"至":{"docs":{},"少":{"docs":{},"有":{"docs":{},"几":{"docs":{},"百":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{},"。":{"docs":{},"一":{"docs":{},"般":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"发":{"docs":{},"现":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"大":{"docs":{},"小":{"docs":{},"的":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"翻":{"docs":{},"倍":{"docs":{},"都":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"模":{"docs":{},"型":{"docs":{},"质":{"docs":{},"量":{"docs":{},"的":{"docs":{},"线":{"docs":{},"性":{"docs":{},"增":{"docs":{},"加":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"简":{"docs":{},"称":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"，":{"docs":{},"旨":{"docs":{},"在":{"docs":{},"在":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"减":{"docs":{},"少":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"实":{"docs":{},"现":{"docs":{},"对":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"有":{"docs":{},"效":{"docs":{},"微":{"docs":{},"调":{"docs":{},"。":{"docs":{},"它":{"docs":{},"是":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"（":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"）":{"docs":{},"中":{"docs":{},"一":{"docs":{},"组":{"docs":{},"用":{"docs":{},"于":{"docs":{},"将":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"适":{"docs":{},"应":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"其":{"docs":{},"所":{"docs":{},"需":{"docs":{},"参":{"docs":{},"数":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"资":{"docs":{},"源":{"docs":{},"比":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}},"：":{"docs":{},"由":{"docs":{},"l":{"docs":{},"i":{"docs":{},"u":{"docs":{},"等":{"docs":{},"人":{"docs":{},"在":{"docs":{},"论":{"docs":{},"文":{"docs":{},"“":{"docs":{},"p":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}},"加":{"docs":{},"上":{"docs":{},"“":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"”":{"docs":{},"，":{"docs":{},"变":{"docs":{},"成":{"docs":{},"填":{"docs":{},"空":{"docs":{},"题":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}},"、":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.022388059701492536}}}}}}}}}}},"介":{"docs":{},"绍":{"docs":{},"：":{"docs":{},"更":{"docs":{},"为":{"docs":{},"详":{"docs":{},"细":{"docs":{},"流":{"docs":{},"程":{"docs":{},"化":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"而":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"较":{"docs":{},"少":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"可":{"docs":{},"以":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"泛":{"docs":{},"化":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.024096385542168676},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.014925373134328358},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"、":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}},"和":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}},"r":{"docs":{},"k":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"结":{"docs":{},"果":{"docs":{},"进":{"docs":{},"行":{"docs":{},"人":{"docs":{},"工":{"docs":{},"评":{"docs":{},"估":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},".":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"(":{"1":{"docs":{},"，":{"1":{"docs":{},")":{"docs":{},")":{"docs":{},".":{"docs":{},"t":{"docs":{},"o":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"\"":{"docs":{},")":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"(":{"docs":{},"o":{"docs":{},"s":{"docs":{},".":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},".":{"docs":{},"j":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"实":{"docs":{},"现":{"docs":{},"：":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"—":{"docs":{},"—":{"docs":{},"构":{"docs":{},"建":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"构":{"docs":{},"建":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"；":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"模":{"docs":{},"型":{"docs":{},"优":{"docs":{},"化":{"docs":{},"—":{"docs":{},"—":{"docs":{},"对":{"docs":{},"比":{"docs":{},"学":{"docs":{},"习":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"、":{"docs":{},"度":{"docs":{},"量":{"docs":{},"学":{"docs":{},"习":{"docs":{},"；":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"【":{"docs":{},"用":{"docs":{},"户":{"docs":{},"查":{"docs":{},"询":{"docs":{},"】":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"h":{"docs":{},"u":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"g":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}},"，":{"docs":{},"近":{"docs":{},"似":{"docs":{},"为":{"docs":{},"黄":{"docs":{},"金":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"+":{"6":{"docs":{},"g":{"docs":{},"b":{"docs":{},"显":{"docs":{},"+":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"本":{"docs":{},"地":{"docs":{},"部":{"docs":{},"署":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":5}}}}}}}}}}}}}}}}}}}}},"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"部":{"docs":{},"署":{"docs":{},"方":{"docs":{},"案":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"部":{"docs":{},"署":{"docs":{},"方":{"docs":{},"案":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"e":{"docs":{},"b":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"2":{"0":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"项":{"docs":{},"目":{"docs":{},"生":{"docs":{},"成":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"开":{"docs":{},"放":{"docs":{},"领":{"docs":{},"域":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"5":{"docs":{},",":{"8":{"1":{"0":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"?":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"o":{"docs":{},"r":{"docs":{},"l":{"docs":{},"d":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}},"y":{"docs":{},"a":{"docs":{},"n":{"docs":{},"q":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"m":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"y":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{},"f":{"docs":{},"/":{"docs":{},"c":{"docs":{},"m":{"docs":{},"e":{"docs":{},"k":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"o":{"docs":{},"l":{"docs":{},"s":{"docs":{},")":{"docs":{},"，":{"docs":{},"并":{"docs":{},"利":{"docs":{},"用":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"中":{"docs":{},"文":{"docs":{},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"项":{"docs":{},"目":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}}},"法":{"docs":{},"律":{"docs":{},"知":{"docs":{},"识":{"docs":{},"模":{"docs":{},"型":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"这":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"，":{"docs":{},"将":{"docs":{},"参":{"docs":{},"数":{"docs":{},"动":{"docs":{},"态":{"docs":{},"地":{"docs":{},"从":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"的":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}},"检":{"docs":{},"索":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"天":{"docs":{},"工":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"调":{"docs":{},"研":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":10.043478260869565}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"上":{"docs":{},"新":{"docs":{},"了":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}},"学":{"docs":{},"习":{"docs":{},"相":{"docs":{},"关":{"docs":{},"项":{"docs":{},"目":{"docs":{},"代":{"docs":{},"码":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}},"从":{"docs":{},"知":{"docs":{},"识":{"docs":{},"到":{"docs":{},"预":{"docs":{},"测":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"链":{"docs":{},"—":{"docs":{},">":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"构":{"docs":{},"建":{"docs":{},"可":{"docs":{},"解":{"docs":{},"释":{"docs":{},"的":{"docs":{},"q":{"docs":{},"a":{"docs":{},"问":{"docs":{},"答":{"docs":{},"系":{"docs":{},"统":{"docs":{},"。":{"docs":{},"【":{"docs":{},"方":{"docs":{},"法":{"docs":{},"】":{"docs":{},"用":{"docs":{},"由":{"docs":{},"多":{"docs":{},"个":{"docs":{},"隐":{"docs":{},"含":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"组":{"docs":{},"成":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"含":{"docs":{},"树":{"docs":{},"来":{"docs":{},"解":{"docs":{},"释":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{},"【":{"docs":{},"现":{"docs":{},"状":{"docs":{},"】":{"docs":{},"目":{"docs":{},"前":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"建":{"docs":{},"议":{"docs":{},"使":{"docs":{},"用":{"docs":{},"端":{"docs":{},"到":{"docs":{},"端":{"docs":{},"生":{"docs":{},"成":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"生":{"docs":{},"成":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"，":{"docs":{},"但":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"树":{"docs":{},"中":{"docs":{},"的":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"不":{"docs":{},"受":{"docs":{},"约":{"docs":{},"束":{"docs":{},"，":{"docs":{},"而":{"docs":{},"且":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"可":{"docs":{},"靠":{"docs":{},"。":{"docs":{},"【":{"docs":{},"方":{"docs":{},"法":{"docs":{},"/":{"docs":{},"创":{"docs":{},"新":{"docs":{},"】":{"docs":{},"本":{"docs":{},"文":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"模":{"docs":{},"块":{"docs":{},"的":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"生":{"docs":{},"成":{"docs":{},"枚":{"docs":{},"举":{"docs":{},"框":{"docs":{},"架":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"它":{"docs":{},"具":{"docs":{},"有":{"docs":{},"“":{"docs":{},"多":{"docs":{},"个":{"docs":{},"模":{"docs":{},"块":{"docs":{},"和":{"docs":{},"一":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"控":{"docs":{},"制":{"docs":{},"器":{"docs":{},"”":{"docs":{},"。":{"docs":{},"给":{"docs":{},"定":{"docs":{},"一":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"一":{"docs":{},"些":{"docs":{},"支":{"docs":{},"持":{"docs":{},"知":{"docs":{},"识":{"docs":{},"，":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"对":{"docs":{},"单":{"docs":{},"独":{"docs":{},"的":{"docs":{},"模":{"docs":{},"块":{"docs":{},"进":{"docs":{},"行":{"docs":{},"单":{"docs":{},"步":{"docs":{},"隐":{"docs":{},"含":{"docs":{},"，":{"docs":{},"用":{"docs":{},"控":{"docs":{},"制":{"docs":{},"器":{"docs":{},"选":{"docs":{},"择":{"docs":{},"推":{"docs":{},"理":{"docs":{},"流":{"docs":{},"，":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"生":{"docs":{},"成":{"docs":{},"隐":{"docs":{},"含":{"docs":{},"树":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"每":{"docs":{},"个":{"docs":{},"模":{"docs":{},"块":{"docs":{},"都":{"docs":{},"被":{"docs":{},"引":{"docs":{},"导":{"docs":{},"去":{"docs":{},"执":{"docs":{},"行":{"docs":{},"一":{"docs":{},"种":{"docs":{},"特":{"docs":{},"定":{"docs":{},"类":{"docs":{},"型":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"含":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"由":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"更":{"docs":{},"加":{"docs":{},"可":{"docs":{},"靠":{"docs":{},"和":{"docs":{},"有":{"docs":{},"效":{"docs":{},"。":{"docs":{},"【":{"docs":{},"结":{"docs":{},"果":{"docs":{},"】":{"docs":{},"在":{"docs":{},"标":{"docs":{},"准":{"docs":{},"基":{"docs":{},"准":{"docs":{},"测":{"docs":{},"试":{"docs":{},"上":{"docs":{},"的":{"docs":{},"实":{"docs":{},"验":{"docs":{},"结":{"docs":{},"果":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"仅":{"docs":{},"使":{"docs":{},"用":{"9":{"docs":{},"%":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"优":{"docs":{},"于":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{},"最":{"docs":{},"先":{"docs":{},"进":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"术":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"调":{"docs":{},"研":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":10}}}}}}}}}},"生":{"docs":{},"】":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"简":{"docs":{},"介":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":10}}}},"必":{"docs":{},"须":{"docs":{},"在":{"docs":{},"模":{"docs":{},"型":{"docs":{},"规":{"docs":{},"模":{"docs":{},"足":{"docs":{},"够":{"docs":{},"大":{"docs":{},"时":{"docs":{},"才":{"docs":{},"能":{"docs":{},"涌":{"docs":{},"现":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}},"提":{"docs":{},"示":{"docs":{},"会":{"docs":{},"在":{"docs":{},"给":{"docs":{},"出":{"docs":{},"答":{"docs":{},"案":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"还":{"docs":{},"会":{"docs":{},"自":{"docs":{},"动":{"docs":{},"给":{"docs":{},"出":{"docs":{},"推":{"docs":{},"理":{"docs":{},"步":{"docs":{},"骤":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}},"暴":{"docs":{},"露":{"docs":{},"了":{"docs":{},"它":{"docs":{},"，":{"docs":{},"依":{"docs":{},"然":{"docs":{},"是":{"docs":{},"鹦":{"docs":{},"鹉":{"docs":{},"学":{"docs":{},"舌":{"docs":{},"，":{"docs":{},"而":{"docs":{},"非":{"docs":{},"真":{"docs":{},"的":{"docs":{},"产":{"docs":{},"生":{"docs":{},"了":{"docs":{},"意":{"docs":{},"识":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"地":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"问":{"docs":{},"答":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}},"领":{"docs":{},"域":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{},"由":{"docs":{},"于":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"长":{"docs":{},"度":{"docs":{},"限":{"docs":{},"制":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"多":{"docs":{},"个":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"进":{"docs":{},"行":{"docs":{},"拆":{"docs":{},"分":{"docs":{},"成":{"docs":{},"段":{"docs":{},"落":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"g":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"）":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"利":{"docs":{},"用":{"docs":{},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"+":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"s":{"docs":{},"s":{"docs":{},"向":{"docs":{},"量":{"docs":{},"库":{"docs":{},"建":{"docs":{},"立":{"docs":{},"向":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"库":{"docs":{},"和":{"docs":{},"文":{"docs":{},"档":{"docs":{},"索":{"docs":{},"引":{"docs":{},"。":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"草":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"文":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"基":{"docs":{},"于":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"次":{"docs":{},"只":{"docs":{},"是":{"docs":{},"演":{"docs":{},"示":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"部":{"docs":{},"署":{"docs":{},"脚":{"docs":{},"本":{"docs":{},"加":{"docs":{},"载":{"docs":{},"本":{"docs":{},"地":{"docs":{},"模":{"docs":{},"型":{"docs":{},",":{"docs":{},"并":{"docs":{},"加":{"docs":{},"载":{"docs":{},"新":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"根":{"docs":{},"据":{"docs":{},"自":{"docs":{},"己":{"docs":{},"数":{"docs":{},"据":{"docs":{},"库":{"docs":{},"让":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"作":{"docs":{},"答":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":10.022222222222222}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"估":{"docs":{},"计":{"docs":{},"模":{"docs":{},"型":{"docs":{},"大":{"docs":{},"致":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}},"已":{"docs":{},"有":{"docs":{},"的":{"docs":{},"样":{"docs":{},"本":{"docs":{},"，":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"喂":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"4":{"docs":{},"进":{"docs":{},"行":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}},"docs":{}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"底":{"docs":{},"座":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}},"微":{"docs":{},"调":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}},"训":{"docs":{},"练":{"docs":{},"【":{"docs":{},"后":{"docs":{},"续":{"docs":{},"可":{"docs":{},"参":{"docs":{},"考":{"docs":{},"】":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}},"与":{"docs":{},"微":{"docs":{},"调":{"docs":{},"【":{"docs":{},"后":{"docs":{},"续":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"可":{"docs":{},"借":{"docs":{},"鉴":{"docs":{},"】":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}},"后":{"docs":{},"，":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"一":{"docs":{},"些":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"框":{"docs":{},"架":{"docs":{},"，":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{},"例":{"docs":{},"估":{"docs":{},"算":{"docs":{},"其":{"docs":{},"大":{"docs":{},"致":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"：":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"：":{"docs":{},"等":{"docs":{},"于":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"*":{"docs":{},"每":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"所":{"docs":{},"需":{"docs":{},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{},"大":{"docs":{},"致":{"docs":{},"需":{"docs":{},"要":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"署":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"测":{"docs":{},"试":{"docs":{},"和":{"docs":{},"评":{"docs":{},"估":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}},"的":{"docs":{},"格":{"docs":{},"式":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"将":{"docs":{},"文":{"docs":{},"本":{"docs":{},"和":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"在":{"docs":{},"一":{"docs":{},"起":{"docs":{},"，":{"docs":{},"用":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"分":{"docs":{},"隔":{"docs":{},"符":{"docs":{},"（":{"docs":{},"如":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"够":{"docs":{},"根":{"docs":{},"据":{"docs":{},"输":{"docs":{},"入":{"docs":{},"文":{"docs":{},"本":{"docs":{},"生":{"docs":{},"成":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"实":{"docs":{},"现":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.014925373134328358}}},"推":{"docs":{},"理":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"路":{"docs":{},"径":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}},"下":{"docs":{},"载":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"前":{"docs":{},"缀":{"docs":{},"长":{"docs":{},"度":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"名":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"准":{"docs":{},"备":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"评":{"docs":{},"估":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"路":{"docs":{},"径":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"前":{"docs":{},"面":{"docs":{},"描":{"docs":{},"述":{"docs":{},"的":{"docs":{},"三":{"docs":{},"个":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"插":{"docs":{},"入":{"docs":{},"检":{"docs":{},"索":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"3":{"docs":{},"（":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"针":{"docs":{},"对":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"毕":{"docs":{},"设":{"docs":{},"技":{"docs":{},"术":{"docs":{},"框":{"docs":{},"架":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":10}}}}}}}},"相":{"docs":{},"关":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"调":{"docs":{},"研":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":10}}}}}}},"技":{"docs":{},"术":{"docs":{},"调":{"docs":{},"研":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}},"神":{"docs":{},"奇":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"上":{"docs":{},"线":{"docs":{},"！":{"docs":{},"帮":{"docs":{},"你":{"docs":{},"把":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}},"再":{"docs":{},"谈":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"与":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"如":{"docs":{},"何":{"docs":{},"结":{"docs":{},"合":{"docs":{},"：":{"docs":{},"参":{"docs":{},"数":{"docs":{},"化":{"docs":{},"与":{"docs":{},"形":{"docs":{},"式":{"docs":{},"化":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"的":{"docs":{},"现":{"docs":{},"实":{"docs":{},"问":{"docs":{},"题":{"docs":{},"、":{"docs":{},"结":{"docs":{},"合":{"docs":{},"要":{"docs":{},"素":{"docs":{},"和":{"docs":{},"具":{"docs":{},"体":{"docs":{},"路":{"docs":{},"线":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"于":{"docs":{},"让":{"docs":{},"a":{"docs":{},"i":{"docs":{},"做":{"docs":{},"分":{"docs":{},"析":{"docs":{},"题":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"“":{"docs":{},"填":{"docs":{},"空":{"docs":{},"题":{"docs":{},"”":{"docs":{},"，":{"docs":{},"要":{"docs":{},"把":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"详":{"docs":{},"细":{"docs":{},"说":{"docs":{},"清":{"docs":{},"楚":{"docs":{},"，":{"docs":{},"按":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"得":{"docs":{},"分":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"给":{"docs":{},"出":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"似":{"docs":{},"的":{"docs":{},"技":{"docs":{},"术":{"docs":{},"，":{"docs":{},"针":{"docs":{},"对":{"docs":{},"中":{"docs":{},"文":{"docs":{},"问":{"docs":{},"答":{"docs":{},"和":{"docs":{},"对":{"docs":{},"话":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{},"经":{"docs":{},"过":{"docs":{},"约":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{},"点":{"docs":{},"：":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"v":{"docs":{},"s":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"本":{"docs":{},"质":{"docs":{},"上":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"；":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"遇":{"docs":{},"到":{"docs":{},"的":{"docs":{},"事":{"docs":{},"实":{"docs":{},"性":{"docs":{},"错":{"docs":{},"误":{"docs":{},"和":{"docs":{},"时":{"docs":{},"效":{"docs":{},"性":{"docs":{},"，":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"同":{"docs":{},"样":{"docs":{},"存":{"docs":{},"在":{"docs":{},"，":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"解":{"docs":{},"决":{"docs":{},"知":{"docs":{},"识":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"第":{"docs":{},"一":{"docs":{},"章":{"docs":{},"：":{"docs":{},"训":{"docs":{},"练":{"docs":{},"微":{"docs":{},"调":{"docs":{},"相":{"docs":{},"关":{"docs":{},"技":{"docs":{},"术":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"：":{"docs":{},"扩":{"docs":{},"充":{"docs":{},"法":{"docs":{},"律":{"docs":{},"领":{"docs":{},"域":{"docs":{},"词":{"docs":{},"表":{"docs":{},"，":{"docs":{},"在":{"docs":{},"大":{"docs":{},"规":{"docs":{},"模":{"docs":{},"法":{"docs":{},"律":{"docs":{},"文":{"docs":{},"书":{"docs":{},"及":{"docs":{},"法":{"docs":{},"典":{"docs":{},"数":{"docs":{},"据":{"docs":{},"上":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"三":{"docs":{},"章":{"docs":{},"：":{"docs":{},"数":{"docs":{},"据":{"docs":{},"底":{"docs":{},"座":{"docs":{},"方":{"docs":{},"法":{"docs":{},"与":{"docs":{},"调":{"docs":{},"研":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}}},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"称":{"docs":{},"为":{"docs":{},"渐":{"docs":{},"进":{"docs":{},"收":{"docs":{},"缩":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}},"二":{"docs":{},"章":{"docs":{},"：":{"docs":{},"如":{"docs":{},"何":{"docs":{},"定":{"docs":{},"制":{"docs":{},"化":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"：":{"docs":{},"构":{"docs":{},"造":{"docs":{},"法":{"docs":{},"律":{"docs":{},"领":{"docs":{},"域":{"docs":{},"对":{"docs":{},"话":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"在":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"指":{"docs":{},"令":{"docs":{},"精":{"docs":{},"调":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"四":{"docs":{},"章":{"docs":{},"：":{"docs":{},"其":{"docs":{},"他":{"docs":{},"相":{"docs":{},"关":{"docs":{},"知":{"docs":{},"识":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}}}}}}}}},"节":{"docs":{},"省":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"推":{"docs":{},"理":{"docs":{},"技":{"docs":{},"术":{"docs":{},"对":{"docs":{},"比":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":10}}}}}}}}}}}}}}},"训":{"docs":{},"练":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"部":{"docs":{},"署":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":5.001097694840834},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"羊":{"docs":{},"驼":{"docs":{"./":{"ref":"./","tf":0.017241379310344827},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":3.341145833333333}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"主":{"docs":{},"要":{"docs":{},"分":{"docs":{},"为":{"docs":{},"两":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"1":{"docs":{},".":{"docs":{},"律":{"docs":{},"师":{"docs":{},"和":{"docs":{},"用":{"docs":{},"户":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"情":{"docs":{},"景":{"docs":{},"对":{"docs":{},"话":{"docs":{},"；":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"下":{"docs":{},"载":{"docs":{},"存":{"docs":{},"放":{"docs":{},"路":{"docs":{},"径":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"示":{"docs":{},"例":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"技":{"docs":{},"术":{"docs":{},"：":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}},"模":{"docs":{},"型":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"完":{"docs":{},"成":{"docs":{},"后":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"进":{"docs":{},"行":{"docs":{},"模":{"docs":{},"型":{"docs":{},"评":{"docs":{},"估":{"docs":{},"和":{"docs":{},"调":{"docs":{},"整":{"docs":{},"。":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"一":{"docs":{},"些":{"docs":{},"指":{"docs":{},"标":{"docs":{},"来":{"docs":{},"评":{"docs":{},"估":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"集":{"docs":{},"、":{"1":{"docs":{},"g":{"docs":{},"b":{"docs":{},"开":{"docs":{},"发":{"docs":{},"集":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"docs":{}}},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"推":{"docs":{},"广":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"领":{"docs":{},"域":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}},"相":{"docs":{},"关":{"docs":{},"句":{"docs":{},"子":{"docs":{},"排":{"docs":{},"序":{"docs":{},"器":{"docs":{},"）":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"它":{"docs":{},"们":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"。":{"docs":{},"所":{"docs":{},"有":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"都":{"docs":{},"是":{"docs":{},"解":{"docs":{},"释":{"docs":{},"q":{"docs":{},"a":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"研":{"docs":{},"报":{"docs":{},"告":{"docs":{"./":{"ref":"./","tf":0.017241379310344827}}}}},"整":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}},"一":{"docs":{},"、":{"docs":{},"天":{"docs":{},"工":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"：":{"docs":{},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}},"本":{"docs":{},"草":{"docs":{},"医":{"docs":{},"学":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{},"基":{"docs":{},"于":{"docs":{},"中":{"docs":{},"文":{"docs":{},"医":{"docs":{},"学":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"+":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"6":{"docs":{},"g":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}},"docs":{}}}}}}}}}}}},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"q":{"docs":{},"a":{"docs":{},"：":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"q":{"docs":{},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}},"摘":{"docs":{},"要":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}},"下":{"docs":{},"；":{"docs":{},"同":{"docs":{},"样":{"docs":{},"，":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}},"样":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"些":{"docs":{},"值":{"docs":{},"得":{"docs":{},"注":{"docs":{},"意":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}},"主":{"docs":{},"要":{"docs":{},"特":{"docs":{},"点":{"docs":{},"：":{"docs":{},"从":{"docs":{},"提":{"docs":{},"问":{"docs":{},"中":{"docs":{},"抽":{"docs":{},"取":{"docs":{},"出":{"docs":{},"关":{"docs":{},"键":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"进":{"docs":{},"行":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"。":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"实":{"docs":{},"现":{"docs":{},"原":{"docs":{},"理":{"docs":{},"：":{"docs":{},"将":{"docs":{},"文":{"docs":{},"章":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"割":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"与":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"进":{"docs":{},"行":{"docs":{},"查":{"docs":{},"询":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"，":{"docs":{},"将":{"docs":{},"相":{"docs":{},"关":{"docs":{},"段":{"docs":{},"落":{"docs":{},"返":{"docs":{},"回":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"中":{"docs":{},"得":{"docs":{},"到":{"docs":{},"最":{"docs":{},"后":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"二":{"docs":{},"、":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"天":{"docs":{},"工":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"：":{"docs":{},"天":{"docs":{},"宫":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"w":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"估":{"docs":{},"算":{"docs":{},"模":{"docs":{},"型":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"：":{"docs":{},"参":{"docs":{},"数":{"docs":{},"个":{"docs":{},"数":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"+":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"2":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"斯":{"docs":{},"坦":{"docs":{},"福":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}},"docs":{}}}}}},"综":{"docs":{},"述":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}},"解":{"docs":{},"释":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}},"实":{"docs":{},"测":{"docs":{},"体":{"docs":{},"验":{"docs":{},"：":{"docs":{},"速":{"docs":{},"度":{"docs":{},"较":{"docs":{},"慢":{"docs":{},"，":{"docs":{},"生":{"docs":{},"成":{"docs":{},"效":{"docs":{},"果":{"docs":{},"如":{"docs":{},"下":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{},"主":{"docs":{},"要":{"docs":{},"包":{"docs":{},"括":{"docs":{},"文":{"docs":{},"本":{"docs":{},"信":{"docs":{},"息":{"docs":{},"+":{"docs":{},"相":{"docs":{},"关":{"docs":{},"扩":{"docs":{},"展":{"docs":{},"链":{"docs":{},"接":{"docs":{},"。":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"现":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"例":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"概":{"docs":{},"述":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}},"：":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}},"一":{"docs":{},"个":{"docs":{},"典":{"docs":{},"型":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"类":{"docs":{},"似":{"docs":{},"应":{"docs":{},"用":{"docs":{},"，":{"docs":{},"类":{"docs":{},"似":{"docs":{},"相":{"docs":{},"关":{"docs":{},"项":{"docs":{},"目":{"docs":{},"很":{"docs":{},"多":{"docs":{},"如":{"docs":{},"：":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"主":{"docs":{},"体":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"环":{"docs":{},"境":{"docs":{},"工":{"docs":{},"程":{"docs":{},"、":{"docs":{},"生":{"docs":{},"态":{"docs":{},"学":{"docs":{},"相":{"docs":{},"关":{"docs":{},"领":{"docs":{},"域":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"将":{"docs":{},"一":{"docs":{},"个":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"推":{"docs":{},"理":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"分":{"docs":{},"解":{"docs":{},"成":{"docs":{},"了":{"docs":{},"多":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"来":{"docs":{},"一":{"docs":{},"步":{"docs":{},"步":{"docs":{},"进":{"docs":{},"行":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"就":{"docs":{},"有":{"docs":{},"着":{"docs":{},"更":{"docs":{},"加":{"docs":{},"清":{"docs":{},"晰":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"链":{"docs":{},"路":{"docs":{},"，":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"一":{"docs":{},"定":{"docs":{},"的":{"docs":{},"可":{"docs":{},"解":{"docs":{},"释":{"docs":{},"性":{"docs":{},"，":{"docs":{},"让":{"docs":{},"人":{"docs":{},"知":{"docs":{},"道":{"docs":{},"答":{"docs":{},"案":{"docs":{},"是":{"docs":{},"怎":{"docs":{},"么":{"docs":{},"来":{"docs":{},"的":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"语":{"docs":{},"料":{"docs":{},"微":{"docs":{},"调":{"docs":{},"训":{"docs":{},"练":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"提":{"docs":{},"供":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"页":{"docs":{},"面":{"docs":{},"。":{"docs":{"天工GPT调研/天工GPT调研.html":{"ref":"天工GPT调研/天工GPT调研.html","tf":0.043478260869565216}}}}}}}}}}}}}}}}}}}}}}}}}},"库":{"docs":{},"加":{"docs":{},"上":{"docs":{},"注":{"docs":{},"释":{"docs":{},"器":{"docs":{},"创":{"docs":{},"建":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"其":{"docs":{},"他":{"docs":{},"科":{"docs":{},"学":{"docs":{},"事":{"docs":{},"实":{"docs":{},"；":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"都":{"docs":{},"是":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"\"":{"docs":{},"偏":{"docs":{},"头":{"docs":{},"痛":{"docs":{},"\"":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}},"内":{"docs":{},"科":{"docs":{},"\"":{"docs":{},"]":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}},"发":{"docs":{},"病":{"docs":{},"部":{"docs":{},"位":{"docs":{},"\"":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"头":{"docs":{},"部":{"docs":{},"及":{"docs":{},"眼":{"docs":{},"后":{"docs":{},"部":{"docs":{},"疼":{"docs":{},"痛":{"docs":{},"并":{"docs":{},"能":{"docs":{},"听":{"docs":{},"到":{"docs":{},"连":{"docs":{},"续":{"docs":{},"不":{"docs":{},"断":{"docs":{},"的":{"docs":{},"隆":{"docs":{},"隆":{"docs":{},"声":{"docs":{},"\"":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}},"恶":{"docs":{},"寒":{"docs":{},"发":{"docs":{},"热":{"docs":{},"\"":{"docs":{},"]":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}},"所":{"docs":{},"属":{"docs":{},"科":{"docs":{},"室":{"docs":{},"\"":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"晨":{"docs":{},"起":{"docs":{},"头":{"docs":{},"痛":{"docs":{},"加":{"docs":{},"重":{"docs":{},"\"":{"docs":{},"]":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}},"相":{"docs":{},"关":{"docs":{},"疾":{"docs":{},"病":{"docs":{},"\"":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}},"症":{"docs":{},"状":{"docs":{},"\"":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"一":{"docs":{},"位":{"docs":{},"年":{"docs":{},"轻":{"docs":{},"男":{"docs":{},"性":{"docs":{},"长":{"docs":{},"期":{"docs":{},"使":{"docs":{},"用":{"docs":{},"可":{"docs":{},"卡":{"docs":{},"因":{"docs":{},"，":{"docs":{},"突":{"docs":{},"然":{"docs":{},"出":{"docs":{},"现":{"docs":{},"胸":{"docs":{},"痛":{"docs":{},"、":{"docs":{},"呕":{"docs":{},"吐":{"docs":{},"、":{"docs":{},"出":{"docs":{},"汗":{"docs":{},"等":{"docs":{},"症":{"docs":{},"状":{"docs":{},"，":{"docs":{},"经":{"docs":{},"检":{"docs":{},"查":{"docs":{},"发":{"docs":{},"现":{"docs":{},"心":{"docs":{},"电":{"docs":{},"图":{"docs":{},"反":{"docs":{},"映":{"docs":{},"心":{"docs":{},"肌":{"docs":{},"急":{"docs":{},"性":{"docs":{},"损":{"docs":{},"伤":{"docs":{},"，":{"docs":{},"请":{"docs":{},"问":{"docs":{},"可":{"docs":{},"能":{"docs":{},"患":{"docs":{},"的":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"疾":{"docs":{},"病":{"docs":{},"？":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"方":{"docs":{},"式":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"？":{"docs":{},"\"":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},".":{"docs":{},"/":{"docs":{},".":{"docs":{},".":{"docs":{},"/":{"docs":{},".":{"docs":{},".":{"docs":{},"/":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"/":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"/":{"docs":{},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}},"e":{"docs":{},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"\"":{"docs":{},")":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"是":{"docs":{},"谁":{"docs":{},"\"":{"docs":{},")":{"docs":{},")":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"修":{"docs":{},"身":{"docs":{},"修":{"docs":{},"身":{"docs":{},"的":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},">":{"docs":{},",":{"docs":{},"这":{"docs":{},"款":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},">":{"docs":{},"感":{"docs":{},"感":{"docs":{},",":{"docs":{},"加":{"docs":{},"上":{"docs":{},"加":{"docs":{},"上":{"docs":{},"性":{"docs":{},"感":{"docs":{},"的":{"docs":{},"面":{"docs":{},"料":{"docs":{},",":{"docs":{},"展":{"docs":{},"现":{"docs":{},"气":{"docs":{},"质":{"docs":{},",":{"docs":{},"整":{"docs":{},"体":{"docs":{},"整":{"docs":{},"体":{"docs":{},"整":{"docs":{},"体":{"docs":{},"性":{"docs":{},"感":{"docs":{},",":{"docs":{},"展":{"docs":{},"现":{"docs":{},"彰":{"docs":{},"显":{"docs":{},"修":{"docs":{},"饰":{"docs":{},"修":{"docs":{},"饰":{"docs":{},"的":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},">":{"docs":{},"。":{"docs":{},"加":{"docs":{},"上":{"docs":{},"加":{"docs":{},"上":{"docs":{},"气":{"docs":{},"质":{"docs":{},",":{"docs":{},"让":{"docs":{},"简":{"docs":{},"约":{"docs":{},"设":{"docs":{},"计":{"docs":{},",":{"docs":{},"穿":{"docs":{},"着":{"docs":{},"穿":{"docs":{},"着":{"docs":{},"设":{"docs":{},"计":{"docs":{},",":{"docs":{},"搭":{"docs":{},"配":{"docs":{},"搭":{"docs":{},"配":{"docs":{},"。":{"docs":{},"\"":{"docs":{},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"宽":{"docs":{},"松":{"docs":{},"的":{"docs":{},"阔":{"docs":{},"腿":{"docs":{},"裤":{"docs":{},"这":{"docs":{},"两":{"docs":{},"年":{"docs":{},"真":{"docs":{},"的":{"docs":{},"吸":{"docs":{},"粉":{"docs":{},"不":{"docs":{},"少":{"docs":{},"，":{"docs":{},"明":{"docs":{},"星":{"docs":{},"时":{"docs":{},"尚":{"docs":{},"达":{"docs":{},"人":{"docs":{},"的":{"docs":{},"心":{"docs":{},"头":{"docs":{},"爱":{"docs":{},"。":{"docs":{},"毕":{"docs":{},"竟":{"docs":{},"好":{"docs":{},"穿":{"docs":{},"时":{"docs":{},"尚":{"docs":{},"，":{"docs":{},"谁":{"docs":{},"都":{"docs":{},"能":{"docs":{},"穿":{"docs":{},"出":{"docs":{},"腿":{"docs":{},"长":{"2":{"docs":{},"米":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"宽":{"docs":{},"松":{"docs":{},"的":{"docs":{},"裤":{"docs":{},"腿":{"docs":{},"，":{"docs":{},"当":{"docs":{},"然":{"docs":{},"是":{"docs":{},"遮":{"docs":{},"肉":{"docs":{},"小":{"docs":{},"能":{"docs":{},"手":{"docs":{},"啊":{"docs":{},"。":{"docs":{},"上":{"docs":{},"身":{"docs":{},"随":{"docs":{},"性":{"docs":{},"自":{"docs":{},"然":{"docs":{},"不":{"docs":{},"拘":{"docs":{},"束":{"docs":{},"，":{"docs":{},"面":{"docs":{},"料":{"docs":{},"亲":{"docs":{},"肤":{"docs":{},"舒":{"docs":{},"适":{"docs":{},"贴":{"docs":{},"身":{"docs":{},"体":{"docs":{},"验":{"docs":{},"感":{"docs":{},"棒":{"docs":{},"棒":{"docs":{},"哒":{"docs":{},"。":{"docs":{},"系":{"docs":{},"带":{"docs":{},"部":{"docs":{},"分":{"docs":{},"增":{"docs":{},"加":{"docs":{},"设":{"docs":{},"计":{"docs":{},"看":{"docs":{},"点":{"docs":{},"，":{"docs":{},"还":{"docs":{},"让":{"docs":{},"单":{"docs":{},"品":{"docs":{},"的":{"docs":{},"设":{"docs":{},"计":{"docs":{},"感":{"docs":{},"更":{"docs":{},"强":{"docs":{},"。":{"docs":{},"腿":{"docs":{},"部":{"docs":{},"线":{"docs":{},"条":{"docs":{},"若":{"docs":{},"隐":{"docs":{},"若":{"docs":{},"现":{"docs":{},"的":{"docs":{},"，":{"docs":{},"性":{"docs":{},"感":{"docs":{},"撩":{"docs":{},"人":{"docs":{},"。":{"docs":{},"颜":{"docs":{},"色":{"docs":{},"敲":{"docs":{},"温":{"docs":{},"柔":{"docs":{},"的":{"docs":{},"，":{"docs":{},"与":{"docs":{},"裤":{"docs":{},"子":{"docs":{},"本":{"docs":{},"身":{"docs":{},"所":{"docs":{},"呈":{"docs":{},"现":{"docs":{},"的":{"docs":{},"风":{"docs":{},"格":{"docs":{},"有":{"docs":{},"点":{"docs":{},"反":{"docs":{},"差":{"docs":{},"萌":{"docs":{},"。":{"docs":{},"\"":{"docs":{},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"简":{"docs":{},"约":{"docs":{},"而":{"docs":{},"不":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"牛":{"docs":{},"仔":{"docs":{},"外":{"docs":{},"套":{"docs":{},",":{"docs":{},"白":{"docs":{},"色":{"docs":{},"的":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"十":{"docs":{},"分":{"docs":{},"百":{"docs":{},"搭":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"多":{"docs":{},"处":{"docs":{},"有":{"docs":{},"做":{"docs":{},"旧":{"docs":{},"破":{"docs":{},"洞":{"docs":{},"设":{"docs":{},"计":{"docs":{},",":{"docs":{},"打":{"docs":{},"破":{"docs":{},"单":{"docs":{},"调":{"docs":{},"乏":{"docs":{},"味":{"docs":{},",":{"docs":{},"增":{"docs":{},"加":{"docs":{},"一":{"docs":{},"丝":{"docs":{},"造":{"docs":{},"型":{"docs":{},"看":{"docs":{},"点":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"后":{"docs":{},"背":{"docs":{},"处":{"docs":{},"有":{"docs":{},"趣":{"docs":{},"味":{"docs":{},"刺":{"docs":{},"绣":{"docs":{},"装":{"docs":{},"饰":{"docs":{},",":{"docs":{},"丰":{"docs":{},"富":{"docs":{},"层":{"docs":{},"次":{"docs":{},"感":{"docs":{},",":{"docs":{},"彰":{"docs":{},"显":{"docs":{},"别":{"docs":{},"样":{"docs":{},"时":{"docs":{},"尚":{"docs":{},"。":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"白":{"docs":{},"色":{"docs":{},"的":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"十":{"docs":{},"分":{"docs":{},"百":{"docs":{},"搭":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"多":{"docs":{},"处":{"docs":{},"有":{"docs":{},"做":{"docs":{},"旧":{"docs":{},"破":{"docs":{},"洞":{"docs":{},"设":{"docs":{},"计":{"docs":{},"，":{"docs":{},"打":{"docs":{},"破":{"docs":{},"单":{"docs":{},"调":{"docs":{},"乏":{"docs":{},"味":{"docs":{},"，":{"docs":{},"增":{"docs":{},"加":{"docs":{},"一":{"docs":{},"丝":{"docs":{},"造":{"docs":{},"型":{"docs":{},"看":{"docs":{},"点":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"后":{"docs":{},"背":{"docs":{},"处":{"docs":{},"有":{"docs":{},"趣":{"docs":{},"味":{"docs":{},"刺":{"docs":{},"绣":{"docs":{},"装":{"docs":{},"饰":{"docs":{},"，":{"docs":{},"丰":{"docs":{},"富":{"docs":{},"层":{"docs":{},"次":{"docs":{},"感":{"docs":{},"，":{"docs":{},"彰":{"docs":{},"显":{"docs":{},"别":{"docs":{},"样":{"docs":{},"时":{"docs":{},"尚":{"docs":{},"。":{"docs":{},"\"":{"docs":{},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"型":{"docs":{},"#":{"docs":{},"上":{"docs":{},"衣":{"docs":{},"*":{"docs":{},"材":{"docs":{},"质":{"docs":{},"#":{"docs":{},"牛":{"docs":{},"仔":{"docs":{},"布":{"docs":{},"*":{"docs":{},"颜":{"docs":{},"色":{"docs":{},"#":{"docs":{},"白":{"docs":{},"色":{"docs":{},"*":{"docs":{},"风":{"docs":{},"格":{"docs":{},"#":{"docs":{},"简":{"docs":{},"约":{"docs":{},"*":{"docs":{},"图":{"docs":{},"案":{"docs":{},"#":{"docs":{},"刺":{"docs":{},"绣":{"docs":{},"*":{"docs":{},"衣":{"docs":{},"样":{"docs":{},"式":{"docs":{},"#":{"docs":{},"外":{"docs":{},"套":{"docs":{},"*":{"docs":{},"衣":{"docs":{},"款":{"docs":{},"式":{"docs":{},"#":{"docs":{},"破":{"docs":{},"洞":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"裤":{"docs":{},"*":{"docs":{},"版":{"docs":{},"型":{"docs":{},"#":{"docs":{},"宽":{"docs":{},"松":{"docs":{},"*":{"docs":{},"风":{"docs":{},"格":{"docs":{},"#":{"docs":{},"性":{"docs":{},"感":{"docs":{},"*":{"docs":{},"图":{"docs":{},"案":{"docs":{},"#":{"docs":{},"线":{"docs":{},"条":{"docs":{},"*":{"docs":{},"裤":{"docs":{},"型":{"docs":{},"#":{"docs":{},"阔":{"docs":{},"腿":{"docs":{},"裤":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"x":{"docs":{},"i":{"docs":{},"d":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"1":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"2":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"3":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"docs":{}}}}}}}}}}},"o":{"docs":{},"x":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"y":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\"":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}},"'":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"多":{"docs":{},"少":{"docs":{},"钱":{"docs":{},"呢":{"docs":{},"'":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"大":{"docs":{},"概":{"docs":{},"金":{"docs":{},"额":{"docs":{},"多":{"docs":{},"少":{"docs":{},"？":{"docs":{},"'":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}},"律":{"docs":{},"师":{"docs":{},"费":{"docs":{},"诉":{"docs":{},"讼":{"docs":{},"费":{"docs":{},"都":{"docs":{},"非":{"docs":{},"常":{"docs":{},"少":{"docs":{},"都":{"docs":{},"很":{"docs":{},"合":{"docs":{},"理":{"docs":{},"，":{"docs":{},"一":{"docs":{},"定":{"docs":{},"要":{"docs":{},"起":{"docs":{},"诉":{"docs":{},"。":{"docs":{},"'":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}},"您":{"docs":{},"好":{"docs":{},"，":{"docs":{},"建":{"docs":{},"议":{"docs":{},"尽":{"docs":{},"量":{"docs":{},"协":{"docs":{},"商":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"协":{"docs":{},"商":{"docs":{},"不":{"docs":{},"成":{"docs":{},"可":{"docs":{},"起":{"docs":{},"诉":{"docs":{},"'":{"docs":{},"]":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"看":{"docs":{},"标":{"docs":{},"的":{"docs":{},"额":{"docs":{},"和":{"docs":{},"案":{"docs":{},"情":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"程":{"docs":{},"度":{"docs":{},"，":{"docs":{},"建":{"docs":{},"议":{"docs":{},"细":{"docs":{},"致":{"docs":{},"面":{"docs":{},"谈":{"docs":{},"'":{"docs":{},"]":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"/":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"'":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}}}}}}}}}}},"t":{"docs":{},"l":{"docs":{},"o":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.006586169045005488}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"'":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}},"*":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{},"*":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.019230769230769232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"s":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},".":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"/":{"docs":{},"s":{"docs":{},"c":{"docs":{},"r":{"docs":{},"i":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"/":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"/":{"docs":{},"$":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}},".":{"docs":{},"/":{"docs":{},".":{"docs":{},".":{"docs":{},"/":{"docs":{},".":{"docs":{},".":{"docs":{},"/":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"/":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.019230769230769232}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"/":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.007683863885839737}}}}}}}}}}}}}}}}}}}}}}}}}},"[":{"3":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"5":{"docs":{},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"\"":{"docs":{},"中":{"docs":{},"西":{"docs":{},"医":{"docs":{},"结":{"docs":{},"合":{"docs":{},"科":{"docs":{},"\"":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}},"头":{"docs":{},"部":{"docs":{},"\"":{"docs":{},"]":{"docs":{},"}":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}},"妊":{"docs":{},"娠":{"docs":{},"合":{"docs":{},"并":{"docs":{},"偏":{"docs":{},"头":{"docs":{},"痛":{"docs":{},"\"":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}},"皮":{"docs":{},"肤":{"docs":{},"变":{"docs":{},"硬":{"docs":{},"\"":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}},"'":{"docs":{},"您":{"docs":{},"好":{"docs":{},"，":{"docs":{},"建":{"docs":{},"议":{"docs":{},"协":{"docs":{},"商":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"对":{"docs":{},"方":{"docs":{},"告":{"docs":{},"了":{"docs":{},"你":{"docs":{},"们":{"docs":{},"，":{"docs":{},"就":{"docs":{},"只":{"docs":{},"能":{"docs":{},"积":{"docs":{},"极":{"docs":{},"应":{"docs":{},"诉":{"docs":{},"了":{"docs":{},"。":{"docs":{},"'":{"docs":{},",":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"欠":{"docs":{},"款":{"docs":{},"金":{"docs":{},"额":{"docs":{},"是":{"docs":{},"多":{"docs":{},"少":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"+":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{},"\\":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"]":{"docs":{},"/":{"1":{"0":{"2":{"4":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625}}}}}}}}}},"c":{"docs":{},"k":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"，":{"docs":{},"设":{"docs":{},"置":{"docs":{},"模":{"docs":{},"型":{"docs":{},"精":{"docs":{},"度":{"docs":{},"，":{"docs":{},"选":{"docs":{},"择":{"docs":{},"微":{"docs":{},"调":{"docs":{},"方":{"docs":{},"法":{"docs":{},"和":{"docs":{},"参":{"docs":{},"数":{"docs":{},"分":{"docs":{},"布":{"docs":{},"方":{"docs":{},"法":{"docs":{},"等":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"n":{"docs":{},"k":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"，":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"用":{"docs":{},"于":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"s":{"docs":{},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644}}},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"e":{"docs":{},"s":{"docs":{},"量":{"docs":{},"化":{"docs":{},"方":{"docs":{},"法":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588}},".":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"s":{"docs":{},".":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}}}},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"出":{"docs":{},"现":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"k":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"k":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"k":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"7":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"设":{"docs":{},"计":{"docs":{},"为":{"docs":{},"展":{"docs":{},"示":{"docs":{},"多":{"docs":{},"种":{"docs":{},"对":{"docs":{},"话":{"docs":{},"模":{"docs":{},"式":{"docs":{},"，":{"docs":{},"如":{"docs":{},"展":{"docs":{},"示":{"docs":{},"个":{"docs":{},"性":{"docs":{},"、":{"docs":{},"表":{"docs":{},"达":{"docs":{},"同":{"docs":{},"理":{"docs":{},"心":{"docs":{},"和":{"docs":{},"展":{"docs":{},"示":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}},":":{"docs":{},"昨":{"docs":{},"天":{"docs":{},"把":{"docs":{},"人":{"docs":{},"家":{"docs":{},"车":{"docs":{},"刮":{"docs":{},"了":{"docs":{},",":{"docs":{},"要":{"docs":{},"赔":{"docs":{},"多":{"docs":{},"少":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}},"朋":{"docs":{},"友":{"docs":{},"欠":{"docs":{},"钱":{"docs":{},"不":{"docs":{},"还":{"docs":{},"咋":{"docs":{},"办":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"矢":{"docs":{},"量":{"docs":{},"量":{"docs":{},"化":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}},"_":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"s":{"docs":{},"o":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"s":{"docs":{},"o":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"和":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"o":{"docs":{},"。":{"docs":{},"说":{"docs":{},"明":{"docs":{},"编":{"docs":{},"译":{"docs":{},"成":{"docs":{},"功":{"docs":{},"，":{"docs":{},"后":{"docs":{},"面":{"docs":{},"我":{"docs":{},"们":{"docs":{},"手":{"docs":{},"动":{"docs":{},"载":{"docs":{},"入":{"docs":{},"即":{"docs":{},"可":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.04878048780487805}},"对":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"v":{"0":{"docs":{},".":{"3":{"docs":{},".":{"docs":{},"t":{"docs":{},"g":{"docs":{},"z":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"docs":{}}},"1":{"0":{"0":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"docs":{}},"docs":{}},"2":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}},".":{"0":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"]":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"；":{"docs":{},"开":{"docs":{},"发":{"docs":{},"集":{"docs":{},"[":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"r":{"docs":{},"a":{"docs":{},"j":{"docs":{},"p":{"docs":{},"u":{"docs":{},"r":{"docs":{},"k":{"docs":{},"a":{"docs":{},"r":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}}}}}}}},"”":{"docs":{},"测":{"docs":{},"试":{"docs":{},"是":{"docs":{},"否":{"docs":{},"成":{"docs":{},"功":{"docs":{},"即":{"docs":{},"可":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"i":{"docs":{},"c":{"docs":{},"u":{"docs":{},"n":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"{":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"\"":{"docs":{},"中":{"docs":{},"心":{"docs":{},"词":{"docs":{},"\"":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}},"'":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"'":{"docs":{},":":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}}}}}},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"​":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"展":{"docs":{},"示":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}},"了":{"docs":{},"两":{"docs":{},"个":{"docs":{},"方":{"docs":{},"法":{"docs":{},"最":{"docs":{},"大":{"docs":{},"程":{"docs":{},"度":{"docs":{},"地":{"docs":{},"降":{"docs":{},"低":{"docs":{},"了":{"docs":{},"其":{"docs":{},"带":{"docs":{},"来":{"docs":{},"的":{"docs":{},"误":{"docs":{},"差":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"准":{"docs":{},"备":{"docs":{},"好":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"和":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"格":{"docs":{},"式":{"docs":{},"，":{"docs":{},"对":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{},"后":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}},"你":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}},"k":{"docs":{},"a":{"docs":{},"g":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},"部":{"docs":{},"署":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"访":{"docs":{},"问":{"docs":{},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{},"交":{"docs":{},"互":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}},"最":{"docs":{},"先":{"docs":{},"进":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"模":{"docs":{},"型":{"docs":{},"基":{"docs":{},"线":{"docs":{},"结":{"docs":{},"果":{"docs":{},"表":{"docs":{},"明":{"docs":{},"可":{"docs":{},"以":{"docs":{},"生":{"docs":{},"成":{"docs":{},"合":{"docs":{},"理":{"docs":{},"树":{"docs":{},"，":{"docs":{},"特":{"docs":{},"别":{"docs":{},"是":{"docs":{},"当":{"docs":{},"提":{"docs":{},"供":{"docs":{},"必":{"docs":{},"要":{"docs":{},"的":{"docs":{},"原":{"docs":{},"始":{"docs":{},"事":{"docs":{},"实":{"docs":{},"作":{"docs":{},"为":{"docs":{},"模":{"docs":{},"型":{"docs":{},"输":{"docs":{},"入":{"docs":{},"时":{"docs":{},"（":{"docs":{},"导":{"docs":{},"致":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"了":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"，":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"还":{"docs":{},"是":{"docs":{},"没":{"docs":{},"有":{"docs":{},"真":{"docs":{},"正":{"docs":{},"理":{"docs":{},"解":{"docs":{},"数":{"docs":{},"学":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"，":{"docs":{},"不":{"docs":{},"知":{"docs":{},"道":{"docs":{},"加":{"docs":{},"减":{"docs":{},"乘":{"docs":{},"除":{"docs":{},"的":{"docs":{},"真":{"docs":{},"实":{"docs":{},"意":{"docs":{},"义":{"docs":{},"，":{"docs":{},"只":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"更":{"docs":{},"精":{"docs":{},"细":{"docs":{},"的":{"docs":{},"叠":{"docs":{},"加":{"docs":{},"来":{"docs":{},"“":{"docs":{},"照":{"docs":{},"葫":{"docs":{},"芦":{"docs":{},"画":{"docs":{},"瓢":{"docs":{},"”":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"有":{"docs":{},"精":{"docs":{},"确":{"docs":{},"要":{"docs":{},"求":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"还":{"docs":{},"要":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"探":{"docs":{},"索":{"docs":{},"新":{"docs":{},"的":{"docs":{},"技":{"docs":{},"术":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"医":{"docs":{},"学":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}},"可":{"docs":{},"能":{"docs":{},"患":{"docs":{},"的":{"docs":{},"是":{"docs":{},"心":{"docs":{},"肌":{"docs":{},"梗":{"docs":{},"塞":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"进":{"docs":{},"行":{"docs":{},"维":{"docs":{},"拉":{"docs":{},"帕":{"docs":{},"米":{"docs":{},"、":{"docs":{},"依":{"docs":{},"普":{"docs":{},"利":{"docs":{},"酮":{"docs":{},"、":{"docs":{},"硝":{"docs":{},"酸":{"docs":{},"甘":{"docs":{},"油":{"docs":{},"、":{"docs":{},"ß":{"docs":{},"阻":{"docs":{},"滞":{"docs":{},"剂":{"docs":{},"、":{"docs":{},"吗":{"docs":{},"啡":{"docs":{},"等":{"docs":{},"药":{"docs":{},"物":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"，":{"docs":{},"并":{"docs":{},"进":{"docs":{},"行":{"docs":{},"溶":{"docs":{},"栓":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"、":{"docs":{},"低":{"docs":{},"分":{"docs":{},"子":{"docs":{},"量":{"docs":{},"肝":{"docs":{},"素":{"docs":{},"、":{"docs":{},"钙":{"docs":{},"通":{"docs":{},"道":{"docs":{},"阻":{"docs":{},"滞":{"docs":{},"剂":{"docs":{},"等":{"docs":{},"辅":{"docs":{},"助":{"docs":{},"治":{"docs":{},"疗":{"docs":{},"。":{"docs":{},"此":{"docs":{},"外":{"docs":{},"需":{"docs":{},"要":{"docs":{},"及":{"docs":{},"时":{"docs":{},"停":{"docs":{},"用":{"docs":{},"可":{"docs":{},"卡":{"docs":{},"因":{"docs":{},"等":{"docs":{},"药":{"docs":{},"物":{"docs":{},"，":{"docs":{},"以":{"docs":{},"防":{"docs":{},"止":{"docs":{},"病":{"docs":{},"情":{"docs":{},"加":{"docs":{},"重":{"docs":{},"。":{"docs":{},"\"":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616},"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"人":{"docs":{},"工":{"docs":{},"标":{"docs":{},"记":{"docs":{},"团":{"docs":{},"队":{"docs":{},"来":{"docs":{},"运":{"docs":{},"行":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}},"回":{"docs":{},"答":{"docs":{},":":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}},"垂":{"docs":{},"直":{"docs":{},"领":{"docs":{},"域":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{},"介":{"docs":{},"绍":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}},"张":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"指":{"docs":{},"令":{"docs":{},"微":{"docs":{},"调":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"q":{"docs":{},"a":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}},"的":{"docs":{},"动":{"docs":{},"机":{"docs":{},"是":{"docs":{},"提":{"docs":{},"高":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"对":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"指":{"docs":{},"令":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"支":{"docs":{},"持":{"docs":{},"使":{"docs":{},"用":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"，":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"按":{"docs":{},"照":{"docs":{},".":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"格":{"docs":{},"式":{"docs":{},"构":{"docs":{},"建":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"执":{"docs":{},"行":{"docs":{},"命":{"docs":{},"令":{"docs":{},"：":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.019230769230769232}},"，":{"docs":{},"将":{"docs":{},"解":{"docs":{},"压":{"docs":{},"后":{"docs":{},"的":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}},"更":{"docs":{},"现":{"docs":{},"实":{"docs":{},"、":{"docs":{},"更":{"docs":{},"具":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"性":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"【":{"docs":{},"维":{"docs":{},"基":{"docs":{},"百":{"docs":{},"科":{"docs":{},"】":{"docs":{},"【":{"docs":{},"英":{"docs":{},"文":{"docs":{},"】":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"c":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"2":{"0":{"1":{"9":{"docs":{},"/":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"s":{"docs":{},".":{"docs":{},"m":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{},"m":{"docs":{},"u":{"docs":{},".":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"s":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"v":{"1":{"docs":{},".":{"1":{"docs":{},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"i":{"2":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"docs":{}}},"q":{"docs":{},"a":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}},"p":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"q":{"docs":{},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"[":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"r":{"docs":{},"a":{"docs":{},"j":{"docs":{},"p":{"docs":{},"u":{"docs":{},"r":{"docs":{},"k":{"docs":{},"a":{"docs":{},"r":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"u":{"docs":{},"d":{"docs":{},".":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"/":{"docs":{},"v":{"1":{"docs":{},".":{"0":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}},"描":{"docs":{},"述":{"docs":{},"：":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"o":{"docs":{},"t":{"docs":{},"q":{"docs":{},"a":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"n":{"docs":{},"q":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"包":{"docs":{},"含":{"docs":{},"来":{"docs":{},"自":{"docs":{},"真":{"docs":{},"实":{"docs":{},"用":{"docs":{},"户":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"它":{"docs":{},"要":{"docs":{},"求":{"docs":{},"q":{"docs":{},"a":{"docs":{},"系":{"docs":{},"统":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"和":{"docs":{},"理":{"docs":{},"解":{"docs":{},"整":{"docs":{},"个":{"docs":{},"维":{"docs":{},"基":{"docs":{},"百":{"docs":{},"科":{"docs":{},"文":{"docs":{},"章":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"可":{"docs":{},"能":{"docs":{},"包":{"docs":{},"含":{"docs":{},"也":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"包":{"docs":{},"含":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{},"包":{"docs":{},"含":{"docs":{},"真":{"docs":{},"实":{"docs":{},"的":{"docs":{},"用":{"docs":{},"户":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"以":{"docs":{},"及":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"应":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"整":{"docs":{},"个":{"docs":{},"页":{"docs":{},"面":{"docs":{},"以":{"docs":{},"找":{"docs":{},"到":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"要":{"docs":{},"求":{"docs":{},"，":{"docs":{},"使":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"q":{"docs":{},"a":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"使":{"docs":{},"用":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"回":{"docs":{},"答":{"docs":{},"是":{"docs":{},"/":{"docs":{},"否":{"docs":{},"/":{"docs":{},"也":{"docs":{},"许":{"docs":{},"的":{"docs":{},"研":{"docs":{},"究":{"docs":{},"问":{"docs":{},"题":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"：":{"docs":{},"术":{"docs":{},"前":{"docs":{},"他":{"docs":{},"汀":{"docs":{},"类":{"docs":{},"药":{"docs":{},"物":{"docs":{},"是":{"docs":{},"否":{"docs":{},"会":{"docs":{},"减":{"docs":{},"少":{"docs":{},"冠":{"docs":{},"状":{"docs":{},"动":{"docs":{},"脉":{"docs":{},"旁":{"docs":{},"路":{"docs":{},"移":{"docs":{},"植":{"docs":{},"术":{"docs":{},"后":{"docs":{},"的":{"docs":{},"心":{"docs":{},"房":{"docs":{},"颤":{"docs":{},"动":{"docs":{},"？":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"包":{"docs":{},"含":{"1":{"3":{"6":{"7":{"9":{"docs":{},"个":{"docs":{},"关":{"docs":{},"于":{"docs":{},"物":{"docs":{},"理":{"docs":{},"，":{"docs":{},"化":{"docs":{},"学":{"docs":{},"和":{"docs":{},"生":{"docs":{},"物":{"docs":{},"学":{"docs":{},"等":{"docs":{},"的":{"docs":{},"众":{"docs":{},"包":{"docs":{},"科":{"docs":{},"学":{"docs":{},"考":{"docs":{},"试":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"问":{"docs":{},"题":{"docs":{},"采":{"docs":{},"用":{"docs":{},"多":{"docs":{},"项":{"docs":{},"选":{"docs":{},"择":{"docs":{},"题":{"docs":{},"格":{"docs":{},"式":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"选":{"docs":{},"项":{"docs":{},"有":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"是":{"docs":{},"来":{"docs":{},"自":{"docs":{},"“":{"docs":{},"中":{"docs":{},"国":{"docs":{},"裁":{"docs":{},"判":{"docs":{},"文":{"docs":{},"书":{"docs":{},"网":{"docs":{},"”":{"docs":{},"公":{"docs":{},"开":{"docs":{},"的":{"docs":{},"法":{"docs":{},"律":{"docs":{},"文":{"docs":{},"书":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"民":{"docs":{},"事":{"docs":{},"和":{"docs":{},"刑":{"docs":{},"事":{"docs":{},"的":{"docs":{},"一":{"docs":{},"审":{"docs":{},"判":{"docs":{},"决":{"docs":{},"书":{"docs":{},"，":{"docs":{},"总":{"docs":{},"共":{"docs":{},"约":{"1":{"docs":{},"万":{"docs":{},"份":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"并":{"docs":{},"按":{"docs":{},"比":{"docs":{},"例":{"docs":{},"划":{"docs":{},"分":{"docs":{},"训":{"docs":{},"练":{"docs":{},"、":{"docs":{},"开":{"docs":{},"发":{"docs":{},"和":{"docs":{},"测":{"docs":{},"试":{"docs":{},"。":{"docs":{},"每":{"docs":{},"份":{"docs":{},"数":{"docs":{},"据":{"docs":{},"包":{"docs":{},"括":{"docs":{},"若":{"docs":{},"干":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"只":{"docs":{},"包":{"docs":{},"含":{"docs":{},"一":{"docs":{},"个":{"docs":{},"标":{"docs":{},"准":{"docs":{},"回":{"docs":{},"答":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"开":{"docs":{},"发":{"docs":{},"和":{"docs":{},"测":{"docs":{},"试":{"docs":{},"集":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"包":{"docs":{},"含":{"3":{"docs":{},"个":{"docs":{},"标":{"docs":{},"准":{"docs":{},"回":{"docs":{},"答":{"docs":{},"。":{"docs":{},"回":{"docs":{},"答":{"docs":{},"内":{"docs":{},"容":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"案":{"docs":{},"情":{"docs":{},"片":{"docs":{},"段":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"y":{"docs":{},"e":{"docs":{},"s":{"docs":{},"或":{"docs":{},"n":{"docs":{},"o":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"拒":{"docs":{},"答":{"docs":{},"即":{"docs":{},"回":{"docs":{},"答":{"docs":{},"内":{"docs":{},"容":{"docs":{},"为":{"docs":{},"空":{"docs":{},"。":{"docs":{},"数":{"docs":{},"据":{"docs":{},"格":{"docs":{},"式":{"docs":{},"参":{"docs":{},"考":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"2":{"docs":{},".":{"0":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"格":{"docs":{},"式":{"docs":{},"，":{"docs":{},"整":{"docs":{},"体":{"docs":{},"为":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"格":{"docs":{},"式":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{},"并":{"docs":{},"增":{"docs":{},"设":{"docs":{},"案":{"docs":{},"由":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"\"":{"docs":{},"字":{"docs":{},"段":{"docs":{},"和":{"docs":{},"领":{"docs":{},"域":{"docs":{},"\"":{"docs":{},"d":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"\"":{"docs":{},"字":{"docs":{},"段":{"docs":{},"，":{"docs":{},"\"":{"docs":{},"d":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"\"":{"docs":{},"字":{"docs":{},"段":{"docs":{},"只":{"docs":{},"有":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"i":{"docs":{},"v":{"docs":{},"i":{"docs":{},"l":{"docs":{},"\"":{"docs":{},"和":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"r":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"\"":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"。":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"\"":{"docs":{},"抽":{"docs":{},"取":{"docs":{},"自":{"docs":{},"裁":{"docs":{},"判":{"docs":{},"文":{"docs":{},"书":{"docs":{},"的":{"docs":{},"案":{"docs":{},"情":{"docs":{},"描":{"docs":{},"述":{"docs":{},"或":{"docs":{},"原":{"docs":{},"告":{"docs":{},"诉":{"docs":{},"称":{"docs":{},"部":{"docs":{},"分":{"docs":{},"。":{"docs":{},"【":{"docs":{},"裁":{"docs":{},"判":{"docs":{},"文":{"docs":{},"书":{"docs":{},"网":{"docs":{},"】":{"docs":{},"【":{"docs":{},"中":{"docs":{},"文":{"docs":{},"】":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"格":{"docs":{},"式":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}},"：":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.017777777777777778}}}}},"规":{"docs":{},"模":{"docs":{},"：":{"1":{"5":{"docs":{},"万":{"docs":{},"+":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"docs":{}},"3":{"0":{"docs":{},"m":{"docs":{},"左":{"docs":{},"右":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"docs":{}},"4":{"1":{"docs":{},"g":{"docs":{},"b":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"docs":{}},"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"不":{"docs":{},"大":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"训":{"docs":{},"练":{"docs":{},"集":{"5":{"3":{"5":{"docs":{},"m":{"docs":{},"，":{"docs":{},"测":{"docs":{},"试":{"docs":{},"集":{"4":{"6":{"docs":{},"m":{"docs":{},"，":{"docs":{},"开":{"docs":{},"发":{"docs":{},"集":{"1":{"0":{"0":{"docs":{},"m":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"docs":{}},"docs":{}},"docs":{}}}}}}},"docs":{}},"docs":{}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}},"点":{"docs":{},"，":{"docs":{},"而":{"docs":{},"无":{"docs":{},"需":{"docs":{},"启":{"docs":{},"动":{"docs":{},"任":{"docs":{},"何":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"器":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}},"是":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"基":{"docs":{},"于":{"docs":{},"中":{"docs":{},"文":{"docs":{},"法":{"docs":{},"律":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"开":{"docs":{},"源":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"该":{"docs":{},"系":{"docs":{},"列":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"通":{"docs":{},"用":{"docs":{},"中":{"docs":{},"文":{"docs":{},"基":{"docs":{},"座":{"docs":{},"模":{"docs":{},"型":{"docs":{},"（":{"docs":{},"如":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"种":{"docs":{},"微":{"docs":{},"调":{"docs":{},"大":{"docs":{},"型":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"（":{"docs":{},"如":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"技":{"docs":{},"巧":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"大":{"docs":{},"型":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"多":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{},"然":{"docs":{},"而":{"docs":{},"，":{"docs":{},"在":{"docs":{},"实":{"docs":{},"际":{"docs":{},"应":{"docs":{},"用":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"需":{"docs":{},"要":{"docs":{},"结":{"docs":{},"合":{"docs":{},"其":{"docs":{},"他":{"docs":{},"技":{"docs":{},"巧":{"docs":{},"来":{"docs":{},"克":{"docs":{},"服":{"docs":{},"其":{"docs":{},"局":{"docs":{},"限":{"docs":{},"性":{"docs":{},"，":{"docs":{},"以":{"docs":{},"实":{"docs":{},"现":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"个":{"docs":{},"开":{"docs":{},"源":{"docs":{},"的":{"docs":{},"、":{"docs":{},"支":{"docs":{},"持":{"docs":{},"中":{"docs":{},"英":{"docs":{},"双":{"docs":{},"语":{"docs":{},"的":{"docs":{},"对":{"docs":{},"话":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"具":{"docs":{},"有":{"docs":{},"自":{"docs":{},"然":{"docs":{},"的":{"docs":{},"多":{"docs":{},"跳":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"对":{"docs":{},"支":{"docs":{},"持":{"docs":{},"事":{"docs":{},"实":{"docs":{},"进":{"docs":{},"行":{"docs":{},"强":{"docs":{},"有":{"docs":{},"力":{"docs":{},"的":{"docs":{},"监":{"docs":{},"督":{"docs":{},"，":{"docs":{},"以":{"docs":{},"实":{"docs":{},"现":{"docs":{},"更":{"docs":{},"可":{"docs":{},"解":{"docs":{},"释":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"系":{"docs":{},"统":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"经":{"docs":{},"过":{"docs":{},"中":{"docs":{},"文":{"docs":{},"医":{"docs":{},"学":{"docs":{},"指":{"docs":{},"令":{"docs":{},"精":{"docs":{},"调":{"docs":{},"/":{"docs":{},"指":{"docs":{},"令":{"docs":{},"微":{"docs":{},"调":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}},"个":{"docs":{},"很":{"docs":{},"极":{"docs":{},"端":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"它":{"docs":{},"最":{"docs":{},"多":{"docs":{},"只":{"docs":{},"能":{"docs":{},"表":{"docs":{},"示":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"构":{"docs":{},"建":{"docs":{},"了":{"docs":{},"中":{"docs":{},"文":{"docs":{},"医":{"docs":{},"学":{"docs":{},"指":{"docs":{},"令":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"并":{"docs":{},"在":{"docs":{},"此":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"对":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"指":{"docs":{},"令":{"docs":{},"微":{"docs":{},"调":{"docs":{},"，":{"docs":{},"提":{"docs":{},"高":{"docs":{},"了":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"在":{"docs":{},"医":{"docs":{},"疗":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"效":{"docs":{},"果":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"虚":{"docs":{},"拟":{"docs":{},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"输":{"docs":{},"出":{"docs":{},"对":{"docs":{},"的":{"docs":{},"大":{"docs":{},"型":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}},"造":{"docs":{},"指":{"docs":{},"令":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"结":{"docs":{},"构":{"docs":{},"，":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"可":{"docs":{},"参":{"docs":{},"考":{"docs":{},"使":{"docs":{},"用":{"docs":{},"开":{"docs":{},"源":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"此":{"docs":{},"外":{"docs":{},"，":{"docs":{},"项":{"docs":{},"目":{"docs":{},"组":{"docs":{},"还":{"docs":{},"收":{"docs":{},"集":{"docs":{},"了":{"2":{"0":{"2":{"3":{"docs":{},"年":{"docs":{},"关":{"docs":{},"于":{"docs":{},"肝":{"docs":{},"癌":{"docs":{},"疾":{"docs":{},"病":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"医":{"docs":{},"学":{"docs":{},"文":{"docs":{},"献":{"docs":{},"，":{"docs":{},"利":{"docs":{},"用":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"3":{"docs":{},".":{"5":{"docs":{},"接":{"docs":{},"口":{"docs":{},"围":{"docs":{},"绕":{"docs":{},"医":{"docs":{},"学":{"docs":{},"文":{"docs":{},"献":{"docs":{},"多":{"docs":{},"轮":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"（":{"1":{"docs":{},"k":{"docs":{},"条":{"docs":{},"左":{"docs":{},"右":{"docs":{},"）":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588}},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}},"作":{"docs":{},"者":{"docs":{},"根":{"docs":{},"据":{"docs":{},"这":{"docs":{},"一":{"docs":{},"特":{"docs":{},"点":{"docs":{},"将":{"docs":{},"更":{"docs":{},"新":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"变":{"docs":{},"成":{"docs":{},"两":{"docs":{},"个":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"的":{"docs":{},"积":{"docs":{},"积":{"docs":{},"b":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}},"大":{"docs":{},"致":{"docs":{},"实":{"docs":{},"现":{"docs":{},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}},"完":{"docs":{},"整":{"docs":{},"流":{"docs":{},"程":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"巧":{"docs":{},"妙":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"在":{"docs":{},"所":{"docs":{},"有":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"数":{"docs":{},"字":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"完":{"docs":{},"全":{"docs":{},"没":{"docs":{},"有":{"docs":{},"精":{"docs":{},"度":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}},"据":{"docs":{},"生":{"docs":{},"成":{"docs":{},"器":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}},"时":{"docs":{},"候":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"训":{"docs":{},"练":{"docs":{},"/":{"docs":{},"微":{"docs":{},"调":{"docs":{},"/":{"docs":{},"推":{"docs":{},"理":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}},"设":{"docs":{},"定":{"docs":{},"下":{"docs":{},"进":{"docs":{},"行":{"docs":{},"全":{"docs":{},"参":{"docs":{},"数":{"docs":{},"训":{"docs":{},"练":{"docs":{},"【":{"2":{"5":{"docs":{},".":{"3":{"docs":{},"+":{"9":{"9":{"0":{"docs":{},"/":{"1":{"0":{"2":{"4":{"docs":{},"*":{"5":{"0":{"docs":{},"】":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}}}}}}}}}}}},"高":{"docs":{},"效":{"docs":{},"参":{"docs":{},"数":{"docs":{},"微":{"docs":{},"调":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"实":{"docs":{},"际":{"docs":{},"动":{"docs":{},"手":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"提":{"docs":{},"升":{"docs":{},"对":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{},"和":{"docs":{},"应":{"docs":{},"用":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{},"需":{"docs":{},"要":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"到":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"间":{"docs":{},"和":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"因":{"docs":{},"素":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"启":{"docs":{},"发":{"docs":{},"，":{"docs":{},"研":{"docs":{},"究":{"docs":{},"人":{"docs":{},"员":{"docs":{},"也":{"docs":{},"选":{"docs":{},"择":{"docs":{},"用":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}},"性":{"docs":{},"能":{"docs":{},"是":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"；":{"docs":{},"用":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}},"开":{"docs":{},"源":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}},"上":{"docs":{},"微":{"docs":{},"调":{"docs":{},"出":{"docs":{},"一":{"docs":{},"个":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"和":{"docs":{},"其":{"docs":{},"他":{"docs":{},"开":{"docs":{},"源":{"docs":{},"模":{"docs":{},"型":{"docs":{},"之":{"docs":{},"间":{"docs":{},"切":{"docs":{},"换":{"docs":{},"。":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}},"研":{"docs":{},"究":{"docs":{},"团":{"docs":{},"队":{"docs":{},"在":{"docs":{},"其":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"中":{"docs":{},"，":{"docs":{},"有":{"docs":{},"多":{"docs":{},"种":{"docs":{},"解":{"docs":{},"释":{"docs":{},"/":{"docs":{},"理":{"docs":{},"由":{"docs":{},"的":{"docs":{},"概":{"docs":{},"念":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"显":{"docs":{},"示":{"docs":{},"权":{"docs":{},"威":{"docs":{},"的":{"docs":{},"、":{"docs":{},"有":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{},"（":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"z":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"支":{"docs":{},"持":{"docs":{},"基":{"docs":{},"于":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"的":{"docs":{},"解":{"docs":{},"释":{"docs":{},"。":{"docs":{},"每":{"docs":{},"棵":{"docs":{},"树":{"docs":{},"平":{"docs":{},"均":{"docs":{},"包":{"docs":{},"含":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}},"树":{"docs":{},"的":{"docs":{},"错":{"docs":{},"误":{"docs":{},"为":{"docs":{},"零":{"docs":{},"）":{"docs":{},"。":{"docs":{},"还":{"docs":{},"提":{"docs":{},"出":{"docs":{},"迹":{"docs":{},"象":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"b":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"模":{"docs":{},"型":{"docs":{},"（":{"docs":{},"每":{"docs":{},"个":{"docs":{},"任":{"docs":{},"务":{"docs":{},"一":{"docs":{},"个":{"docs":{},"）":{"docs":{},"，":{"docs":{},"称":{"docs":{},"为":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"知":{"docs":{},"识":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"包":{"docs":{},"括":{"docs":{},"针":{"docs":{},"对":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}},"类":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"资":{"docs":{},"源":{"docs":{},"对":{"docs":{},"外":{"docs":{},"开":{"docs":{},"放":{"docs":{},"：":{"docs":{},"百":{"docs":{},"万":{"docs":{},"级":{"docs":{},"百":{"docs":{},"度":{"docs":{},"知":{"docs":{},"道":{"docs":{},"、":{"docs":{},"社":{"docs":{},"区":{"docs":{},"问":{"docs":{},"答":{"docs":{},"及":{"docs":{},"六":{"docs":{},"大":{"docs":{},"领":{"docs":{},"域":{"docs":{},"级":{"docs":{},"小":{"docs":{},"规":{"docs":{},"模":{"docs":{},"语":{"docs":{},"料":{"docs":{},"概":{"docs":{},"述":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"图":{"docs":{},"谱":{"docs":{},"v":{"docs":{},"s":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"化":{"docs":{},"表":{"docs":{},"示":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"(":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},")":{"docs":{},"是":{"docs":{},"参":{"docs":{},"数":{"docs":{},"化":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.15384615384615385}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"利":{"docs":{},"用":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"，":{"docs":{},"参":{"docs":{},"与":{"docs":{},"到":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"前":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"构":{"docs":{},"造":{"docs":{},"，":{"docs":{},"训":{"docs":{},"练":{"docs":{},"中":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"以":{"docs":{},"及":{"docs":{},"训":{"docs":{},"练":{"docs":{},"后":{"docs":{},"推":{"docs":{},"理":{"docs":{},"结":{"docs":{},"果":{"docs":{},"的":{"docs":{},"约":{"docs":{},"束":{"docs":{},"生":{"docs":{},"成":{"docs":{},"，":{"docs":{},"提":{"docs":{},"升":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"等":{"docs":{},"）":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"扩":{"docs":{},"充":{"docs":{},"法":{"docs":{},"律":{"docs":{},"领":{"docs":{},"域":{"docs":{},"专":{"docs":{},"有":{"docs":{},"词":{"docs":{},"表":{"docs":{},"、":{"docs":{},"大":{"docs":{},"规":{"docs":{},"模":{"docs":{},"中":{"docs":{},"文":{"docs":{},"法":{"docs":{},"律":{"docs":{},"语":{"docs":{},"料":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"增":{"docs":{},"强":{"docs":{},"了":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"法":{"docs":{},"律":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"语":{"docs":{},"义":{"docs":{},"理":{"docs":{},"解":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{},"在":{"docs":{},"此":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"，":{"docs":{},"构":{"docs":{},"造":{"docs":{},"法":{"docs":{},"律":{"docs":{},"领":{"docs":{},"域":{"docs":{},"对":{"docs":{},"话":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"、":{"docs":{},"中":{"docs":{},"国":{"docs":{},"司":{"docs":{},"法":{"docs":{},"考":{"docs":{},"试":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"进":{"docs":{},"行":{"docs":{},"指":{"docs":{},"令":{"docs":{},"精":{"docs":{},"调":{"docs":{},"，":{"docs":{},"提":{"docs":{},"升":{"docs":{},"了":{"docs":{},"模":{"docs":{},"型":{"docs":{},"对":{"docs":{},"法":{"docs":{},"律":{"docs":{},"内":{"docs":{},"容":{"docs":{},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{},"和":{"docs":{},"执":{"docs":{},"行":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"布":{"docs":{},"优":{"docs":{},"化":{"docs":{},"算":{"docs":{},"法":{"docs":{},"，":{"docs":{},"减":{"docs":{},"少":{"docs":{},"内":{"docs":{},"存":{"docs":{},"的":{"docs":{},"占":{"docs":{},"用":{"docs":{},"量":{"docs":{},"。":{"docs":{},"其":{"docs":{},"将":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"和":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"状":{"docs":{},"态":{"docs":{},"分":{"docs":{},"布":{"docs":{},"至":{"docs":{},"多":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"人":{"docs":{},"，":{"2":{"0":{"1":{"6":{"docs":{},"）":{"docs":{},"、":{"docs":{},"综":{"docs":{},"合":{"docs":{},"连":{"docs":{},"接":{"docs":{},"问":{"docs":{},"题":{"docs":{},"和":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"短":{"docs":{},"语":{"docs":{},"（":{"docs":{},"r":{"docs":{},"a":{"docs":{},"j":{"docs":{},"a":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}},"8":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"9":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"）":{"docs":{},"、":{"docs":{},"段":{"docs":{},"落":{"docs":{},"上":{"docs":{},"的":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"图":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"o":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"们":{"docs":{},"很":{"docs":{},"少":{"docs":{},"从":{"docs":{},"什":{"docs":{},"么":{"docs":{},"解":{"docs":{},"释":{"docs":{},"推":{"docs":{},"理":{"docs":{},"链":{"docs":{},"已":{"docs":{},"知":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"即":{"docs":{},"在":{"docs":{},"给":{"docs":{},"出":{"docs":{},"证":{"docs":{},"据":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"答":{"docs":{},"案":{"docs":{},"是":{"docs":{},"如":{"docs":{},"何":{"docs":{},"得":{"docs":{},"出":{"docs":{},"的":{"docs":{},"—":{"docs":{},"—":{"docs":{},"这":{"docs":{},"项":{"docs":{},"工":{"docs":{},"作":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"2":{"0":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}},"系":{"docs":{},"列":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"为":{"docs":{},"两":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"：":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}},"统":{"docs":{},"中":{"docs":{},"的":{"docs":{},"“":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"资":{"docs":{},"源":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}},"问":{"docs":{},"题":{"docs":{},"”":{"docs":{},"对":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"让":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"回":{"docs":{},"答":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"使":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"能":{"docs":{},"够":{"docs":{},"生":{"docs":{},"成":{"docs":{},"含":{"docs":{},"有":{"docs":{},"法":{"docs":{},"律":{"docs":{},"信":{"docs":{},"息":{"docs":{},"的":{"docs":{},"回":{"docs":{},"答":{"docs":{},"，":{"docs":{},"保":{"docs":{},"证":{"docs":{},"回":{"docs":{},"答":{"docs":{},"的":{"docs":{},"准":{"docs":{},"确":{"docs":{},"性":{"docs":{},"。":{"docs":{},"【":{"docs":{},"后":{"docs":{},"续":{"docs":{},"可":{"docs":{},"参":{"docs":{},"考":{"docs":{},"该":{"docs":{},"方":{"docs":{},"法":{"docs":{},"构":{"docs":{},"建":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"】":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"项":{"docs":{},"目":{"docs":{},"组":{"docs":{},"在":{"docs":{},"一":{"docs":{},"张":{"docs":{},"a":{"1":{"0":{"0":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}},"docs":{}},"docs":{}},"docs":{}}}}},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"公":{"docs":{},"开":{"docs":{},"和":{"docs":{},"自":{"docs":{},"建":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"医":{"docs":{},"学":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"参":{"docs":{},"考":{"docs":{},"了":{"docs":{},"c":{"docs":{},"m":{"docs":{},"e":{"docs":{},"k":{"docs":{},"g":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},".":{"docs":{},"a":{"docs":{},"i":{"docs":{},"/":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"1":{"docs":{},"）":{"docs":{},"l":{"docs":{},"a":{"docs":{},"w":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"准":{"docs":{},"备":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"集":{"docs":{},"：":{"docs":{},"针":{"docs":{},"对":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"准":{"docs":{},"备":{"docs":{},"一":{"docs":{},"组":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"描":{"docs":{},"述":{"docs":{},"任":{"docs":{},"务":{"docs":{},"类":{"docs":{},"型":{"docs":{},"和":{"docs":{},"任":{"docs":{},"务":{"docs":{},"目":{"docs":{},"标":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"“":{"docs":{},"该":{"docs":{},"文":{"docs":{},"本":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"是":{"docs":{},"正":{"docs":{},"面":{"docs":{},"的":{"docs":{},"还":{"docs":{},"是":{"docs":{},"负":{"docs":{},"面":{"docs":{},"的":{"docs":{},"？":{"docs":{},"”":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"收":{"docs":{},"集":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"各":{"docs":{},"种":{"docs":{},"主":{"docs":{},"题":{"docs":{},"和":{"docs":{},"风":{"docs":{},"格":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"。":{"docs":{},"可":{"docs":{},"以":{"docs":{},"从":{"docs":{},"各":{"docs":{},"种":{"docs":{},"来":{"docs":{},"源":{"docs":{},"获":{"docs":{},"取":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"如":{"docs":{},"网":{"docs":{},"站":{"docs":{},"、":{"docs":{},"社":{"docs":{},"交":{"docs":{},"媒":{"docs":{},"体":{"docs":{},"、":{"docs":{},"新":{"docs":{},"闻":{"docs":{},"、":{"docs":{},"书":{"docs":{},"籍":{"docs":{},"等":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"首":{"docs":{},"先":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"定":{"docs":{},"义":{"docs":{},"一":{"docs":{},"个":{"docs":{},"目":{"docs":{},"标":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"即":{"docs":{},"要":{"docs":{},"求":{"docs":{},"模":{"docs":{},"型":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"最":{"docs":{},"终":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"：":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"[":{"docs":{},"用":{"docs":{},"户":{"docs":{},"提":{"docs":{},"问":{"docs":{},"+":{"docs":{},"相":{"docs":{},"关":{"docs":{},"检":{"docs":{},"索":{"docs":{},"信":{"docs":{},"息":{"docs":{},"]":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"2":{"docs":{},"）":{"docs":{},"m":{"docs":{},"i":{"docs":{},"x":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"准":{"docs":{},"备":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"针":{"docs":{},"对":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"准":{"docs":{},"备":{"docs":{},"一":{"docs":{},"个":{"docs":{},"标":{"docs":{},"记":{"docs":{},"化":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"样":{"docs":{},"本":{"docs":{},"都":{"docs":{},"包":{"docs":{},"含":{"docs":{},"输":{"docs":{},"入":{"docs":{},"文":{"docs":{},"本":{"docs":{},"和":{"docs":{},"标":{"docs":{},"签":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"标":{"docs":{},"签":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"“":{"docs":{},"正":{"docs":{},"面":{"docs":{},"”":{"docs":{},"或":{"docs":{},"“":{"docs":{},"负":{"docs":{},"面":{"docs":{},"”":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"分":{"docs":{},"词":{"docs":{},"、":{"docs":{},"标":{"docs":{},"记":{"docs":{},"化":{"docs":{},"、":{"docs":{},"去":{"docs":{},"除":{"docs":{},"停":{"docs":{},"用":{"docs":{},"词":{"docs":{},"、":{"docs":{},"处":{"docs":{},"理":{"docs":{},"语":{"docs":{},"法":{"docs":{},"结":{"docs":{},"构":{"docs":{},"等":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"然":{"docs":{},"后":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"目":{"docs":{},"标":{"docs":{},"任":{"docs":{},"务":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"：":{"docs":{},"带":{"docs":{},"有":{"docs":{},"标":{"docs":{},"引":{"docs":{},"信":{"docs":{},"息":{"docs":{},"的":{"docs":{},"回":{"docs":{},"答":{"docs":{},"结":{"docs":{},"果":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}},"3":{"docs":{},"）":{"docs":{},"定":{"docs":{},"义":{"docs":{},"一":{"docs":{},"个":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"窗":{"docs":{},"口":{"docs":{},"，":{"docs":{},"即":{"docs":{},"模":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"的":{"docs":{},"前":{"docs":{},"面":{"docs":{},"和":{"docs":{},"后":{"docs":{},"面":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"内":{"docs":{},"容":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"模":{"docs":{},"型":{"docs":{},"输":{"docs":{},"入":{"docs":{},"：":{"docs":{},"将":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"模":{"docs":{},"型":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"对":{"docs":{},"于":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"将":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"指":{"docs":{},"令":{"docs":{},"和":{"docs":{},"文":{"docs":{},"本":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"作":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"：":{"docs":{},"“":{"docs":{},"该":{"docs":{},"文":{"docs":{},"本":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"是":{"docs":{},"正":{"docs":{},"面":{"docs":{},"的":{"docs":{},"还":{"docs":{},"是":{"docs":{},"负":{"docs":{},"面":{"docs":{},"的":{"docs":{},"？":{"docs":{},"这":{"docs":{},"家":{"docs":{},"餐":{"docs":{},"厅":{"docs":{},"的":{"docs":{},"食":{"docs":{},"物":{"docs":{},"很":{"docs":{},"好":{"docs":{},"吃":{"docs":{},"。":{"docs":{},"”":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"都":{"docs":{},"需":{"docs":{},"要":{"docs":{},"定":{"docs":{},"义":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}},"垂":{"docs":{},"直":{"docs":{},"领":{"docs":{},"域":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"模":{"docs":{},"型":{"docs":{},"微":{"docs":{},"调":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{},"根":{"docs":{},"据":{"docs":{},"已":{"docs":{},"有":{"docs":{},"的":{"docs":{},"开":{"docs":{},"源":{"docs":{},"微":{"docs":{},"调":{"docs":{},"项":{"docs":{},"目":{"docs":{},"进":{"docs":{},"行":{"docs":{},"改":{"docs":{},"动":{"docs":{},"、":{"docs":{},"参":{"docs":{},"考":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"4":{"docs":{},"）":{"docs":{},"在":{"docs":{},"指":{"docs":{},"令":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"：":{"docs":{},"在":{"docs":{},"指":{"docs":{},"令":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"，":{"docs":{},"以":{"docs":{},"适":{"docs":{},"应":{"docs":{},"特":{"docs":{},"定":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"需":{"docs":{},"求":{"docs":{},"，":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"逐":{"docs":{},"步":{"docs":{},"更":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"都":{"docs":{},"需":{"docs":{},"要":{"docs":{},"为":{"docs":{},"其":{"docs":{},"定":{"docs":{},"义":{"docs":{},"一":{"docs":{},"个":{"docs":{},"训":{"docs":{},"练":{"docs":{},"目":{"docs":{},"标":{"docs":{},"和":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"5":{"docs":{},"）":{"docs":{},"为":{"docs":{},"每":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"定":{"docs":{},"义":{"docs":{},"适":{"docs":{},"当":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"目":{"docs":{},"标":{"docs":{},"和":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"后":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"所":{"docs":{},"有":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"组":{"docs":{},"合":{"docs":{},"起":{"docs":{},"来":{"docs":{},"，":{"docs":{},"构":{"docs":{},"建":{"docs":{},"一":{"docs":{},"个":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"都":{"docs":{},"将":{"docs":{},"成":{"docs":{},"为":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"完":{"docs":{},"成":{"docs":{},"目":{"docs":{},"标":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"6":{"docs":{},"）":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"完":{"docs":{},"成":{"docs":{},"后":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"测":{"docs":{},"试":{"docs":{},"数":{"docs":{},"据":{"docs":{},"来":{"docs":{},"评":{"docs":{},"估":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"检":{"docs":{},"查":{"docs":{},"模":{"docs":{},"型":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"够":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"，":{"docs":{},"以":{"docs":{},"及":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"够":{"docs":{},"维":{"docs":{},"护":{"docs":{},"文":{"docs":{},"本":{"docs":{},"中":{"docs":{},"的":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"7":{"docs":{},"）":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"地":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"和":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}},"docs":{},"用":{"docs":{},"来":{"docs":{},"储":{"docs":{},"存":{"docs":{},"一":{"docs":{},"阶":{"docs":{},"和":{"docs":{},"二":{"docs":{},"阶":{"docs":{},"m":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"m":{"docs":{},"）":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"有":{"docs":{},"显":{"docs":{},"卡":{"docs":{},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"下":{"docs":{},"载":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"和":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"n":{"docs":{},"n":{"docs":{},"安":{"docs":{},"装":{"docs":{},"成":{"docs":{},"功":{"docs":{},"才":{"docs":{},"可":{"docs":{},"以":{"docs":{},"，":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"可":{"docs":{},"以":{"docs":{},"去":{"docs":{},"网":{"docs":{},"上":{"docs":{},"找":{"docs":{},"教":{"docs":{},"程":{"docs":{},"）":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"二":{"docs":{},"次":{"docs":{},"训":{"docs":{},"练":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"耗":{"docs":{},"时":{"docs":{},"约":{"docs":{"相关GPT调研/相关GPT调研.html":{"ref":"相关GPT调研/相关GPT调研.html","tf":0.009615384615384616}}}}}}}}}}}},"+":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}},"=":{"1":{"1":{"0":{"0":{"8":{"docs":{},",":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.025423728813559324},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.024149286498353458},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.03345724907063197}},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.01486988847583643}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},">":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},".":{"docs":{},"s":{"3":{"docs":{},".":{"docs":{},"u":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"docs":{}}},"s":{"docs":{},".":{"docs":{},"s":{"3":{"docs":{},".":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"z":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"w":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"s":{"docs":{},"c":{"docs":{},"i":{"docs":{},"q":{"docs":{},"/":{"docs":{},"s":{"docs":{},"c":{"docs":{},"i":{"docs":{},"q":{"docs":{},".":{"docs":{},"z":{"docs":{},"i":{"docs":{},"p":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}},"（":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{},"）":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"众":{"docs":{},"包":{"docs":{},"工":{"docs":{},"作":{"docs":{},"者":{"docs":{},"在":{"docs":{},"一":{"docs":{},"组":{"docs":{},"维":{"docs":{},"基":{"docs":{},"百":{"docs":{},"科":{"docs":{},"条":{"docs":{},"目":{"docs":{},"上":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"组":{"docs":{},"成":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"是":{"docs":{},"相":{"docs":{},"应":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"段":{"docs":{},"落":{"docs":{},"中":{"docs":{},"的":{"docs":{},"一":{"docs":{},"段":{"docs":{},"文":{"docs":{},"本":{"docs":{},"或":{"docs":{},"跨":{"docs":{},"度":{"docs":{},"，":{"docs":{},"或":{"docs":{},"者":{"docs":{},"问":{"docs":{},"题":{"docs":{},"可":{"docs":{},"能":{"docs":{},"无":{"docs":{},"法":{"docs":{},"回":{"docs":{},"答":{"docs":{},"。":{"docs":{},"【":{"docs":{},"英":{"docs":{},"文":{"docs":{},"】":{"docs":{},"【":{"docs":{},"维":{"docs":{},"基":{"docs":{},"百":{"docs":{},"科":{"docs":{},"】":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"5":{"2":{"docs":{},"k":{"docs":{},"个":{"docs":{},"指":{"docs":{},"令":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}},"docs":{}},"7":{"5":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"对":{"docs":{},"话":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}},"科":{"docs":{},"学":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}},"用":{"docs":{},"户":{"docs":{},"首":{"docs":{},"先":{"docs":{},"填":{"docs":{},"充":{"docs":{},"“":{"docs":{},"解":{"docs":{},"释":{"docs":{},"性":{"docs":{},"工":{"docs":{},"作":{"docs":{},"表":{"docs":{},"”":{"docs":{},"，":{"docs":{},"用":{"docs":{},"少":{"docs":{},"量":{"docs":{},"特":{"docs":{},"定":{"docs":{},"类":{"docs":{},"别":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"“":{"docs":{},"核":{"docs":{},"心":{"docs":{},"事":{"docs":{},"实":{"docs":{},"”":{"docs":{},"、":{"docs":{},"“":{"docs":{},"基":{"docs":{},"础":{"docs":{},"事":{"docs":{},"实":{"docs":{},"”":{"docs":{},"）":{"docs":{},"标":{"docs":{},"记":{"docs":{},"他":{"docs":{},"们":{"docs":{},"预":{"docs":{},"期":{"docs":{},"将":{"docs":{},"包":{"docs":{},"含":{"docs":{},"在":{"docs":{},"树":{"docs":{},"中":{"docs":{},"的":{"docs":{},"事":{"docs":{},"实":{"docs":{},"。":{"docs":{},"然":{"docs":{},"后":{"docs":{},"，":{"docs":{},"用":{"docs":{},"户":{"docs":{},"从":{"docs":{},"该":{"docs":{},"工":{"docs":{},"作":{"docs":{},"表":{"docs":{},"开":{"docs":{},"始":{"docs":{},"构":{"docs":{},"建":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"：":{"docs":{},"要":{"docs":{},"求":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}},"：":{"docs":{},"使":{"docs":{},"用":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"将":{"5":{"docs":{},".":{"2":{"docs":{},"万":{"docs":{},"条":{"docs":{},"指":{"docs":{},"令":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"成":{"docs":{},"中":{"docs":{},"文":{"docs":{},"，":{"docs":{},"并":{"docs":{},"要":{"docs":{},"求":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}},"v":{"docs":{},"i":{"docs":{},"n":{"docs":{},"c":{"docs":{},"i":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}},"d":{"docs":{},"p":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"混":{"docs":{},"合":{"docs":{},"精":{"docs":{},"度":{"docs":{},"反":{"docs":{},"编":{"docs":{},"译":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644}}}}}}},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"y":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}},"v":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}},".":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"o":{"docs":{},"w":{"docs":{},"n":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}},"n":{"docs":{},"'":{"docs":{},"t":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}},"a":{"docs":{},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"1":{"5":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"由":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"员":{"docs":{},"工":{"docs":{},"生":{"docs":{},"成":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"训":{"docs":{},"练":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"大":{"docs":{},"规":{"docs":{},"模":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"docs":{},"三":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"：":{"docs":{},"机":{"docs":{},"器":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"、":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"式":{"docs":{},"问":{"docs":{},"答":{"docs":{},"和":{"docs":{},"多":{"docs":{},"文":{"docs":{},"档":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"。":{"docs":{},"数":{"docs":{},"据":{"docs":{},"来":{"docs":{},"源":{"docs":{},"于":{"docs":{},"百":{"docs":{},"度":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"和":{"docs":{},"百":{"docs":{},"度":{"docs":{},"知":{"docs":{},"道":{"docs":{},"。":{"docs":{},"【":{"docs":{},"百":{"docs":{},"度":{"docs":{},"】":{"docs":{},"【":{"docs":{},"中":{"docs":{},"文":{"docs":{},"】":{"docs":{},"m":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"f":{"2":{"docs":{},",":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}},"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}}}}}},"c":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"p":{"1":{"6":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"=":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"docs":{}},"3":{"2":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}},"docs":{}},"docs":{},"i":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}},"s":{"docs":{},"d":{"docs":{},"p":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"+":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"p":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"，":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.060240963855421686},"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.044444444444444446}},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"6":{"9":{"docs":{},"k":{"docs":{},"个":{"docs":{},"金":{"docs":{},"融":{"docs":{},"相":{"docs":{},"关":{"docs":{},"指":{"docs":{},"令":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"m":{"docs":{},"p":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},".":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"数":{"docs":{},"据":{"docs":{},"上":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}},"；":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}},"表":{"docs":{},"现":{"docs":{},"出":{"docs":{},"更":{"docs":{},"强":{"docs":{},"大":{"docs":{},"的":{"docs":{},"对":{"docs":{},"齐":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"并":{"docs":{},"研":{"docs":{},"究":{"docs":{},"指":{"docs":{},"令":{"docs":{},"调":{"docs":{},"优":{"docs":{},"的":{"docs":{},"跨":{"docs":{},"语":{"docs":{},"言":{"docs":{},"泛":{"docs":{},"化":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"=":{"docs":{},"\"":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"[":{"docs":{},"k":{"docs":{},"[":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{},":":{"docs":{},"]":{"docs":{},"]":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"t":{"docs":{},"k":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"p":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"o":{"docs":{},"h":{"docs":{},"u":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}},".":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}},"q":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}},"r":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"a":{"docs":{},"m":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"）":{"docs":{},"大":{"docs":{},"概":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"，":{"docs":{},"大":{"docs":{},"概":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"进":{"docs":{},"而":{"docs":{},"通":{"docs":{},"过":{"docs":{},"估":{"docs":{},"算":{"docs":{},"设":{"docs":{},"置":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}},"n":{"docs":{},"k":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625}}}}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.003293084522502744}}}}}}}}},",":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"下":{"docs":{},"载":{"docs":{},"安":{"docs":{},"装":{"docs":{},"即":{"docs":{},"可":{"docs":{},"，":{"docs":{},"注":{"docs":{},"意":{"docs":{},"安":{"docs":{},"装":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"直":{"docs":{},"接":{"docs":{},"选":{"docs":{},"择":{"docs":{},"全":{"docs":{},"部":{"docs":{},"安":{"docs":{},"装":{"docs":{},"就":{"docs":{},"好":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"p":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"=":{"docs":{},"\"":{"docs":{},"\"":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"f":{"docs":{},"(":{"docs":{},")":{"docs":{},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}},"t":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.013333333333333334}}}}}}},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"t":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"a":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}},"l":{"docs":{},"h":{"docs":{},"f":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"9":{"1":{"docs":{},"k":{"docs":{},"个":{"docs":{},"对":{"docs":{},"话":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"从":{"docs":{},"人":{"docs":{},"类":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"中":{"docs":{},"进":{"docs":{},"行":{"docs":{},"强":{"docs":{},"化":{"docs":{},"学":{"docs":{},"习":{"docs":{},"。":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"s":{"docs":{},",":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}},"p":{"docs":{},":":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}},"r":{"docs":{},"l":{"docs":{},":":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644}},"零":{"docs":{},"冗":{"docs":{},"余":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"h":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}},"'":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"●":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.03389830508474576}}},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"七":{"docs":{},"、":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"s":{"docs":{},"c":{"docs":{},"i":{"docs":{},"q":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"实":{"docs":{},"验":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}},"三":{"docs":{},"、":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}},"docs":{}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"i":{"docs":{},".":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"/":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"/":{"docs":{},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"u":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"贡":{"docs":{},"献":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"个":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"：":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}},"上":{"docs":{},"保":{"docs":{},"留":{"docs":{},"完":{"docs":{},"整":{"docs":{},"副":{"docs":{},"本":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}},"平":{"docs":{},"均":{"docs":{},"划":{"docs":{},"分":{"docs":{},"参":{"docs":{},"数":{"docs":{},"、":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"和":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"状":{"docs":{},"态":{"docs":{},"，":{"docs":{},"并":{"docs":{},"为":{"docs":{},"每":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"而":{"docs":{},"非":{"docs":{},"像":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"述":{"docs":{},"文":{"docs":{},"件":{"docs":{},"全":{"docs":{},"部":{"docs":{},"下":{"docs":{},"载":{"docs":{},"之":{"docs":{},"后":{"docs":{},"保":{"docs":{},"存":{"docs":{},"到":{"docs":{},"本":{"docs":{},"地":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"即":{"docs":{},"可":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"保":{"docs":{},"存":{"docs":{},"在":{"docs":{},"：":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{},"了":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"和":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"这":{"docs":{},"项":{"docs":{},"任":{"docs":{},"务":{"docs":{},"定":{"docs":{},"义":{"docs":{},"和":{"docs":{},"训":{"docs":{},"练":{"docs":{},"称":{"docs":{},"为":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"存":{"docs":{},"储":{"docs":{},"零":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"。":{"docs":{},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"解":{"docs":{},"释":{"docs":{},"q":{"docs":{},"a":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"方":{"docs":{},"法":{"docs":{},"与":{"docs":{},"技":{"docs":{},"术":{"docs":{},"：":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}},"也":{"docs":{},"会":{"docs":{},"占":{"docs":{},"据":{"docs":{},"一":{"docs":{},"些":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}},"五":{"docs":{},"、":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"：":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}},"p":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"q":{"docs":{},"a":{"docs":{},"：":{"docs":{},"医":{"docs":{},"学":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"仅":{"docs":{},"对":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"状":{"docs":{},"态":{"docs":{},"和":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"执":{"docs":{},"行":{"docs":{},"分":{"docs":{},"区":{"docs":{},"（":{"docs":{},"分":{"docs":{},"片":{"docs":{},"）":{"docs":{},"。":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"分":{"docs":{},"片":{"docs":{},"应":{"docs":{},"该":{"docs":{},"很":{"docs":{},"快":{"docs":{},"就":{"docs":{},"会":{"docs":{},"在":{"docs":{},"d":{"docs":{},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"和":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"中":{"docs":{},"推":{"docs":{},"出":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"参":{"docs":{},"数":{"docs":{},"：":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"所":{"docs":{},"储":{"docs":{},"存":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"不":{"docs":{},"同":{"docs":{},"。":{"docs":{},"对":{"docs":{},"于":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"例":{"docs":{},"子":{"docs":{},"：":{"docs":{},"借":{"docs":{},"助":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"如":{"docs":{},"，":{"docs":{},"为":{"docs":{},"了":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"理":{"docs":{},"解":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"定":{"docs":{},"义":{"docs":{},"一":{"docs":{},"个":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"它":{"docs":{},"评":{"docs":{},"估":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"与":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"性":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"理":{"docs":{},"解":{"docs":{},"语":{"docs":{},"法":{"docs":{},"和":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"、":{"docs":{},"生":{"docs":{},"成":{"docs":{},"单":{"docs":{},"词":{"docs":{},"和":{"docs":{},"短":{"docs":{},"语":{"docs":{},"、":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{},"和":{"docs":{},"段":{"docs":{},"落":{"docs":{},"、":{"docs":{},"理":{"docs":{},"解":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"等":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"生":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"其":{"docs":{},"分":{"docs":{},"解":{"docs":{},"为":{"docs":{},"理":{"docs":{},"解":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"语":{"docs":{},"义":{"docs":{},"、":{"docs":{},"确":{"docs":{},"定":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"语":{"docs":{},"法":{"docs":{},"结":{"docs":{},"构":{"docs":{},"、":{"docs":{},"生":{"docs":{},"成":{"docs":{},"文":{"docs":{},"本":{"docs":{},"等":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"一":{"docs":{},"组":{"docs":{},"与":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"单":{"docs":{},"词":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"单":{"docs":{},"词":{"docs":{},"或":{"docs":{},"整":{"docs":{},"个":{"docs":{},"句":{"docs":{},"子":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"果":{"docs":{},"目":{"docs":{},"标":{"docs":{},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"生":{"docs":{},"成":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"中":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"一":{"docs":{},"句":{"docs":{},"话":{"docs":{},"或":{"docs":{},"一":{"docs":{},"个":{"docs":{},"段":{"docs":{},"落":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"其":{"docs":{},"转":{"docs":{},"化":{"docs":{},"为":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"响":{"docs":{},"应":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"对":{"docs":{},"于":{"docs":{},"问":{"docs":{},"答":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"可":{"docs":{},"以":{"docs":{},"提":{"docs":{},"供":{"docs":{},"具":{"docs":{},"体":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"“":{"docs":{},"请":{"docs":{},"回":{"docs":{},"答":{"docs":{},"下":{"docs":{},"列":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"谁":{"docs":{},"是":{"docs":{},"美":{"docs":{},"国":{"docs":{},"第":{"docs":{},"一":{"docs":{},"位":{"docs":{},"总":{"docs":{},"统":{"docs":{},"？":{"docs":{},"”":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"文":{"docs":{},"本":{"docs":{},"段":{"docs":{},"落":{"docs":{},"作":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"提":{"docs":{},"供":{"docs":{},"给":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"借":{"docs":{},"助":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}}}},"六":{"docs":{},"、":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}},"q":{"docs":{},"a":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"：":{"docs":{},"卡":{"docs":{},"斯":{"docs":{},"珀":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"构":{"docs":{},"建":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}},"其":{"docs":{},"次":{"docs":{},"，":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"模":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"中":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"一":{"docs":{},"种":{"docs":{},"p":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"技":{"docs":{},"术":{"docs":{},"称":{"docs":{},"为":{"docs":{},"蒸":{"docs":{},"馏":{"docs":{},"(":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{},"，":{"docs":{},"它":{"docs":{},"由":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{},"等":{"docs":{},"人":{"docs":{},"于":{"2":{"0":{"1":{"5":{"docs":{},"年":{"docs":{},"引":{"docs":{},"入":{"docs":{},"。":{"docs":{},"该":{"docs":{},"方":{"docs":{},"法":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"个":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"模":{"docs":{},"仿":{"docs":{},"一":{"docs":{},"个":{"docs":{},"较":{"docs":{},"大":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"行":{"docs":{},"为":{"docs":{},"。":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"“":{"docs":{},"教":{"docs":{},"师":{"docs":{},"”":{"docs":{},"预":{"docs":{},"测":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"用":{"docs":{},"于":{"docs":{},"训":{"docs":{},"练":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"“":{"docs":{},"学":{"docs":{},"生":{"docs":{},"”":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"这":{"docs":{},"样":{"docs":{},"做":{"docs":{},"，":{"docs":{},"学":{"docs":{},"生":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"从":{"docs":{},"较":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"中":{"docs":{},"学":{"docs":{},"习":{"docs":{},"，":{"docs":{},"而":{"docs":{},"无":{"docs":{},"需":{"docs":{},"存":{"docs":{},"储":{"docs":{},"所":{"docs":{},"有":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{},"【":{"docs":{},"教":{"docs":{},"师":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"他":{"docs":{},"具":{"docs":{},"体":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"链":{"docs":{},"接":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"再":{"docs":{},"根":{"docs":{},"据":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"的":{"docs":{},"架":{"docs":{},"构":{"docs":{},"（":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}},"则":{"docs":{},"允":{"docs":{},"许":{"docs":{},"在":{"docs":{},"一":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"包":{"docs":{},"装":{"docs":{},"一":{"docs":{},"下":{"docs":{},"即":{"docs":{},"可":{"docs":{},"，":{"docs":{},"详":{"docs":{},"见":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"含":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}},"卸":{"docs":{},"载":{"docs":{},"（":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"功":{"docs":{},"能":{"docs":{},"将":{"docs":{},"一":{"docs":{},"些":{"docs":{},"处":{"docs":{},"理":{"docs":{},"和":{"docs":{},"内":{"docs":{},"存":{"docs":{},"需":{"docs":{},"求":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"到":{"docs":{},"主":{"docs":{},"机":{"docs":{},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"原":{"docs":{},"理":{"docs":{},"：":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"(":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}},"参":{"docs":{},"考":{"docs":{},"论":{"docs":{},"文":{"docs":{},"：":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},".":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"8":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"docs":{}}}}}}}}}}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}},"有":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"省":{"docs":{},"内":{"docs":{},"存":{"docs":{},"的":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"/":{"docs":{},"微":{"docs":{},"调":{"docs":{},"/":{"docs":{},"推":{"docs":{},"理":{"docs":{},"方":{"docs":{},"法":{"docs":{},"？":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"微":{"docs":{},"调":{"docs":{},"技":{"docs":{},"术":{"docs":{},"：":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"三":{"docs":{},"种":{"docs":{},"训":{"docs":{},"练":{"docs":{},"技":{"docs":{},"术":{"docs":{},"及":{"docs":{},"区":{"docs":{},"别":{"docs":{},"：":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"进":{"docs":{},"阶":{"docs":{},"（":{"docs":{},"二":{"docs":{},"）":{"docs":{},":":{"docs":{},"训":{"docs":{},"练":{"docs":{},"部":{"docs":{},"署":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"模":{"docs":{},"型":{"docs":{},"(":{"docs":{},"羊":{"docs":{},"驼":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"【":{"docs":{},"实":{"docs":{},"战":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"】":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}},"手":{"docs":{},"把":{"docs":{},"手":{"docs":{},"教":{"docs":{},"你":{"docs":{},"本":{"docs":{},"地":{"docs":{},"部":{"docs":{},"署":{"docs":{},"清":{"docs":{},"华":{"docs":{},"大":{"docs":{},"学":{"docs":{},"k":{"docs":{},"e":{"docs":{},"g":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"高":{"docs":{},"效":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}},"发":{"docs":{},"送":{"docs":{},"它":{"docs":{},"所":{"docs":{},"缺":{"docs":{},"少":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"来":{"docs":{},"动":{"docs":{},"态":{"docs":{},"构":{"docs":{},"建":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}},"四":{"docs":{},"、":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"8":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}}}},"对":{"docs":{},"比":{"docs":{},"总":{"docs":{},"结":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"—":{"docs":{},"—":{"docs":{},"“":{"docs":{},"l":{"docs":{},"e":{"docs":{},"t":{"docs":{},"’":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}},"中":{"docs":{},"文":{"docs":{},"法":{"docs":{},"律":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"：":{"docs":{},"c":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"2":{"0":{"1":{"9":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"综":{"docs":{},"述":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}},"在":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076},"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}},"这":{"docs":{},"个":{"docs":{},"可":{"docs":{},"以":{"docs":{},"查":{"docs":{},"看":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"中":{"docs":{},"，":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}},"实":{"docs":{},"际":{"docs":{},"应":{"docs":{},"用":{"docs":{},"中":{"docs":{},"，":{"docs":{},"当":{"docs":{},"你":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"进":{"docs":{},"行":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"这":{"docs":{},"样":{"docs":{},"使":{"docs":{},"用":{"docs":{},"微":{"docs":{},"调":{"docs":{},"后":{"docs":{},"的":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{},"后":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"测":{"docs":{},"试":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"（":{"docs":{},"不":{"docs":{},"包":{"docs":{},"含":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"）":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"测":{"docs":{},"试":{"docs":{},"。":{"docs":{},"输":{"docs":{},"入":{"docs":{},"文":{"docs":{},"本":{"docs":{},"并":{"docs":{},"观":{"docs":{},"察":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"与":{"docs":{},"实":{"docs":{},"际":{"docs":{},"标":{"docs":{},"签":{"docs":{},"进":{"docs":{},"行":{"docs":{},"比":{"docs":{},"较":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"准":{"docs":{},"确":{"docs":{},"率":{"docs":{},"、":{"docs":{},"召":{"docs":{},"回":{"docs":{},"率":{"docs":{},"等":{"docs":{},"性":{"docs":{},"能":{"docs":{},"指":{"docs":{},"标":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"到":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"可":{"docs":{},"用":{"docs":{},"性":{"docs":{},"、":{"docs":{},"可":{"docs":{},"扩":{"docs":{},"展":{"docs":{},"性":{"docs":{},"和":{"docs":{},"性":{"docs":{},"能":{"docs":{},"等":{"docs":{},"因":{"docs":{},"素":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"上":{"docs":{},"下":{"docs":{},"载":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{},"即":{"docs":{},"可":{"docs":{},"。":{"docs":{},"下":{"docs":{},"载":{"docs":{},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"d":{"docs":{},"m":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"安":{"docs":{},"装":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"上":{"docs":{},"面":{"docs":{},"需":{"docs":{},"要":{"docs":{},"安":{"docs":{},"装":{"docs":{},"好":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{},"中":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"外":{"docs":{},"，":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"需":{"docs":{},"要":{"docs":{},"安":{"docs":{},"装":{"docs":{},"好":{"docs":{},"正":{"docs":{},"常":{"docs":{},"的":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"即":{"docs":{},"可":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"上":{"docs":{},"微":{"docs":{},"调":{"docs":{},"基":{"docs":{},"础":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}},"经":{"docs":{},"过":{"docs":{},"微":{"docs":{},"调":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"上":{"docs":{},"运":{"docs":{},"行":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}},"段":{"docs":{},"落":{"docs":{},"上":{"docs":{},"显":{"docs":{},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"地":{"docs":{},"图":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}}}},"大":{"docs":{},"致":{"docs":{},"分":{"docs":{},"三":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"思":{"docs":{},"路":{"docs":{},"：":{"docs":{},"在":{"docs":{},"前":{"docs":{},"向":{"docs":{},"反":{"docs":{},"馈":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"“":{"docs":{},"涌":{"docs":{},"现":{"docs":{},"”":{"docs":{},"的":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"，":{"docs":{},"究":{"docs":{},"竟":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"什":{"docs":{},"么":{"docs":{},"能":{"docs":{},"力":{"docs":{},"？":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"，":{"docs":{},"来":{"docs":{},"执":{"docs":{},"行":{"docs":{},"相":{"docs":{},"应":{"docs":{},"信":{"docs":{},"息":{"docs":{},"提":{"docs":{},"取":{"docs":{},"以":{"docs":{},"及":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"形":{"docs":{},"式":{"docs":{},"化":{"docs":{},"成":{"docs":{},"不":{"docs":{},"同":{"docs":{},"形":{"docs":{},"式":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"【":{"docs":{},"例":{"docs":{},"如":{"docs":{},"三":{"docs":{},"元":{"docs":{},"组":{"docs":{},"，":{"docs":{},"多":{"docs":{},"元":{"docs":{},"组":{"docs":{},"或":{"docs":{},"者":{"docs":{},"事":{"docs":{},"件":{"docs":{},"链":{"docs":{},"条":{"docs":{},"】":{"docs":{},"。":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}},"于":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.005649717514124294}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"本":{"docs":{},"文":{"docs":{},"的":{"docs":{},"重":{"docs":{},"点":{"docs":{},"，":{"docs":{},"有":{"docs":{},"时":{"docs":{},"将":{"docs":{},"解":{"docs":{},"释":{"docs":{},"视":{"docs":{},"为":{"docs":{},"导":{"docs":{},"致":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"链":{"docs":{},"（":{"docs":{},"通":{"docs":{},"常":{"docs":{},"是":{"docs":{},"句":{"docs":{},"子":{"docs":{},"）":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"众":{"docs":{},"包":{"docs":{},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"链":{"docs":{},"很":{"docs":{},"困":{"docs":{},"难":{"docs":{},"，":{"docs":{},"现":{"docs":{},"有":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"通":{"docs":{},"常":{"docs":{},"会":{"docs":{},"简":{"docs":{},"化":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"收":{"docs":{},"集":{"docs":{},"支":{"docs":{},"持":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"它":{"docs":{},"们":{"docs":{},"如":{"docs":{},"何":{"docs":{},"组":{"docs":{},"合":{"docs":{},"，":{"docs":{},"和":{"docs":{},"/":{"docs":{},"或":{"docs":{},"主":{"docs":{},"要":{"docs":{},"集":{"docs":{},"中":{"docs":{},"在":{"docs":{},"单":{"docs":{},"跳":{"docs":{},"（":{"docs":{},"长":{"docs":{},"度":{"docs":{},"为":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"比":{"docs":{},"数":{"docs":{},"据":{"docs":{},"（":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"，":{"docs":{},"给":{"docs":{},"定":{"docs":{},"（":{"docs":{},"a":{"docs":{},"）":{"docs":{},"所":{"docs":{},"有":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{},"（":{"docs":{},"黄":{"docs":{},"金":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"叶":{"docs":{},"子":{"docs":{},"）":{"docs":{},"，":{"docs":{},"（":{"docs":{},"b":{"docs":{},"）":{"docs":{},"所":{"docs":{},"有":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"和":{"docs":{},"一":{"docs":{},"些":{"docs":{},"干":{"docs":{},"扰":{"docs":{},"语":{"docs":{},"句":{"docs":{},"，":{"docs":{},"或":{"docs":{},"(":{"docs":{},"c":{"docs":{},")":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"专":{"docs":{},"家":{"docs":{},"注":{"docs":{},"释":{"docs":{},"器":{"docs":{},"构":{"docs":{},"建":{"docs":{},"，":{"docs":{},"是":{"docs":{},"同":{"docs":{},"类":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"中":{"docs":{},"的":{"docs":{},"首":{"docs":{},"个":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"模":{"docs":{},"型":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"docs":{}},"docs":{}}}}}}}},"文":{"docs":{},"本":{"docs":{},"和":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"适":{"docs":{},"用":{"docs":{},"于":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}},"微":{"docs":{},"调":{"docs":{},"封":{"docs":{},"装":{"docs":{},"成":{"docs":{},"一":{"docs":{},"种":{"docs":{},"服":{"docs":{},"务":{"docs":{},"，":{"docs":{},"使":{"docs":{},"开":{"docs":{},"发":{"docs":{},"人":{"docs":{},"员":{"docs":{},"可":{"docs":{},"以":{"docs":{},"轻":{"docs":{},"松":{"docs":{},"将":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}},"解":{"docs":{},"释":{"docs":{},"表":{"docs":{},"述":{"docs":{},"为":{"docs":{},"多":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"、":{"docs":{},"多":{"docs":{},"前":{"docs":{},"提":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}},"左":{"docs":{},"右":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"微":{"docs":{},"调":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}},"范":{"docs":{},"式":{"docs":{},"对":{"docs":{},"比":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}},"作":{"docs":{},"用":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}},"步":{"docs":{},"骤":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}},"数":{"docs":{},"据":{"docs":{},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"成":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}},"所":{"docs":{},"以":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}},"一":{"docs":{},"张":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"示":{"docs":{},"，":{"docs":{},"由":{"docs":{},"单":{"docs":{},"个":{"docs":{},"多":{"docs":{},"前":{"docs":{},"提":{"docs":{},"文":{"docs":{},"本":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}},"把":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"推":{"docs":{},"理":{"docs":{},"直":{"docs":{},"接":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"提":{"docs":{},"供":{"docs":{},"一":{"docs":{},"个":{"docs":{},"分":{"docs":{},"区":{"docs":{},"（":{"docs":{},"也":{"docs":{},"称":{"docs":{},"为":{"docs":{},"分":{"docs":{},"片":{"docs":{},"）":{"docs":{},"。":{"docs":{},"这":{"docs":{},"导":{"docs":{},"致":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"托":{"docs":{},"管":{"docs":{},"数":{"docs":{},"据":{"docs":{},"生":{"docs":{},"成":{"docs":{},"器":{"docs":{},"，":{"docs":{},"只":{"docs":{},"需":{"docs":{},"几":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"即":{"docs":{},"可":{"docs":{},"将":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}},"种":{"docs":{},"托":{"docs":{},"管":{"docs":{},"化":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"生":{"docs":{},"成":{"docs":{},"器":{"docs":{},"，":{"docs":{},"只":{"docs":{},"需":{"docs":{},"执":{"docs":{},"行":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}},"快":{"docs":{},"速":{"docs":{},"调":{"docs":{},"优":{"docs":{},"功":{"docs":{},"能":{"docs":{},"，":{"docs":{},"只":{"docs":{},"需":{"docs":{},"一":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"即":{"docs":{},"可":{"docs":{},"在":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{},"省":{"docs":{},"内":{"docs":{},"存":{"docs":{},"方":{"docs":{},"法":{"docs":{},"之":{"docs":{},"一":{"docs":{},"【":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"转":{"docs":{},"换":{"docs":{},"】":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"加":{"docs":{},"速":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"在":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"时":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"说":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"储":{"docs":{},"存":{"docs":{},"两":{"docs":{},"倍":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"对":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"进":{"docs":{},"行":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"析":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{},"根":{"docs":{},"据":{"docs":{},"文":{"docs":{},"本":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"判":{"docs":{},"断":{"docs":{},"其":{"docs":{},"情":{"docs":{},"感":{"docs":{},"是":{"docs":{},"正":{"docs":{},"面":{"docs":{},"、":{"docs":{},"负":{"docs":{},"面":{"docs":{},"还":{"docs":{},"是":{"docs":{},"中":{"docs":{},"性":{"docs":{},"。":{"docs":{},"以":{"docs":{},"下":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"指":{"docs":{},"南":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"被":{"docs":{},"原":{"docs":{},"始":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"量":{"docs":{},"化":{"docs":{},"等":{"docs":{},"级":{"docs":{},"，":{"docs":{},"不":{"docs":{},"加":{"docs":{},"此":{"docs":{},"选":{"docs":{},"项":{"docs":{},"则":{"docs":{},"默":{"docs":{},"认":{"docs":{},"为":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}},"框":{"docs":{},"架":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"梯":{"docs":{},"度":{"docs":{},"计":{"docs":{},"算":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"：":{"docs":{},"等":{"docs":{},"于":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"*":{"docs":{},"每":{"docs":{},"个":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"参":{"docs":{},"数":{"docs":{},"所":{"docs":{},"需":{"docs":{},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"一":{"docs":{},"个":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}},"户":{"docs":{},"提":{"docs":{},"问":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{},"将":{"docs":{},"用":{"docs":{},"户":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"进":{"docs":{},"行":{"docs":{},"同":{"docs":{},"义":{"docs":{},"词":{"docs":{},"+":{"docs":{},"历":{"docs":{},"史":{"docs":{},"信":{"docs":{},"息":{"docs":{},"扩":{"docs":{},"充":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"选":{"docs":{},"取":{"docs":{},"目":{"docs":{},"前":{"docs":{},"词":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"效":{"docs":{},"果":{"docs":{},"最":{"docs":{},"佳":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"词":{"docs":{},"向":{"docs":{},"量":{"docs":{},"建":{"docs":{},"模":{"docs":{},"，":{"docs":{},"将":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"词":{"docs":{},"向":{"docs":{},"量":{"docs":{},"与":{"docs":{},"本":{"docs":{},"地":{"docs":{},"知":{"docs":{},"识":{"docs":{},"库":{"docs":{},"的":{"docs":{},"向":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"库":{"docs":{},"进":{"docs":{},"行":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"检":{"docs":{},"索":{"docs":{},"，":{"docs":{},"将":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"结":{"docs":{},"果":{"docs":{},"进":{"docs":{},"行":{"docs":{},"聚":{"docs":{},"类":{"docs":{},"，":{"docs":{},"扩":{"docs":{},"充":{"docs":{},"得":{"docs":{},"到":{"docs":{},"与":{"docs":{},"该":{"docs":{},"问":{"docs":{},"题":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"更":{"docs":{},"全":{"docs":{},"回":{"docs":{},"答":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"并":{"docs":{},"基":{"docs":{},"于":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"进":{"docs":{},"行":{"docs":{},"排":{"docs":{},"序":{"docs":{},"得":{"docs":{},"到":{"docs":{},"喂":{"docs":{},"给":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"简":{"docs":{},"述":{"docs":{},"原":{"docs":{},"理":{"docs":{},"：":{"docs":{},"微":{"docs":{},"调":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"时":{"docs":{},"，":{"docs":{},"更":{"docs":{},"新":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"往":{"docs":{},"往":{"docs":{},"是":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"。":{"docs":{},"（":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"是":{"docs":{},"指":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"中":{"docs":{},"包":{"docs":{},"含":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"较":{"docs":{},"低":{"docs":{},"维":{"docs":{},"度":{"docs":{},"的":{"docs":{},"子":{"docs":{},"空":{"docs":{},"间":{"docs":{},"进":{"docs":{},"行":{"docs":{},"近":{"docs":{},"似":{"docs":{},"表":{"docs":{},"示":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"，":{"docs":{},"由":{"docs":{},"于":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"在":{"docs":{},"储":{"docs":{},"存":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"方":{"docs":{},"面":{"docs":{},"都":{"docs":{},"有":{"docs":{},"优":{"docs":{},"势":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"它":{"docs":{},"们":{"docs":{},"被":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"应":{"docs":{},"用":{"docs":{},"于":{"docs":{},"压":{"docs":{},"缩":{"docs":{},"、":{"docs":{},"降":{"docs":{},"噪":{"docs":{},"、":{"docs":{},"特":{"docs":{},"征":{"docs":{},"提":{"docs":{},"取":{"docs":{},"、":{"docs":{},"模":{"docs":{},"型":{"docs":{},"压":{"docs":{},"缩":{"docs":{},"等":{"docs":{},"任":{"docs":{},"务":{"docs":{},"）":{"docs":{},"（":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"的":{"docs":{},"秩":{"docs":{},"是":{"docs":{},"指":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"中":{"docs":{},"线":{"docs":{},"性":{"docs":{},"无":{"docs":{},"关":{"docs":{},"的":{"docs":{},"行":{"docs":{},"或":{"docs":{},"列":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"数":{"docs":{},"目":{"docs":{},"）":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"单":{"docs":{},"总":{"docs":{},"结":{"docs":{},"就":{"docs":{},"是":{"docs":{},"说":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"就":{"docs":{},"是":{"docs":{},"利":{"docs":{},"用":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"能":{"docs":{},"力":{"docs":{},"帮":{"docs":{},"我":{"docs":{},"们":{"docs":{},"完":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"而":{"docs":{},"言":{"docs":{},"之":{"docs":{},"：":{"docs":{},"在":{"docs":{},"外":{"docs":{},"面":{"docs":{},"包":{"docs":{},"了":{"docs":{},"一":{"docs":{},"层":{"docs":{},"语":{"docs":{},"义":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"，":{"docs":{},"先":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"再":{"docs":{},"打":{"docs":{},"包":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"发":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"回":{"docs":{},"答":{"docs":{},"。":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"约":{"docs":{},"而":{"docs":{},"不":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"牛":{"docs":{},"仔":{"docs":{},"外":{"docs":{},"套":{"docs":{},",":{"docs":{},"白":{"docs":{},"色":{"docs":{},"的":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"十":{"docs":{},"分":{"docs":{},"百":{"docs":{},"搭":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"多":{"docs":{},"处":{"docs":{},"有":{"docs":{},"做":{"docs":{},"旧":{"docs":{},"破":{"docs":{},"洞":{"docs":{},"设":{"docs":{},"计":{"docs":{},",":{"docs":{},"打":{"docs":{},"破":{"docs":{},"单":{"docs":{},"调":{"docs":{},"乏":{"docs":{},"味":{"docs":{},",":{"docs":{},"增":{"docs":{},"加":{"docs":{},"一":{"docs":{},"丝":{"docs":{},"造":{"docs":{},"型":{"docs":{},"看":{"docs":{},"点":{"docs":{},"。":{"docs":{},"衣":{"docs":{},"身":{"docs":{},"后":{"docs":{},"背":{"docs":{},"处":{"docs":{},"有":{"docs":{},"趣":{"docs":{},"味":{"docs":{},"刺":{"docs":{},"绣":{"docs":{},"装":{"docs":{},"饰":{"docs":{},",":{"docs":{},"丰":{"docs":{},"富":{"docs":{},"层":{"docs":{},"次":{"docs":{},"感":{"docs":{},",":{"docs":{},"彰":{"docs":{},"显":{"docs":{},"别":{"docs":{},"样":{"docs":{},"时":{"docs":{},"尚":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"介":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}},"类":{"docs":{},"似":{"docs":{},"，":{"docs":{},"均":{"docs":{},"通":{"docs":{},"过":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"型":{"docs":{},"#":{"docs":{},"上":{"docs":{},"衣":{"docs":{},"*":{"docs":{},"材":{"docs":{},"质":{"docs":{},"#":{"docs":{},"牛":{"docs":{},"仔":{"docs":{},"布":{"docs":{},"*":{"docs":{},"颜":{"docs":{},"色":{"docs":{},"#":{"docs":{},"白":{"docs":{},"色":{"docs":{},"*":{"docs":{},"风":{"docs":{},"格":{"docs":{},"#":{"docs":{},"简":{"docs":{},"约":{"docs":{},"*":{"docs":{},"图":{"docs":{},"案":{"docs":{},"#":{"docs":{},"刺":{"docs":{},"绣":{"docs":{},"*":{"docs":{},"衣":{"docs":{},"样":{"docs":{},"式":{"docs":{},"#":{"docs":{},"外":{"docs":{},"套":{"docs":{},"*":{"docs":{},"衣":{"docs":{},"款":{"docs":{},"式":{"docs":{},"#":{"docs":{},"破":{"docs":{},"洞":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"精":{"docs":{},"度":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"需":{"docs":{},"要":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.00847457627118644}}}}}}}}},"；":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}},"加":{"docs":{},"载":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"综":{"docs":{},"合":{"1":{"docs":{},"、":{"2":{"docs":{},"、":{"3":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"8":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}},"docs":{}}}}}}}},"docs":{}}},"docs":{}}},"docs":{}}},"这":{"docs":{},"篇":{"docs":{},"博":{"docs":{},"文":{"docs":{},"解":{"docs":{},"释":{"docs":{},"了":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}},"个":{"docs":{},"想":{"docs":{},"法":{"docs":{},"是":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"使":{"docs":{},"用":{"docs":{},"监":{"docs":{},"督":{"docs":{},"来":{"docs":{},"教":{"docs":{},"授":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"执":{"docs":{},"行":{"docs":{},"通":{"docs":{},"过":{"docs":{},"指":{"docs":{},"令":{"docs":{},"描":{"docs":{},"述":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"将":{"docs":{},"学":{"docs":{},"会":{"docs":{},"遵":{"docs":{},"循":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"即":{"docs":{},"使":{"docs":{},"是":{"docs":{},"对":{"docs":{},"于":{"docs":{},"未":{"docs":{},"见":{"docs":{},"过":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"也":{"docs":{},"能":{"docs":{},"如":{"docs":{},"此":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"些":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"应":{"docs":{},"该":{"docs":{},"是":{"docs":{},"相":{"docs":{},"互":{"docs":{},"关":{"docs":{},"联":{"docs":{},"的":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"都":{"docs":{},"可":{"docs":{},"以":{"docs":{},"作":{"docs":{},"为":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"子":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"目":{"docs":{},"标":{"docs":{},"和":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"应":{"docs":{},"该":{"docs":{},"与":{"docs":{},"任":{"docs":{},"务":{"docs":{},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"并":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"模":{"docs":{},"型":{"docs":{},"学":{"docs":{},"习":{"docs":{},"与":{"docs":{},"该":{"docs":{},"任":{"docs":{},"务":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"样":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"训":{"docs":{},"练":{"docs":{},"了":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"让":{"docs":{},"模":{"docs":{},"型":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"识":{"docs":{},"别":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"意":{"docs":{},"图":{"docs":{},"，":{"docs":{},"同":{"docs":{},"时":{"docs":{},"也":{"docs":{},"在":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"种":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"分":{"docs":{},"解":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"用":{"docs":{},"在":{"docs":{},"提":{"docs":{},"示":{"docs":{},"学":{"docs":{},"习":{"docs":{},"中":{"docs":{},"，":{"docs":{},"就":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"将":{"docs":{},"大":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"分":{"docs":{},"解":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"直":{"docs":{},"观":{"docs":{},"地":{"docs":{},"展":{"docs":{},"现":{"docs":{},"出":{"docs":{},"来":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"开":{"docs":{},"发":{"docs":{},"人":{"docs":{},"员":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"推":{"docs":{},"理":{"docs":{},"出":{"docs":{},"现":{"docs":{},"错":{"docs":{},"误":{"docs":{},"时":{"docs":{},"，":{"docs":{},"就":{"docs":{},"及":{"docs":{},"时":{"docs":{},"地":{"docs":{},"修":{"docs":{},"复":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"转":{"docs":{},"移":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"节":{"docs":{},"省":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}},"要":{"docs":{},"求":{"docs":{},"参":{"docs":{},"与":{"docs":{},"的":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}},"仅":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"小":{"docs":{},"组":{"docs":{},"参":{"docs":{},"数":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"传":{"docs":{},"统":{"docs":{},"微":{"docs":{},"调":{"docs":{},"技":{"docs":{},"术":{"docs":{},"需":{"docs":{},"要":{"docs":{},"大":{"docs":{},"量":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"现":{"docs":{},"有":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"子":{"docs":{},"集":{"docs":{},"或":{"docs":{},"新":{"docs":{},"添":{"docs":{},"加":{"docs":{},"的":{"docs":{},"一":{"docs":{},"组":{"docs":{},"参":{"docs":{},"数":{"docs":{},"通":{"docs":{},"过":{"docs":{},"仅":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"小":{"docs":{},"组":{"docs":{},"参":{"docs":{},"数":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"传":{"docs":{},"统":{"docs":{},"微":{"docs":{},"调":{"docs":{},"技":{"docs":{},"术":{"docs":{},"需":{"docs":{},"要":{"docs":{},"大":{"docs":{},"量":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"现":{"docs":{},"有":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"子":{"docs":{},"集":{"docs":{},"或":{"docs":{},"新":{"docs":{},"添":{"docs":{},"加":{"docs":{},"的":{"docs":{},"一":{"docs":{},"组":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"提":{"docs":{},"供":{"docs":{},"以":{"docs":{},"下":{"docs":{},"功":{"docs":{},"能":{"docs":{},"，":{"docs":{},"微":{"docs":{},"调":{"docs":{},"可":{"docs":{},"让":{"docs":{},"您":{"docs":{},"从":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"提":{"docs":{},"供":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"获":{"docs":{},"得":{"docs":{},"更":{"docs":{},"多":{"docs":{},"信":{"docs":{},"息":{"docs":{},"：":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"上":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"我":{"docs":{},"们":{"docs":{},"可":{"docs":{},"以":{"docs":{},"得":{"docs":{},"到":{"docs":{},"如":{"docs":{},"下":{"docs":{},"结":{"docs":{},"果":{"docs":{},"：":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"大":{"docs":{},"约":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"1":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"常":{"docs":{},"从":{"docs":{},"最":{"docs":{},"底":{"docs":{},"部":{"docs":{},"的":{"docs":{},"叶":{"docs":{},"节":{"docs":{},"点":{"docs":{},"开":{"docs":{},"始":{"docs":{},"，":{"docs":{},"从":{"docs":{},"它":{"docs":{},"们":{"docs":{},"中":{"docs":{},"创":{"docs":{},"作":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"论":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"逐":{"docs":{},"步":{"docs":{},"在":{"docs":{},"树":{"docs":{},"的":{"docs":{},"更":{"docs":{},"高":{"docs":{},"层":{"docs":{},"次":{"docs":{},"上":{"docs":{},"工":{"docs":{},"作":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"他":{"docs":{},"们":{"docs":{},"创":{"docs":{},"作":{"docs":{},"出":{"docs":{},"直":{"docs":{},"接":{"docs":{},"回":{"docs":{},"答":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"结":{"docs":{},"论":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"里":{"docs":{},"声":{"docs":{},"明":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}},"需":{"docs":{},"要":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.011299435028248588}},"检":{"docs":{},"测":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"是":{"docs":{},"否":{"docs":{},"正":{"docs":{},"确":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"如":{"docs":{},"下":{"docs":{},"命":{"docs":{},"令":{"docs":{},"检":{"docs":{},"查":{"docs":{},"（":{"docs":{},"下":{"docs":{},"面":{"docs":{},"是":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"代":{"docs":{},"码":{"docs":{},"）":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"上":{"docs":{},"，":{"docs":{},"官":{"docs":{},"方":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"清":{"docs":{},"华":{"docs":{},"云":{"docs":{},"上":{"docs":{},"的":{"docs":{},"下":{"docs":{},"载":{"docs":{},"地":{"docs":{},"址":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"那":{"docs":{},"个":{"docs":{},"只":{"docs":{},"包":{"docs":{},"含":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"结":{"docs":{},"果":{"docs":{},"文":{"docs":{},"件":{"docs":{},"即":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"文":{"docs":{},"件":{"docs":{},"，":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"首":{"docs":{},"先":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"精":{"docs":{},"度":{"docs":{},"对":{"docs":{},"所":{"docs":{},"需":{"docs":{},"内":{"docs":{},"存":{"docs":{},"的":{"docs":{},"影":{"docs":{},"响":{"docs":{},"：":{"docs":{"Chapter2/微调范式对比.html":{"ref":"Chapter2/微调范式对比.html","tf":0.002824858757062147}}}}}}}}}}}}}}},"，":{"docs":{},"你":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"个":{"docs":{},"带":{"docs":{},"有":{"docs":{},"标":{"docs":{},"签":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"以":{"docs":{},"便":{"docs":{},"在":{"docs":{},"情":{"docs":{},"感":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"应":{"docs":{},"该":{"docs":{},"包":{"docs":{},"含":{"docs":{},"多":{"docs":{},"个":{"docs":{},"实":{"docs":{},"例":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"实":{"docs":{},"例":{"docs":{},"都":{"docs":{},"有":{"docs":{},"一":{"docs":{},"段":{"docs":{},"文":{"docs":{},"本":{"docs":{},"和":{"docs":{},"一":{"docs":{},"个":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"情":{"docs":{},"感":{"docs":{},"标":{"docs":{},"签":{"docs":{},"（":{"docs":{},"正":{"docs":{},"面":{"docs":{},"、":{"docs":{},"负":{"docs":{},"面":{"docs":{},"或":{"docs":{},"中":{"docs":{},"性":{"docs":{},"）":{"docs":{},"。":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"开":{"docs":{},"源":{"docs":{},"的":{"docs":{},"，":{"docs":{},"如":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"需":{"docs":{},"要":{"docs":{},"从":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"上":{"docs":{},"下":{"docs":{},"载":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"t":{"docs":{},"x":{"docs":{},"t":{"docs":{},"来":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"我":{"docs":{},"们":{"docs":{},"安":{"docs":{},"装":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"的":{"docs":{},"库":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"称":{"docs":{},"为":{"docs":{},"适":{"docs":{},"配":{"docs":{},"器":{"docs":{},"训":{"docs":{},"练":{"docs":{},"(":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}},"外":{"docs":{},"，":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"总":{"docs":{},"结":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}},"：":{"docs":{},"将":{"docs":{},"除":{"docs":{},"了":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"以":{"docs":{},"外":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"权":{"docs":{},"重":{"docs":{},"“":{"docs":{},"冻":{"docs":{},"结":{"docs":{},"”":{"docs":{},"（":{"docs":{},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"z":{"docs":{},"e":{"docs":{},"）":{"docs":{},"。":{"docs":{},"然":{"docs":{},"后":{"docs":{},"随":{"docs":{},"机":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"再":{"docs":{},"以":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{},"仅":{"docs":{},"仅":{"docs":{},"更":{"docs":{},"新":{"docs":{},"全":{"docs":{},"连":{"docs":{},"接":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"，":{"docs":{},"其":{"docs":{},"它":{"docs":{},"层":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"不":{"docs":{},"变":{"docs":{},"。":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"开":{"docs":{},"始":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"更":{"docs":{},"加":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"和":{"docs":{},"现":{"docs":{},"实":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"可":{"docs":{},"以":{"docs":{},"出":{"docs":{},"现":{"docs":{},"自":{"docs":{},"动":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"把":{"docs":{},"一":{"docs":{},"个":{"docs":{},"多":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"推":{"docs":{},"理":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"分":{"docs":{},"解":{"docs":{},"成":{"docs":{},"很":{"docs":{},"多":{"docs":{},"个":{"docs":{},"中":{"docs":{},"间":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"，":{"docs":{},"生":{"docs":{},"成":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"再":{"docs":{},"把":{"docs":{},"这":{"docs":{},"些":{"docs":{},"答":{"docs":{},"案":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"在":{"docs":{},"一":{"docs":{},"起":{"docs":{},"进":{"docs":{},"行":{"docs":{},"求":{"docs":{},"解":{"docs":{},"。":{"docs":{},"【":{"docs":{},"因":{"docs":{},"式":{"docs":{},"分":{"docs":{},"解":{"docs":{},"】":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"显":{"docs":{},"示":{"docs":{},"从":{"docs":{},"已":{"docs":{},"知":{"docs":{},"到":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"线":{"docs":{},"来":{"docs":{},"解":{"docs":{},"释":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"简":{"docs":{},"单":{"docs":{},"地":{"docs":{},"显":{"docs":{},"示":{"docs":{},"文":{"docs":{},"本":{"docs":{},"证":{"docs":{},"据":{"docs":{},"的":{"docs":{},"片":{"docs":{},"段":{"docs":{},"。":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"之":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"方":{"docs":{},"法":{"docs":{},"都":{"docs":{},"有":{"docs":{},"助":{"docs":{},"于":{"docs":{},"提":{"docs":{},"高":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"能":{"docs":{},"力":{"docs":{},"和":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"理":{"docs":{},"解":{"docs":{},"能":{"docs":{},"力":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"和":{"docs":{},"目":{"docs":{},"的":{"docs":{},"略":{"docs":{},"有":{"docs":{},"不":{"docs":{},"同":{"docs":{},"。":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"经":{"docs":{},"典":{"docs":{},"的":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"ref":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","tf":0.012048192771084338}}}}}}}}},"“":{"docs":{},"|":{"docs":{},"|":{"docs":{},"|":{"docs":{},"”":{"docs":{},"）":{"docs":{},"分":{"docs":{},"隔":{"docs":{},"。":{"docs":{},"如":{"docs":{},"下":{"docs":{},"所":{"docs":{},"示":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}},"与":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"不":{"docs":{},"同":{"docs":{},"，":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"通":{"docs":{},"常":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"更":{"docs":{},"详":{"docs":{},"细":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"执":{"docs":{},"行":{"docs":{},"特":{"docs":{},"定":{"docs":{},"操":{"docs":{},"作":{"docs":{},"或":{"docs":{},"完":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"计":{"docs":{},"算":{"docs":{},"机":{"docs":{},"程":{"docs":{},"序":{"docs":{},"或":{"docs":{},"脚":{"docs":{},"本":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"人":{"docs":{},"类":{"docs":{},"编":{"docs":{},"写":{"docs":{},"的":{"docs":{},"指":{"docs":{},"导":{"docs":{},"性":{"docs":{},"文":{"docs":{},"本":{"docs":{},"。":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"告":{"docs":{},"诉":{"docs":{},"模":{"docs":{},"型":{"docs":{},"如":{"docs":{},"何":{"docs":{},"处":{"docs":{},"理":{"docs":{},"数":{"docs":{},"据":{"docs":{},"或":{"docs":{},"执":{"docs":{},"行":{"docs":{},"某":{"docs":{},"个":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"简":{"docs":{},"单":{"docs":{},"地":{"docs":{},"提":{"docs":{},"供":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"或":{"docs":{},"任":{"docs":{},"务":{"docs":{},"相":{"docs":{},"关":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"输":{"docs":{},"出":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"组":{"docs":{},"成":{"docs":{},"的":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"信":{"docs":{},"息":{"docs":{},"即":{"docs":{},"可":{"docs":{},"理":{"docs":{},"解":{"docs":{},"为":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"。":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"通":{"docs":{},"常":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"短":{"docs":{},"文":{"docs":{},"本":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"导":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"响":{"docs":{},"应":{"docs":{},"。":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"提":{"docs":{},"供":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"和":{"docs":{},"任":{"docs":{},"务":{"docs":{},"相":{"docs":{},"关":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"以":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"模":{"docs":{},"型":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"理":{"docs":{},"解":{"docs":{},"要":{"docs":{},"求":{"docs":{},"，":{"docs":{},"并":{"docs":{},"生":{"docs":{},"成":{"docs":{},"正":{"docs":{},"确":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"为":{"docs":{},"例":{"docs":{},"，":{"docs":{},"其":{"docs":{},"基":{"docs":{},"本":{"docs":{},"流":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}},"允":{"docs":{},"许":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"多":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"中":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"的":{"docs":{},"回":{"docs":{},"答":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"解":{"docs":{},"决":{"docs":{},"问":{"docs":{},"题":{"docs":{},"或":{"docs":{},"完":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"思":{"docs":{},"维":{"docs":{},"链":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{},"训":{"docs":{},"练":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"解":{"docs":{},"成":{"docs":{},"较":{"docs":{},"小":{"docs":{},"、":{"docs":{},"相":{"docs":{},"互":{"docs":{},"关":{"docs":{},"联":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"以":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"模":{"docs":{},"型":{"docs":{},"理":{"docs":{},"解":{"docs":{},"和":{"docs":{},"生":{"docs":{},"成":{"docs":{},"连":{"docs":{},"贯":{"docs":{},"、":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"感":{"docs":{},"知":{"docs":{},"的":{"docs":{},"响":{"docs":{},"应":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"准":{"docs":{},"备":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}},"：":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}},"和":{"docs":{},"上":{"docs":{},"传":{"docs":{},"培":{"docs":{},"训":{"docs":{},"数":{"docs":{},"据":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}},"区":{"docs":{},"别":{"docs":{},"：":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"和":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"都":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"和":{"docs":{},"使":{"docs":{},"用":{"docs":{},"方":{"docs":{},"式":{"docs":{},"是":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"。":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"更":{"docs":{},"多":{"docs":{},"地":{"docs":{},"用":{"docs":{},"于":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"模":{"docs":{},"型":{"docs":{},"理":{"docs":{},"解":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"，":{"docs":{},"而":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"则":{"docs":{},"更":{"docs":{},"多":{"docs":{},"地":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"导":{"docs":{},"模":{"docs":{},"型":{"docs":{},"执":{"docs":{},"行":{"docs":{},"具":{"docs":{},"体":{"docs":{},"操":{"docs":{},"作":{"docs":{},"或":{"docs":{},"完":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"只":{"docs":{},"要":{"docs":{},"我":{"docs":{},"们":{"docs":{},"把":{"docs":{},"希":{"docs":{},"望":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"删":{"docs":{},"除":{"docs":{},"掉":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"尽":{"docs":{},"量":{"docs":{},"构":{"docs":{},"造":{"docs":{},"与":{"docs":{},"该":{"docs":{},"输":{"docs":{},"出":{"docs":{},"有":{"docs":{},"关":{"docs":{},"的":{"docs":{},"其":{"docs":{},"它":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"即":{"docs":{},"可":{"docs":{},"。":{"docs":{},"这":{"docs":{},"就":{"docs":{},"是":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"文":{"docs":{},"本":{"1":{"docs":{},"|":{"docs":{},"|":{"docs":{},"|":{"docs":{},"标":{"docs":{},"签":{"1":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}},"docs":{}}}}}}},"2":{"docs":{},"|":{"docs":{},"|":{"docs":{},"|":{"docs":{},"标":{"docs":{},"签":{"2":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}},"docs":{}}}}}}},"3":{"docs":{},"|":{"docs":{},"|":{"docs":{},"|":{"docs":{},"标":{"docs":{},"签":{"3":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}},"docs":{}}}}}}},"docs":{}}},"方":{"docs":{},"法":{"docs":{},"中":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"被":{"docs":{},"视":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"序":{"docs":{},"列":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"独":{"docs":{},"立":{"docs":{},"的":{"docs":{},"“":{"docs":{},"思":{"docs":{},"考":{"docs":{},"链":{"docs":{},"”":{"docs":{},"或":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"。":{"docs":{},"模":{"docs":{},"型":{"docs":{},"通":{"docs":{},"过":{"docs":{},"将":{"docs":{},"先":{"docs":{},"前":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"作":{"docs":{},"为":{"docs":{},"后":{"docs":{},"续":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"来":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"地":{"docs":{},"生":{"docs":{},"成":{"docs":{},"这":{"docs":{},"些":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"可":{"docs":{},"以":{"docs":{},"让":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"一":{"docs":{},"定":{"docs":{},"程":{"docs":{},"度":{"docs":{},"上":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"人":{"docs":{},"类":{"docs":{},"解":{"docs":{},"决":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"冻":{"docs":{},"结":{"docs":{},"全":{"docs":{},"部":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"可":{"docs":{},"通":{"docs":{},"过":{"docs":{},"调":{"docs":{},"整":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}},"便":{"docs":{},"用":{"docs":{},"户":{"docs":{},"将":{"docs":{},"模":{"docs":{},"型":{"docs":{},"部":{"docs":{},"署":{"docs":{},"到":{"docs":{},"云":{"docs":{},"端":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}},"电":{"docs":{},"影":{"docs":{},"评":{"docs":{},"论":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"你":{"docs":{},"自":{"docs":{},"己":{"docs":{},"收":{"docs":{},"集":{"docs":{},"和":{"docs":{},"标":{"docs":{},"注":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}},"而":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"在":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"中":{"docs":{},"也":{"docs":{},"是":{"docs":{},"类":{"docs":{},"似":{"docs":{},"的":{"docs":{},"想":{"docs":{},"法":{"docs":{},"！":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"就":{"docs":{},"是":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"的":{"docs":{},"前":{"docs":{},"身":{"docs":{},"！":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"：":{"docs":{},"这":{"docs":{},"部":{"docs":{},"电":{"docs":{},"影":{"docs":{},"的":{"docs":{},"剧":{"docs":{},"情":{"docs":{},"令":{"docs":{},"人":{"docs":{},"惊":{"docs":{},"叹":{"docs":{},"，":{"docs":{},"特":{"docs":{},"效":{"docs":{},"也":{"docs":{},"非":{"docs":{},"常":{"docs":{},"出":{"docs":{},"色":{"docs":{},"，":{"docs":{},"我":{"docs":{},"非":{"docs":{},"常":{"docs":{},"喜":{"docs":{},"欢":{"docs":{},"。":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"出":{"docs":{},"：":{"docs":{},"正":{"docs":{},"面":{"docs":{"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"ref":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","tf":0.007462686567164179}}}}}}},"《":{"docs":{},"精":{"docs":{},"准":{"docs":{},"学":{"docs":{},"习":{"docs":{},"》":{"docs":{},"中":{"docs":{},"提":{"docs":{},"出":{"docs":{},"，":{"docs":{},"缓":{"docs":{},"慢":{"docs":{},"地":{"docs":{},"、":{"docs":{},"理":{"docs":{},"智":{"docs":{},"地":{"docs":{},"、":{"docs":{},"符":{"docs":{},"号":{"docs":{},"化":{"docs":{},"地":{"docs":{},"运":{"docs":{},"作":{"docs":{},"，":{"docs":{},"是":{"docs":{},"人":{"docs":{},"脑":{"docs":{},"的":{"docs":{},"特":{"docs":{},"权":{"docs":{},"。":{"docs":{},"它":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"任":{"docs":{},"何":{"docs":{},"可":{"docs":{},"能":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"提":{"docs":{},"取":{"docs":{},"具":{"docs":{},"有":{"docs":{},"普":{"docs":{},"遍":{"docs":{},"性":{"docs":{},"、":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"性":{"docs":{},"的":{"docs":{},"、":{"docs":{},"明":{"docs":{},"确":{"docs":{},"的":{"docs":{},"原":{"docs":{},"则":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"局":{"docs":{},"限":{"docs":{},"：":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}},"策":{"docs":{},"略":{"docs":{},"问":{"docs":{},"题":{"docs":{},"需":{"docs":{},"要":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"世":{"docs":{},"界":{"docs":{},"知":{"docs":{},"识":{"docs":{},"，":{"docs":{},"而":{"docs":{},"小":{"docs":{},"型":{"docs":{},"模":{"docs":{},"型":{"docs":{},"没":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"来":{"docs":{},"记":{"docs":{},"忆":{"docs":{},"这":{"docs":{},"些":{"docs":{},"世":{"docs":{},"界":{"docs":{},"知":{"docs":{},"识":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"也":{"docs":{},"不":{"docs":{},"太":{"docs":{},"可":{"docs":{},"能":{"docs":{},"产":{"docs":{},"生":{"docs":{},"正":{"docs":{},"确":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"。":{"docs":{"Chapter2/思维链.html":{"ref":"Chapter2/思维链.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"类":{"docs":{},"（":{"docs":{},"其":{"docs":{},"中":{"docs":{},"文":{"docs":{},"本":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"按":{"docs":{},"其":{"docs":{},"最":{"docs":{},"相":{"docs":{},"似":{"docs":{},"的":{"docs":{},"标":{"docs":{},"签":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"类":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}},"别":{"docs":{},"是":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}},"为":{"docs":{},"两":{"docs":{},"类":{"docs":{},"：":{"docs":{},"针":{"docs":{},"对":{"docs":{},"单":{"docs":{},"篇":{"docs":{},"事":{"docs":{},"实":{"docs":{},"性":{"docs":{},"问":{"docs":{},"题":{"docs":{},"进":{"docs":{},"行":{"docs":{},"总":{"docs":{},"结":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"（":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"等":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"工":{"docs":{},"具":{"docs":{},"进":{"docs":{},"行":{"docs":{},"文":{"docs":{},"档":{"docs":{},"提":{"docs":{},"问":{"docs":{},"）":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"多":{"docs":{},"样":{"docs":{},"性":{"docs":{},"测":{"docs":{},"量":{"docs":{},"（":{"docs":{},"分":{"docs":{},"析":{"docs":{},"相":{"docs":{},"似":{"docs":{},"性":{"docs":{},"分":{"docs":{},"布":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}},"条":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"以":{"docs":{},"便":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}},"前":{"docs":{},"提":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"，":{"docs":{},"从":{"docs":{},"已":{"docs":{},"知":{"docs":{},"的":{"docs":{},"事":{"docs":{},"实":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"论":{"docs":{},"，":{"docs":{},"到":{"docs":{},"感":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"的":{"docs":{},"假":{"docs":{},"设":{"docs":{},"【":{"docs":{},"转":{"docs":{},"去":{"docs":{},"看":{"docs":{},"了":{"docs":{},"看":{"docs":{},"多":{"docs":{},"前":{"docs":{},"提":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"论":{"docs":{},"文":{"docs":{},"】":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"官":{"docs":{},"方":{"docs":{},"两":{"docs":{},"种":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"：":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"（":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"）":{"docs":{},"；":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"建":{"docs":{},"议":{"docs":{},"（":{"docs":{},"其":{"docs":{},"中":{"docs":{},"建":{"docs":{},"议":{"docs":{},"包":{"docs":{},"含":{"docs":{},"相":{"docs":{},"关":{"docs":{},"文":{"docs":{},"本":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"的":{"docs":{},"项":{"docs":{},"目":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}},"异":{"docs":{},"常":{"docs":{},"检":{"docs":{},"测":{"docs":{},"（":{"docs":{},"其":{"docs":{},"中":{"docs":{},"识":{"docs":{},"别":{"docs":{},"出":{"docs":{},"相":{"docs":{},"关":{"docs":{},"性":{"docs":{},"很":{"docs":{},"小":{"docs":{},"的":{"docs":{},"离":{"docs":{},"群":{"docs":{},"值":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}},"搜":{"docs":{},"索":{"docs":{},"（":{"docs":{},"其":{"docs":{},"中":{"docs":{},"结":{"docs":{},"果":{"docs":{},"按":{"docs":{},"与":{"docs":{},"查":{"docs":{},"询":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"性":{"docs":{},"进":{"docs":{},"行":{"docs":{},"排":{"docs":{},"名":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}},"步":{"docs":{},"骤":{"docs":{},"：":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}},"组":{"docs":{},"成":{"docs":{},"，":{"docs":{},"尽":{"docs":{},"管":{"docs":{},"有":{"docs":{},"许":{"docs":{},"多":{"docs":{},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"单":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"目":{"docs":{},"前":{"docs":{},"不":{"docs":{},"存":{"docs":{},"在":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"批":{"docs":{},"量":{"docs":{},"大":{"docs":{},"小":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}},"比":{"docs":{},"即":{"docs":{},"时":{"docs":{},"设":{"docs":{},"计":{"docs":{},"更":{"docs":{},"高":{"docs":{},"质":{"docs":{},"量":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}},"原":{"docs":{},"来":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"多":{"docs":{},"了":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}},"由":{"docs":{},"于":{"docs":{},"更":{"docs":{},"短":{"docs":{},"的":{"docs":{},"提":{"docs":{},"示":{"docs":{},"而":{"docs":{},"节":{"docs":{},"省":{"docs":{},"令":{"docs":{},"牌":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}},"目":{"docs":{},"前":{"docs":{},"市":{"docs":{},"场":{"docs":{},"上":{"docs":{},"出":{"docs":{},"现":{"docs":{},"的":{"docs":{},"实":{"docs":{},"时":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"基":{"docs":{},"本":{"docs":{},"也":{"docs":{},"是":{"docs":{},"先":{"docs":{},"在":{"docs":{},"网":{"docs":{},"页":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"后":{"docs":{},"将":{"docs":{},"网":{"docs":{},"页":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"提":{"docs":{},"取":{"docs":{},"出":{"docs":{},"来":{"docs":{},"后":{"docs":{},"，":{"docs":{},"一":{"docs":{},"起":{"docs":{},"打":{"docs":{},"包":{"docs":{},"发":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},",":{"docs":{},"让":{"docs":{},"其":{"docs":{},"回":{"docs":{},"复":{"docs":{},"，":{"docs":{},"并":{"docs":{},"没":{"docs":{},"有":{"docs":{},"真":{"docs":{},"正":{"docs":{},"的":{"docs":{},"实":{"docs":{},"现":{"docs":{},"联":{"docs":{},"网":{"docs":{},"功":{"docs":{},"能":{"docs":{},"。":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"录":{"docs":{},"放":{"docs":{},"到":{"docs":{},"本":{"docs":{},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}},"聚":{"docs":{},"类":{"docs":{},"（":{"docs":{},"其":{"docs":{},"中":{"docs":{},"文":{"docs":{},"本":{"docs":{},"字":{"docs":{},"符":{"docs":{},"串":{"docs":{},"按":{"docs":{},"相":{"docs":{},"似":{"docs":{},"性":{"docs":{},"分":{"docs":{},"组":{"docs":{},"）":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"够":{"docs":{},"训":{"docs":{},"练":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{},"比":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"提":{"docs":{},"示":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}}}}}}},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"：":{"docs":{},"矢":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"库":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}}}}}},"降":{"docs":{},"低":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"请":{"docs":{},"求":{"docs":{"Chapter1/根据自己数据库让GPT作答.html":{"ref":"Chapter1/根据自己数据库让GPT作答.html","tf":0.022222222222222223}}}}}}}},"#":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.005488474204171241}},"下":{"docs":{},"载":{"docs":{},"源":{"docs":{},"代":{"docs":{},"码":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}},"脚":{"docs":{},"本":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"关":{"docs":{},"启":{"docs":{},"s":{"docs":{},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"创":{"docs":{},"建":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"s":{"docs":{},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"以":{"docs":{},"便":{"docs":{},"直":{"docs":{},"接":{"docs":{},"运":{"docs":{},"行":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}},"安":{"docs":{},"装":{"docs":{},"依":{"docs":{},"赖":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"测":{"docs":{},"试":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}},"激":{"docs":{},"活":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},"网":{"docs":{},"址":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"显":{"docs":{},"示":{"docs":{},"环":{"docs":{},"境":{"docs":{},"列":{"docs":{},"表":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"\\":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.046875},"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.06366630076838639}}},"x":{"8":{"6":{"docs":{},"_":{"6":{"4":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.015625}}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"~":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"3":{"docs":{},"/":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"下":{"docs":{},"就":{"docs":{},"有":{"docs":{},"模":{"docs":{},"型":{"docs":{},"生":{"docs":{},"成":{"docs":{},"了":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}},"载":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"基":{"docs":{},"础":{"docs":{},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{},"下":{"docs":{},"载":{"docs":{},"完":{"docs":{},"成":{"docs":{},"后":{"docs":{},"放":{"docs":{},"到":{"docs":{},"根":{"docs":{},"目":{"docs":{},"录":{"docs":{},"下":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"羊":{"docs":{},"驼":{"docs":{},"代":{"docs":{},"码":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},"，":{"docs":{},"选":{"docs":{},"择":{"docs":{},"匹":{"docs":{},"配":{"docs":{},"的":{"docs":{},"操":{"docs":{},"作":{"docs":{},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"，":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"码":{"docs":{},"&":{"docs":{},"安":{"docs":{},"装":{"docs":{},"依":{"docs":{},"赖":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"好":{"docs":{},"的":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}},"模":{"docs":{},"型":{"docs":{},"需":{"docs":{},"要":{"docs":{},"先":{"docs":{},"安":{"docs":{},"装":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"后":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"结":{"docs":{},"果":{"docs":{},"文":{"docs":{},"件":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}},"docs":{}}}}}},"云":{"docs":{},"端":{"docs":{},"部":{"docs":{},"署":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}},"具":{"docs":{},"有":{"docs":{},"较":{"docs":{},"低":{"docs":{},"的":{"docs":{},"“":{"docs":{},"内":{"docs":{},"在":{"docs":{},"秩":{"docs":{},"”":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"适":{"docs":{},"应":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{},"k":{"docs":{},"a":{"docs":{},"g":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}},"执":{"docs":{},"行":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}},"论":{"docs":{},"文":{"docs":{},"地":{"docs":{},"址":{"docs":{},"（":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"）":{"docs":{},":":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"/":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"ref":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{},"/":{"2":{"3":{"0":{"4":{"docs":{},".":{"0":{"3":{"2":{"7":{"7":{"docs":{},".":{"docs":{},"p":{"docs":{},"d":{"docs":{},"f":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}},"$":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.03732162458836443}},"l":{"docs":{},"r":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.005488474204171241}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"&":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0021953896816684962}}},"j":{"docs":{},"i":{"docs":{},"e":{"docs":{},"b":{"docs":{},"a":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"}":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0043907793633369925},"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"亿":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"的":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"从":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"官":{"docs":{},"网":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"d":{"docs":{},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"e":{"docs":{},"n":{"docs":{},"/":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{},"下":{"docs":{},"载":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"创":{"docs":{},"建":{"docs":{},"新":{"docs":{},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"名":{"docs":{},"称":{"docs":{},"，":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"想":{"docs":{},"要":{"docs":{},"从":{"docs":{},"本":{"docs":{},"地":{"docs":{},"加":{"docs":{},"载":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}},"运":{"docs":{},"行":{"docs":{},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"出":{"docs":{},"现":{"docs":{},"如":{"docs":{},"下":{"docs":{},"错":{"docs":{},"误":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}},"以":{"docs":{},"上":{"docs":{},"代":{"docs":{},"码":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"是":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"恭":{"docs":{},"喜":{"docs":{},"你":{"docs":{},"，":{"docs":{},"你":{"docs":{},"安":{"docs":{},"装":{"docs":{},"的":{"docs":{},"是":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"中":{"docs":{},"遇":{"docs":{},"到":{"docs":{},"了":{"docs":{},"如":{"docs":{},"下":{"docs":{},"错":{"docs":{},"误":{"docs":{},"提":{"docs":{},"示":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}},"安":{"docs":{},"装":{"docs":{},"依":{"docs":{},"赖":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}},"前":{"docs":{},"说":{"docs":{},"明":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}},"完":{"docs":{},"在":{"docs":{},"c":{"docs":{},"m":{"docs":{},"d":{"docs":{},"中":{"docs":{},"运":{"docs":{},"行":{"docs":{},"”":{"docs":{},"g":{"docs":{},"c":{"docs":{},"c":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}},"已":{"docs":{},"经":{"docs":{},"能":{"docs":{},"生":{"docs":{},"成":{"docs":{},"相":{"docs":{},"当":{"docs":{},"符":{"docs":{},"合":{"docs":{},"人":{"docs":{},"类":{"docs":{},"偏":{"docs":{},"好":{"docs":{},"的":{"docs":{},"回":{"docs":{},"答":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"和":{"docs":{},"评":{"docs":{},"估":{"docs":{},"完":{"docs":{},"成":{"docs":{},"后":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"它":{"docs":{},"部":{"docs":{},"署":{"docs":{},"到":{"docs":{},"适":{"docs":{},"当":{"docs":{},"的":{"docs":{},"平":{"docs":{},"台":{"docs":{},"上":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}}},"或":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}},"者":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"其":{"docs":{},"他":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}},"改":{"docs":{},"为":{"docs":{},"你":{"docs":{},"本":{"docs":{},"地":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"路":{"docs":{},"径":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}},"成":{"docs":{},"你":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"的":{"docs":{},"实":{"docs":{},"际":{"docs":{},"值":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"部":{"docs":{},"署":{"docs":{},"验":{"docs":{},"证":{"docs":{},"演":{"docs":{},"示":{"docs":{},"代":{"docs":{},"码":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}},"更":{"docs":{},"改":{"docs":{},"为":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"保":{"docs":{},"存":{"docs":{},"的":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}},"为":{"docs":{},"宽":{"docs":{},"泛":{"docs":{},"、":{"docs":{},"总":{"docs":{},"结":{"docs":{},"性":{"docs":{},"的":{"docs":{},"跨":{"docs":{},"篇":{"docs":{},"章":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"（":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"自":{"docs":{},"生":{"docs":{},"成":{"docs":{},"）":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}},"架":{"docs":{},"构":{"docs":{},"，":{"docs":{},"具":{"docs":{},"有":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}},"标":{"docs":{},"识":{"docs":{},"符":{"docs":{},"的":{"docs":{},"中":{"docs":{},"英":{"docs":{},"双":{"docs":{},"语":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"辅":{"docs":{},"以":{"docs":{},"监":{"docs":{},"督":{"docs":{},"微":{"docs":{},"调":{"docs":{},"、":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"自":{"docs":{},"助":{"docs":{},"、":{"docs":{},"人":{"docs":{},"类":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"强":{"docs":{},"化":{"docs":{},"学":{"docs":{},"习":{"docs":{},"等":{"docs":{},"技":{"docs":{},"术":{"docs":{},"的":{"docs":{},"加":{"docs":{},"持":{"docs":{},"，":{"6":{"2":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"需":{"docs":{},"要":{"docs":{},"将":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}},"，":{"docs":{},"其":{"docs":{},"实":{"docs":{},"就":{"docs":{},"是":{"docs":{},"第":{"docs":{},"三":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"最":{"docs":{},"后":{"docs":{},"的":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{},"有":{"docs":{},"差":{"docs":{},"异":{"docs":{},"：":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"后":{"docs":{},"面":{"docs":{},"是":{"docs":{},".":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"f":{"docs":{},"(":{"docs":{},")":{"docs":{},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"docs":{},")":{"docs":{},"，":{"docs":{},"而":{"docs":{},"这":{"docs":{},"里":{"docs":{},"是":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"目":{"docs":{},"前":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"：":{"docs":{},"模":{"docs":{},"型":{"docs":{},"量":{"docs":{},"化":{"docs":{},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"一":{"docs":{},"定":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"损":{"docs":{},"失":{"docs":{},"，":{"docs":{},"经":{"docs":{},"过":{"docs":{},"测":{"docs":{},"试":{"docs":{},"，":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"运":{"docs":{},"行":{"docs":{},"一":{"docs":{},"次":{"docs":{},"约":{"1":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}},"docs":{}}}}}}}}}}}}}}}},"安":{"docs":{},"装":{"docs":{},"这":{"docs":{},"个":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"为":{"docs":{},"了":{"docs":{},"编":{"docs":{},"译":{"docs":{},"之":{"docs":{},"前":{"docs":{},"下":{"docs":{},"载":{"docs":{},"的":{"docs":{},"文":{"docs":{},"件":{"docs":{},"中":{"docs":{},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"和":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"文":{"docs":{},"件":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"激":{"docs":{},"活":{"docs":{},"环":{"docs":{},"境":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"保":{"docs":{},"存":{"docs":{},"在":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"早":{"docs":{},"期":{"docs":{},"技":{"docs":{},"术":{"docs":{},"来":{"docs":{},"生":{"docs":{},"成":{"docs":{},"演":{"docs":{},"绎":{"docs":{},"证":{"docs":{},"明":{"docs":{},"。":{"docs":{},"发":{"docs":{},"现":{"docs":{},"这":{"docs":{},"些":{"docs":{},"模":{"docs":{},"型":{"docs":{},"部":{"docs":{},"分":{"docs":{},"地":{"docs":{},"解":{"docs":{},"决":{"docs":{},"了":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"并":{"docs":{},"具":{"docs":{},"有":{"docs":{},"泛":{"docs":{},"化":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"迹":{"docs":{},"象":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"的":{"docs":{},"贡":{"docs":{},"献":{"docs":{},"是":{"docs":{},"：":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"评":{"docs":{},"估":{"docs":{},"数":{"docs":{},"据":{"docs":{},"示":{"docs":{},"例":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}},"测":{"docs":{},"样":{"docs":{},"本":{"docs":{},"示":{"docs":{},"例":{"docs":{},"：":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}},"跟":{"docs":{},"你":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"一":{"docs":{},"致":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}},"运":{"docs":{},"行":{"docs":{},"以":{"docs":{},"下":{"docs":{},"指":{"docs":{},"令":{"docs":{},"进":{"docs":{},"行":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"和":{"docs":{},"评":{"docs":{},"测":{"docs":{},"：":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}},"docs":{}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"长":{"docs":{},"度":{"docs":{},"和":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"学":{"docs":{},"习":{"docs":{},"率":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"进":{"docs":{},"行":{"docs":{},"调":{"docs":{},"节":{"docs":{},"以":{"docs":{},"取":{"docs":{},"得":{"docs":{},"最":{"docs":{},"佳":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"。":{"docs":{"Chapter1/训练部署自己的ChatGLM-6B.html":{"ref":"Chapter1/训练部署自己的ChatGLM-6B.html","tf":0.0010976948408342481}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.007434944237918215}}},"但":{"docs":{},"实":{"docs":{},"际":{"docs":{},"上":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"是":{"docs":{},"需":{"docs":{},"要":{"docs":{},"下":{"docs":{},"载":{"docs":{},"支":{"docs":{},"持":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"默":{"docs":{},"认":{"docs":{},"的":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"这":{"docs":{},"些":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"安":{"docs":{},"装":{"docs":{},"还":{"docs":{},"需":{"docs":{},"要":{"docs":{},"在":{"docs":{},"本":{"docs":{},"地":{"docs":{},"的":{"docs":{},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"s":{"docs":{},"下":{"docs":{},"安":{"docs":{},"装":{"docs":{},"好":{"docs":{},"c":{"docs":{},"/":{"docs":{},"c":{"docs":{},"+":{"docs":{},"+":{"docs":{},"的":{"docs":{},"编":{"docs":{},"译":{"docs":{},"环":{"docs":{},"境":{"docs":{},"。":{"docs":{},"推":{"docs":{},"荐":{"docs":{},"安":{"docs":{},"装":{"docs":{},"t":{"docs":{},"d":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"即":{"docs":{},"在":{"docs":{},"上":{"docs":{},"面":{"docs":{},"下":{"docs":{},"载":{"docs":{},"的":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"此":{"docs":{},"建":{"docs":{},"议":{"docs":{},"全":{"docs":{},"部":{"docs":{},"从":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"上":{"docs":{},"下":{"docs":{},"载":{"docs":{},"所":{"docs":{},"有":{"docs":{},"文":{"docs":{},"件":{"docs":{},"到":{"docs":{},"本":{"docs":{},"地":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"库":{"docs":{},"版":{"docs":{},"本":{"docs":{},"必":{"docs":{},"须":{"docs":{},"是":{"4":{"docs":{},".":{"2":{"7":{"docs":{},".":{"1":{"docs":{},"及":{"docs":{},"以":{"docs":{},"上":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"才":{"docs":{},"可":{"docs":{},"以":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}}}}}},"中":{"docs":{},"的":{"docs":{},"几":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"，":{"docs":{},"用":{"docs":{},"户":{"docs":{},"就":{"docs":{},"能":{"docs":{},"训":{"docs":{},"练":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"大":{"docs":{},"型":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"（":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"）":{"docs":{},"及":{"docs":{},"其":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"而":{"docs":{},"无":{"docs":{},"需":{"docs":{},"使":{"docs":{},"用":{"docs":{},"任":{"docs":{},"何":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"默":{"docs":{},"认":{"docs":{},"超":{"docs":{},"参":{"docs":{},"数":{"docs":{},"（":{"docs":{},"包":{"docs":{},"括":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"）":{"docs":{},"对":{"docs":{},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"上":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"使":{"docs":{},"用":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"定":{"docs":{},"义":{"docs":{},"和":{"docs":{},"调":{"docs":{},"用":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}},"的":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}},"让":{"docs":{},"用":{"docs":{},"户":{"docs":{},"不":{"docs":{},"再":{"docs":{},"需":{"docs":{},"要":{"docs":{},"大":{"docs":{},"型":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}},"还":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"优":{"docs":{},"化":{"docs":{},"之":{"docs":{},"后":{"docs":{},"的":{"docs":{},"正":{"docs":{},"确":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}},"没":{"docs":{},"有":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"需":{"docs":{},"要":{"1":{"3":{"docs":{},"g":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"显":{"docs":{},"存":{"docs":{},"，":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"8":{"docs":{},"量":{"docs":{},"化":{"docs":{},"需":{"docs":{},"要":{"8":{"docs":{},"g":{"docs":{},"b":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"，":{"docs":{},"而":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"4":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"需":{"docs":{},"要":{"6":{"docs":{},"g":{"docs":{},"b":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}},"docs":{}}}}}}}}},"docs":{}}}}}}}}}}}},"docs":{}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}},"然":{"docs":{},"后":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"d":{"docs":{},":":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"\\":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"直":{"docs":{},"接":{"docs":{},"点":{"docs":{},"击":{"docs":{},"上":{"docs":{},"述":{"docs":{},"页":{"docs":{},"面":{"docs":{},"中":{"docs":{},"t":{"docs":{},"d":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}},"那":{"docs":{},"么":{"docs":{},"就":{"docs":{},"是":{"docs":{},"前":{"docs":{},"面":{"docs":{},"说":{"docs":{},"的":{"docs":{},"编":{"docs":{},"译":{"docs":{},"文":{"docs":{},"件":{"docs":{},"出":{"docs":{},"了":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"就":{"docs":{},"必":{"docs":{},"须":{"docs":{},"做":{"docs":{},"上":{"docs":{},"面":{"docs":{},"说":{"docs":{},"的":{"docs":{},"编":{"docs":{},"译":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"那":{"2":{"docs":{},"个":{"docs":{},"s":{"docs":{},"o":{"docs":{},"文":{"docs":{},"件":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"手":{"docs":{},"动":{"docs":{},"加":{"docs":{},"载":{"docs":{},"。":{"docs":{},"新":{"docs":{},"代":{"docs":{},"码":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"文":{"docs":{},"件":{"docs":{},"编":{"docs":{},"译":{"docs":{},"出":{"docs":{},"问":{"docs":{},"题":{"docs":{},"了":{"docs":{},"。":{"docs":{},"那":{"docs":{},"么":{"docs":{},"就":{"docs":{},"需":{"docs":{},"要":{"docs":{},"我":{"docs":{},"们":{"docs":{},"手":{"docs":{},"动":{"docs":{},"去":{"docs":{},"编":{"docs":{},"译":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"文":{"docs":{},"件":{"docs":{},"：":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"l":{"docs":{},"m":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}},"前":{"docs":{},"安":{"docs":{},"装":{"docs":{},"环":{"docs":{},"境":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.011152416356877323}}}}}}}}},"量":{"docs":{},"化":{"docs":{},"下":{"docs":{},"仍":{"docs":{},"然":{"docs":{},"能":{"docs":{},"够":{"docs":{},"进":{"docs":{},"行":{"docs":{},"自":{"docs":{},"然":{"docs":{},"流":{"docs":{},"畅":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"。":{"docs":{"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"ref":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","tf":0.0037174721189591076}}}}}}}}}}}}}}}}}}},"奖":{"docs":{},"励":{"docs":{},"模":{"docs":{},"型":{"docs":{},"：":{"docs":{},"研":{"docs":{},"究":{"docs":{},"人":{"docs":{},"员":{"docs":{},"使":{"docs":{},"用":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}},"帮":{"docs":{},"助":{"docs":{},"性":{"docs":{},"（":{"docs":{},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"p":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"）":{"docs":{},"：":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"人":{"docs":{},"类":{"docs":{},"实":{"docs":{},"现":{"docs":{},"他":{"docs":{},"们":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"能":{"docs":{},"够":{"docs":{},"准":{"docs":{},"确":{"docs":{},"回":{"docs":{},"答":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"是":{"docs":{},"有":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"的":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"效":{"docs":{},"果":{"docs":{},"评":{"docs":{},"估":{"docs":{},"：":{"docs":{},"人":{"docs":{},"类":{"docs":{},"评":{"docs":{},"估":{"3":{"docs":{},"h":{"docs":{},"标":{"docs":{},"准":{"docs":{},"。":{"docs":{},"基":{"docs":{},"于":{"docs":{},"h":{"docs":{},"h":{"docs":{},"h":{"docs":{},"对":{"docs":{},"齐":{"docs":{},"标":{"docs":{},"准":{"docs":{},"，":{"docs":{},"研":{"docs":{},"究":{"docs":{},"人":{"docs":{},"员":{"docs":{},"使":{"docs":{},"用":{"docs":{},"众":{"docs":{},"包":{"docs":{},"平":{"docs":{},"台":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"z":{"docs":{},"o":{"docs":{},"n":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"无":{"docs":{},"害":{"docs":{},"性":{"docs":{},"（":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"m":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"）":{"docs":{},"：":{"docs":{},"是":{"docs":{},"否":{"docs":{},"不":{"docs":{},"会":{"docs":{},"对":{"docs":{},"人":{"docs":{},"类":{"docs":{},"造":{"docs":{},"成":{"docs":{},"伤":{"docs":{},"害":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"产":{"docs":{},"生":{"docs":{},"仇":{"docs":{},"恨":{"docs":{},"言":{"docs":{},"论":{"docs":{},"或":{"docs":{},"提":{"docs":{},"倡":{"docs":{},"暴":{"docs":{},"力":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"不":{"docs":{},"是":{"docs":{},"无":{"docs":{},"害":{"docs":{},"的":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"研":{"docs":{},"究":{"docs":{},"人":{"docs":{},"员":{"docs":{},"基":{"docs":{},"于":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}},"团":{"docs":{},"队":{"docs":{},"收":{"docs":{},"集":{"docs":{},"。":{"docs":{},"【":{"docs":{},"英":{"docs":{},"文":{"docs":{},"】":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}},"结":{"docs":{},"果":{"docs":{},"显":{"docs":{},"示":{"docs":{},"：":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"数":{"docs":{},"据":{"docs":{},"和":{"docs":{},"奖":{"docs":{},"励":{"docs":{},"模":{"docs":{},"型":{"docs":{},"对":{"docs":{},"提":{"docs":{},"高":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}},"构":{"docs":{},"化":{"docs":{},"知":{"docs":{},"识":{"docs":{},"很":{"docs":{},"难":{"docs":{},"构":{"docs":{},"建":{"docs":{},"(":{"docs":{},"因":{"docs":{},"为":{"docs":{},"要":{"docs":{},"设":{"docs":{},"计":{"docs":{},"知":{"docs":{},"识":{"docs":{},"的":{"docs":{},"结":{"docs":{},"构":{"docs":{},"体":{"docs":{},"系":{"docs":{},")":{"docs":{},"，":{"docs":{},"但":{"docs":{},"易":{"docs":{},"于":{"docs":{},"推":{"docs":{},"理":{"docs":{},"(":{"docs":{},"因":{"docs":{},"为":{"docs":{},"有":{"docs":{},"体":{"docs":{},"系":{"docs":{},"结":{"docs":{},"构":{"docs":{},")":{"docs":{},"，":{"docs":{},"非":{"docs":{},"结":{"docs":{},"构":{"docs":{},"化":{"docs":{},"知":{"docs":{},"识":{"docs":{},"易":{"docs":{},"于":{"docs":{},"构":{"docs":{},"建":{"docs":{},"(":{"docs":{},"直":{"docs":{},"接":{"docs":{},"存":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"诚":{"docs":{},"实":{"docs":{},"性":{"docs":{},"（":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"y":{"docs":{},"）":{"docs":{},"：":{"docs":{},"是":{"docs":{},"否":{"docs":{},"提":{"docs":{},"供":{"docs":{},"真":{"docs":{},"实":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"并":{"docs":{},"在":{"docs":{},"必":{"docs":{},"要":{"docs":{},"时":{"docs":{},"表":{"docs":{},"达":{"docs":{},"其":{"docs":{},"不":{"docs":{},"确":{"docs":{},"定":{"docs":{},"性":{"docs":{},"以":{"docs":{},"避":{"docs":{},"免":{"docs":{},"误":{"docs":{},"导":{"docs":{},"人":{"docs":{},"类":{"docs":{},"用":{"docs":{},"户":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"提":{"docs":{},"供":{"docs":{},"虚":{"docs":{},"假":{"docs":{},"信":{"docs":{},"息":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"是":{"docs":{},"不":{"docs":{},"诚":{"docs":{},"实":{"docs":{},"的":{"docs":{},"。":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"轻":{"docs":{},"松":{"docs":{},"打":{"docs":{},"造":{"docs":{},"家":{"docs":{},"用":{"docs":{},"版":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}},"非":{"docs":{},"自":{"docs":{},"然":{"docs":{},"指":{"docs":{},"令":{"docs":{},"评":{"docs":{},"估":{"docs":{},"（":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Chapter3/Self-Instruct数据.html":{"ref":"Chapter3/Self-Instruct数据.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}},"]":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}},"·":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}},"个":{"docs":{},"q":{"docs":{},"a":{"docs":{},"问":{"docs":{},"题":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}},"专":{"docs":{},"家":{"docs":{},"标":{"docs":{},"记":{"docs":{},"、":{"6":{"1":{"docs":{},".":{"2":{"docs":{},"k":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}},"docs":{}}},"docs":{}},"docs":{}}}}}},"人":{"docs":{},"工":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}},"未":{"docs":{},"标":{"docs":{},"记":{"docs":{},"和":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"答":{"docs":{},"案":{"docs":{},"选":{"docs":{},"项":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"数":{"docs":{},"据":{"docs":{},"点":{"docs":{},"生":{"docs":{},"成":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}},"样":{"docs":{},"本":{"docs":{},"变":{"docs":{},"成":{"docs":{},"超":{"docs":{},"过":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"启":{"docs":{},"动":{"docs":{},"任":{"docs":{},"何":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}},"句":{"docs":{},"子":{"docs":{},"（":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"用":{"docs":{},"于":{"docs":{},"伴":{"docs":{},"随":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}},"节":{"docs":{},"点":{"docs":{},"和":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}},"蕴":{"docs":{},"涵":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}},"九":{"docs":{},"、":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"—":{"docs":{},"—":{"docs":{},"来":{"docs":{},"自":{"docs":{},"b":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}},"全":{"docs":{},"面":{"docs":{},"的":{"docs":{},"中":{"docs":{},"文":{"docs":{},"开":{"docs":{},"源":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"合":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}},"八":{"docs":{},"、":{"docs":{},"其":{"docs":{},"他":{"docs":{},"公":{"docs":{},"开":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}},"千":{"docs":{},"言":{"docs":{},"（":{"docs":{},"l":{"docs":{},"u":{"docs":{},"g":{"docs":{},"e":{"docs":{},"）":{"docs":{},"|":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}},"它":{"docs":{},"由":{"docs":{},"卡":{"docs":{},"内":{"docs":{},"基":{"docs":{},"梅":{"docs":{},"隆":{"docs":{},"大":{"docs":{},"学":{"docs":{},"、":{"docs":{},"斯":{"docs":{},"坦":{"docs":{},"福":{"docs":{},"大":{"docs":{},"学":{"docs":{},"和":{"docs":{},"蒙":{"docs":{},"特":{"docs":{},"利":{"docs":{},"尔":{"docs":{},"大":{"docs":{},"学":{"docs":{},"的":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}}}}}}}}}}}}}}}}},"成":{"docs":{},"为":{"docs":{},"一":{"docs":{},"项":{"docs":{},"比":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}}}}}},"篇":{"docs":{},"论":{"docs":{},"文":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"包":{"docs":{},"含":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.008888888888888889}}}}}}}}}}}}}},"飞":{"docs":{},"桨":{"docs":{},"a":{"docs":{},"i":{"docs":{"Chapter3/学术问答数据集调研.html":{"ref":"Chapter3/学术问答数据集调研.html","tf":0.0044444444444444444}}}}}},"万":{"docs":{},"条":{"docs":{},"符":{"docs":{},"合":{"docs":{},"要":{"docs":{},"求":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"最":{"docs":{},"终":{"docs":{},"得":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"大":{"docs":{},"型":{"docs":{},"指":{"docs":{},"令":{"docs":{},"遵":{"docs":{},"循":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}}}}}},"产":{"docs":{},"品":{"docs":{},"定":{"docs":{},"位":{"docs":{},"：":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}},"作":{"docs":{},"用":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}},"为":{"docs":{},"查":{"docs":{},"询":{"docs":{},"从":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}},"响":{"docs":{},"应":{"docs":{},"对":{"docs":{},"。":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}},"引":{"docs":{},"擎":{"docs":{},"，":{"docs":{},"用":{"docs":{},"户":{"docs":{},"可":{"docs":{},"以":{"docs":{},"仅":{"docs":{},"用":{"docs":{},"几":{"docs":{},"行":{"docs":{},"代":{"docs":{},"码":{"docs":{},"就":{"docs":{},"快":{"docs":{},"速":{"docs":{},"从":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"将":{"docs":{},"让":{"docs":{},"模":{"docs":{},"型":{"docs":{},"理":{"docs":{},"解":{"docs":{},"它":{"docs":{},"应":{"docs":{},"如":{"docs":{},"何":{"docs":{},"响":{"docs":{},"应":{"docs":{},"其":{"docs":{},"输":{"docs":{},"入":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{"Chapter4/Lamini.html":{"ref":"Chapter4/Lamini.html","tf":0.011627906976744186}}}}}}}}}}}}}}}}}}}}}}}},"不":{"docs":{},"同":{"docs":{},"点":{"docs":{},"：":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}},"起":{"docs":{},"来":{"docs":{},"就":{"docs":{},"行":{"docs":{},")":{"docs":{},"，":{"docs":{},"但":{"docs":{},"很":{"docs":{},"难":{"docs":{},"用":{"docs":{},"于":{"docs":{},"推":{"docs":{},"理":{"docs":{},"(":{"docs":{},"没":{"docs":{},"有":{"docs":{},"体":{"docs":{},"系":{"docs":{},"结":{"docs":{},"构":{"docs":{},")":{"docs":{},"。":{"docs":{"Chapter4/GPT与知识图谱.html":{"ref":"Chapter4/GPT与知识图谱.html","tf":0.07692307692307693}}}}}}}}}}}}}}}}}}}}}}}},"•":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.024390243902439025}}},"受":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}},"太":{"docs":{},"大":{"docs":{},"而":{"docs":{},"无":{"docs":{},"法":{"docs":{},"直":{"docs":{},"接":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.016260162601626018}}}}}}}}},"年":{"docs":{},"）":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"方":{"docs":{},"法":{"docs":{},"主":{"docs":{},"要":{"docs":{},"设":{"docs":{},"计":{"docs":{},"用":{"docs":{},"于":{"docs":{},"“":{"docs":{},"查":{"docs":{},"找":{"docs":{},"”":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"以":{"docs":{},"解":{"docs":{},"释":{"docs":{},"在":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"中":{"docs":{},"何":{"docs":{},"处":{"docs":{},"/":{"docs":{},"如":{"docs":{},"何":{"docs":{},"找":{"docs":{},"到":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"或":{"docs":{},"用":{"docs":{},"于":{"docs":{},"定":{"docs":{},"位":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"句":{"docs":{},"法":{"docs":{},"模":{"docs":{},"式":{"docs":{},"（":{"docs":{},"y":{"docs":{},"e":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}},"；":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}},"棵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"完":{"docs":{},"整":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"小":{"docs":{},"型":{"docs":{},"和":{"docs":{},"大":{"docs":{},"型":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}},"给":{"docs":{},"定":{"docs":{},"一":{"docs":{},"个":{"docs":{},"假":{"docs":{},"设":{"docs":{},"（":{"docs":{},"问":{"docs":{},"题":{"docs":{},"+":{"docs":{},"答":{"docs":{},"案":{"docs":{},"）":{"docs":{},"，":{"docs":{},"定":{"docs":{},"义":{"docs":{},"了":{"docs":{},"三":{"docs":{},"个":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"难":{"docs":{},"的":{"docs":{},"解":{"docs":{},"释":{"docs":{},"任":{"docs":{},"务":{"docs":{},"：":{"docs":{},"为":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"出":{"docs":{},"一":{"docs":{},"个":{"docs":{},"文":{"docs":{},"本":{"docs":{},"证":{"docs":{},"据":{"docs":{},"的":{"docs":{},"片":{"docs":{},"段":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}}}},"，":{"docs":{},"这":{"docs":{},"是":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"包":{"docs":{},"含":{"docs":{},"多":{"docs":{},"步":{"docs":{},"蕴":{"docs":{},"涵":{"docs":{},"树":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"Chapter4/Entailment Trees论文学习笔记.html":{"ref":"Chapter4/Entailment Trees论文学习笔记.html","tf":0.008130081300813009}}}}}}}}}}}}}}}}}}}},"选":{"docs":{},"择":{"docs":{},"支":{"docs":{},"撑":{"docs":{},"答":{"docs":{},"案":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{"Chapter4/METGEN论文学习笔记.html":{"ref":"Chapter4/METGEN论文学习笔记.html","tf":0.05555555555555555}}}}}}}}}}},"①":{"docs":{},"选":{"docs":{},"取":{"docs":{},"某":{"docs":{},"一":{"docs":{},"领":{"docs":{},"域":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}},"②":{"docs":{},"继":{"docs":{},"续":{"docs":{},"训":{"docs":{},"练":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{},"无":{"docs":{},"监":{"docs":{},"督":{"docs":{},"学":{"docs":{},"习":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}},"③":{"docs":{},"关":{"docs":{},"键":{"docs":{},"：":{"docs":{},"指":{"docs":{},"令":{"docs":{},"微":{"docs":{},"调":{"docs":{},"部":{"docs":{},"分":{"docs":{},"：":{"docs":{},"构":{"docs":{},"建":{"docs":{},"高":{"docs":{},"质":{"docs":{},"量":{"docs":{},"的":{"docs":{},"领":{"docs":{},"域":{"docs":{},"问":{"docs":{},"答":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"。":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}},"④":{"docs":{},"对":{"docs":{},"齐":{"docs":{},"微":{"docs":{},"调":{"docs":{},"：":{"docs":{},"符":{"docs":{},"合":{"docs":{},"用":{"docs":{},"户":{"docs":{},"价":{"docs":{},"值":{"docs":{},"观":{"docs":{},"和":{"docs":{},"说":{"docs":{},"话":{"docs":{},"习":{"docs":{},"惯":{"docs":{},"等":{"docs":{},"（":{"docs":{},"主":{"docs":{},"要":{"docs":{},"借":{"docs":{},"鉴":{"docs":{},"l":{"docs":{},"m":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{},"项":{"docs":{},"目":{"docs":{},"尝":{"docs":{},"试":{"docs":{},"开":{"docs":{},"展":{"docs":{},"，":{"docs":{},"不":{"docs":{},"是":{"docs":{},"必":{"docs":{},"做":{"docs":{},"项":{"docs":{},"）":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"技":{"docs":{},"术":{"docs":{},"框":{"docs":{},"架":{"docs":{},"整":{"docs":{},"体":{"docs":{},"图":{"docs":{"技术框架/技术框架.html":{"ref":"技术框架/技术框架.html","tf":0.07142857142857142}}}}}}}}}},"length":1805},"corpusTokens":["\"../../../pre_model/chatglm/chatglm","\"./output/adgen","\"antioxidants\",","\"compound","\"correct_answer\":","\"distractor1\":","\"distractor2\":","\"distractor3\":","\"epoch\":","\"oxid","\"oxidants\",","\"oxygen\",","\"predict\":","\"pytorch_model.bin\"))","\"question\":","\"residues\",","\"summary\":","\"support\":","\"train_loss\":","\"train_runtime\":","\"train_samples\":","\"train_samples_per_second\":","\"train_steps_per_second\":","\"你是谁\"))","\"修身修身的unk>,这款unk>感感,加上加上性感的面料,展现气质,整体整体整体性感,展现彰显修饰修饰的unk>。加上加上气质,让简约设计,穿着穿着设计,搭配搭配。\"}","\"偏头痛\",","\"内科\"],","\"发病部位\":","\"头部及眼后部疼痛并能听到连续不断的隆隆声\",","\"宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。\"}","\"恶寒发热\"],","\"所属科室\":","\"晨起头痛加重\"],","\"相关疾病\":","\"相关症状\":","\"简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。\",","\"简约而不简单的牛仔外套，白色的衣身十分百搭。衣身多处有做旧破洞设计，打破单调乏味，增加一丝造型看点。衣身后背处有趣味刺绣装饰，丰富层次感，彰显别样时尚。\"}","\"类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞\",","\"类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤\",","\"问题：一位年轻男性长期使用可卡因，突然出现胸痛、呕吐、出汗等症状，经检查发现心电图反映心肌急性损伤，请问可能患的是什么疾病？治疗方式是什么？\"","#","#下载源代码","#下载脚本","#关启shell，创建虚拟环境","#初始化shell，以便直接运行conda","#安装依赖","#显示环境列表","#测试pytorch","#激活","#网址：https://conda.io/en/latest/miniconda.html","$","$lr","$pre_seq_len","$step","&","',","'./lora","'./trans_chinese_alpaca_data.json'","'decapoda","'epoch':","'int4weightextractionfloat'","'learning_rate':","'llama","'tloen/alpaca","'train_loss':","'train_samples_per_second':","'train_steps_per_second':","'多少钱呢',","'大概金额多少？',","'律师费诉讼费都非常少都很合理，一定要起诉。',","'您好，建议尽量协商处理，协商不成可起诉']","'需要看标的额和案情复杂程度，建议细致面谈']","(allenai.org)","(baidu.com)","(c6h12),","(codalab.org)","(generate.py)","(glm)","(https://github.com/k","(huggingface.co)","(or","(rajpurkar.github.io)","(te)","(tiangong.world)【开源chatpdf套壳】","*","*****","*******************************************************","***.sh","+",".","../../../pre_model/chatglm/chatglm","./output/$checkpoint","./output/$checkpoint/checkpoint","./output/adgen","./scripts/finetune.sh","/","/data/pre_model/chatglm","/data/train_data/chatglm","0.0,","0.42","0.42,","0.42}","003调优（即alpaca）和不调优（即llama）的性能更高；7b","05,","0:40:02.13","1","1,840","1.","1.249","1.249,","1.3b的奖励模型，以对不同的回复进行评分：对一个提示和k个回复，gpt","1.3gb","1.今天的解释系统擅长为答案提供一两句话的支持证据（“基本原理”）（dey","1.在开放域文本问答的背景下，的目标是通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。","10","10.3.0","100","1000","105145,","114599","114599,","12","128～127","12b生成。","12h","130001,","130004]","1343","1585","16","1840个随机选择的问题（arc中的7787个问题）总共包括5881个离散蕴涵步骤。总的来说，大约600（带薪）工作小时用于构建数据集。平均而言，每个蕴涵树包括跨越3.2个蕴涵步骤的7.6个节点，其中每个蕴涵步骤通常涉及3个事实（两片叶子，组合起来得出一个结论）。","19.982","19.982,","1e","1k","1t","1、windows+cpu方案的必备条件","1、windows+gpu方案的必备条件","1、下载官方代码，安装python依赖的库","1、执行部署脚本","1、模型文件","1、训练脚本train.sh如下：","2","2.","2.7","2.amazonaws.com/qasp","2.对特定法律知识的问答。","2.本文方法是以多步蕴涵树的形式生成解释，如图","2.的方法是以蕴涵树的形式生成解释，即多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设（即问题+答案）。","2/checkpoint","2/generated_predictions.txt。","2000","2048）计算中间变量内存。","211.3k","2402.1329,","24gb内存","24h","25","25.3gb","2e","2、下载int4量化后的预训练结果文件","2、开始训练,后台执行：","2、执行评测脚本，","2、查看部署脚本","2、运行部署cpu版本的int4量化的chatglm","2、运行部署gpu版本的int4量化的chatglm","2分钟，实在是太慢了，基本不适合使用。有机会还是搞gpu版本吧！","2秒即可获得结果","2）链上。在这里，推广到需要多步蕴涵树的任务。","3","3,","3.","3.30","3.30:","3.5和opt","3.为了用这种技能训练模型，创建了","3.因此本文的一个重要贡献是构建了这样一个数据集，称为","3000","3000\"","3000，训练40分钟完成","32","32,","32gb","35%","3、查看评测脚本","3、训练结束，查看结果，max_step","3为例，以下是一些步骤，可以用chain","3模型：","3的对话生成模型，使用了openai","3直接调成chatgpt","4","4(7b)和","4)进行比较。","4,","4.","4.本文还在这个数据集上定义了三个解释任务，即：为给定的","4/gpt","4096,","40k","48","4、查看训练生成的模型文件及模型结果","4、查看评测结果：","4为每个回复提供一个1到10之间的评分。","4创建了对比数据；为了评估数据质量，研究人员训练一个基于opt","4和gpt","4对llama进行指令调优，往往比用text","4对两个模型之间的回复质量进行评分，评分范围从1到10，并将结果与其他强竞争模型(chatgpt","4对自己的回复提供从1到10的评分，并对gpt","4数据集。","4是在比中文更丰富的英文语料库中训练的，所以具有更强的英文instruct","4来评估不同聊天机器人模型对80个未见过的问题所生成回答的质量，从","4模型中收集回复，并从以前的研究中获得其他模型的答案，然后要求gpt","4模型来自动生成语言模型所需的微调指令数据。gpt","4生成的5.2万条英文instruct","4生成的instruct","4生成的使用instruct","4用中文回答这些指令，并以此建立一个基于llama的中文instruct","4的5.2万条中文instruct","4的案例","4的结果而言，翻译后的回复比中文生成的回复表现得更好，可能是因为gpt","4等大型商业聊天机器人相比，仍有差距。","4自动评估：受","4！微软开源微调指令集：效果不输原版，中英双语都能用","4）的方法，可以让模型根据特定任务提供指令来执行任务。在这个具体的情感分类案例中，我们将使用","4，可以注意到，llama","5","5,","5.","5.研究结果表明，强大的语言模型可以部分解决这些任务，特别是当相关句子包含在输入中时，并且有泛化到其他领域的迹象。这项工作意义重大，因为它提供了一种新型数据集（多步蕴涵）和基线，为社区提供了一条新途径，以产生更丰富、更系统的解释。","5.研究重点是生成推理线，以显示证据如何生成的答案，而不是决定将哪些部分显示给用户。这使能够将两个解释要求，即推导的正确性与效用分开，使能够以更客观的度量评估推导。","50","5049","50k","6","6,","6.5b","6.6","6.666666666666667e","61,","62","63823,","63832,","63912,","64","64051,","64131,","64257,","64290,","64555,","64622,","64703,","64880,","65107,","65173,","65209,","65347,","65388,","65421,","65509,","65594,","66069,","66261,","66268,","66561,","67061,","68554,","69418,","69768,","6b","6b\"","6b*1","6b*2","6b*4","6b*8","6b.git","6b.md","6b/ptune","6b/ptuning/output/adgen","6b:","6b依赖torch，如果你有gpu，且高于6g内存，那么建议部署gpu版本，","6b有3个版本可以使用，","6b模型","6b模型——windows+6gb显卡版本和cpu版本的本地部署","6b模型的训练，需要准备相应的数据集。使用adgen数据集，其任务为根据输入（content）生成一段广告词（summary）。下载adgen数据集，从","6b模型训练完整流程详解","6b的运行需要模型的配置文件，即config.json等。","6b部署比gpu版本稍微麻烦一点，主要涉及到一个kernel的编译问题。","6b需要安装cuda版本的torch，","6b，adamw","6b，然后通过p","6gb","6gb+6gb+12gb+1.3gb","7","7.088,","7.1214,","70936,","70984,","71319,","71689,","72194,","72265,","73412,","73416,","73942,","74197,","75898,","77257,","78598,","7b","7b'","7b模型，由哈尔滨工业大学社会计算与信息检索研究中心健康智能组完成。项目组通过","8","8.5971","8.597134847005208,","80gb显卡上进行了训练，训练总轮次10轮，耗时大约2h17m。batch_size=128的情况下显存占用了40g左右。也可以使用3090/4090显卡，显存在24gb以上时，可以获得较好的效果。","81549,","83343,","85428,","87019,","87834,","8）进行微调，选择开发分数最高的检查点。",":","=","=11008,","=automodel.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm","=autotokenizer.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm",">","[","[\"中西医结合科\",","[\"头部\"]}","[\"妊娠合并偏头痛\",","[\"皮肤变硬\",","['您好，建议协商处理，如果对方告了你们，就只能积极应诉了。',","['欠款金额是多少","[(hidden_size+intermediate_size)context_length\\num_hidden_layers]/1024","[3,","[5,","\\","]","a100（80gb","acceler","accept","activ","adamw","adapt","adaptation,","adgen","advertisegen","advertisegen/dev.json","advertisegen/train.json","agents)","ai","all.jsonl.gz]","all_results.json","alpaca","alpaca。这个生成","alpaca和llama，但和gpt","alpaca：一个包含20k个代码生成任务的数据集。","analysis：确定了6种常见的高级推理类别：替代类型是指需要模型来执行分类、子项或其他形式的链接的蕴涵，这些链接将一个输入句子中的一个实体替换为另一个实体。从规则蕴涵中进行推理需要将指定为一个输入句子的特定规则应用于另一个输入句子。分析表明，大约三分之一（33%）的所有蕴涵需要应用特定领域的规则才能完成。进一步的规范或连接蕴涵需要一个模型将两个输入事实的细节合并到单个输出事实中。不太常见的类型需要从对象的属性推断对象的类、继承对象的属性或确定顺序推理的顺序。总的来说，该分析表明，要成功完成蕴涵库中的蕴涵步骤，需要多种形式的推理。","anoth","answer","answers:","api","api/","api提供。","api提供的数据集和模型来训练。根据openai","api生成的问题和freebase实体作为答案。webquest","api的token的最大是4096","api的文档，chatgpt使用的训练数据集有：","appli","ask","attribut","attributeerror:'nonetype'object","autoconfig","autoconfig.from_pretrained(model_name,","automodel,","automodel.from_pretrained(model_name,","autotokenizer,","autotokenizer.from_pretrained(\"d:\\\\data\\\\llm\\\\chatglm","autotokenizer.from_pretrained(model_name,","back","bank","bank。","bank，第一个用于","base","base_model","bash","batch_size，设置模型精度，选择微调方法和参数分布方法等。","batch数","benchmark","bert出现之后，fin","bit","bits,","bitsandbyt","bitsandbytes量化方法","blended_skill_talk：一个包含7k个对话的数据集，设计为展示多种对话模式，如展示个性、表达同理心和展示知识。","byte","byte.","bytes.","c","c:\\users\\dufei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm","cach","call","calledoxid","calledreduct","capabl","cat","caus","cc_sbu_align：一个包含4k个对话的数据集，基于minigpt","cd","chain","challenge/cail2019","chatalpaca：一个包含10k个对话的数据集，由chatgpt生成。","chatglm","chatglm)","chatgpt","chatgpt。供开发人员使用很多公司、机构的基础模型快速构建定制化模型。","chatgpt是一个基于gpt","chat【领域微调是重点】","checkpoint","checkpoint=adgen","checkpoint_path","checkpointing.html","checkpoint有监督微调后训练得到了两个模型：llama","china","chines","clone","cloud","cn是在gpt","code","compil","compound","compound.","compounds.","comprehens","conda","conda环境","config","config.json","config.pre_seq_len","config=config,","configuration_chatglm.pi","content","context_length","continu","convers","cpu","cpu,","cpu.","cpu版本的chatglm","cpu，从而允许更多内容适应","creat","cuda","cuda_visible_devices=0","cuda内核1.3","custom","cyclohexan","data","data_path","dataset","dataset.s3.u","datasets.s3.amazonaws.com/sciq/sciq.zip","dataset（squad）是一个阅读理解数据集，由众包工作者在一组维基百科条目上提出的问题组成，其中每个问题的答案是相应阅读段落中的一段文本或跨度，或者问题可能无法回答。【英文】【维基百科】","dataset：一个包含52k个指令的数据集，由openai","dataset：一个包含75k个对话的数据集，基于sharegpt对话。","dataset：用户首先填充“解释性工作表”，用少量特定类别（例如，“核心事实”、“基础事实”）标记他们预期将包含在树中的事实。然后，用户从该工作表开始构建蕴涵树","dataset：科学问答数据集","data）：要求gpt","data：使用chatgpt将5.2万条指令翻译成中文，并要求gpt","davinci","ddp","decompasition：混合精度反编译","deepspe","deploy.pi","dev","dev.json","do_predict","do_train","dolly：一个包含15k个对话的数据集，由databricks员工生成，用于训练大型语言模型。","don't","donat","down","drive","dureader：一个大规模的中文阅读理解数据集，包含三个子任务：机器阅读理解、搜索式问答和多文档阅读理解。数据来源于百度搜索引擎和百度知道。【百度】【中文】machin","effici","electrons,","embeddings（嵌入）","embeddings（嵌入）无需训练模型，是将自己的预设pormpt+数据+问题打包，当作一整段话发送给gpt。让gpt根据这个预设的prompt和灌给的数据再加问题做回答。适合数据量超大且实时更新的一些数据。","embedding作用","entail","entailmentbank","entailmentwrit","entailmentwriters。使用","env","epoch","epoch，微调阶段耗时约","equat","evalu","evaluate.sh","evaluate.sh。","evaluation）：从平均roug","evol：一个包含70k个对话的数据集，是wizardlm的训练数据。","explain","explan","explor","explorer/dataset/dev","explorer/dataset/train","f2,","face","fairscal","finance：一个包含69k个金融相关指令的数据集。","fine","finetune.pi","follow","following数据上训练的。","following数据上训练的；llama","following数据表现出更强大的对齐性能。","following模型，并研究指令调优的跨语言泛化能力。","following能力。","fopenmp","found.","fp16","fp16=true","fp32","fp32。","fp32，llama","fpic","framework","fsdp","fsdp+cpu","fsdpwarp","fsdp，只需要将","fsdp：","fulli","function","g","gb","gcc","gcc/","gcc编译环境配置+kernel编译","gcc，下载地址：https://jmeubank.github.io/tdm","gener","generate.pi","generated_predictions.txt","generation_config.json","generation”（2021）中提出。前缀调整涉及学习特定任务的连续提示，在推理过程中将其添加到输入之前。通过优化这个连续提示，模型可以适应特定任务而不修改底层模型参数，这节省了计算资源并实现了高效的精调。","gentl","git","github","github.com/lc1332/chines","github.com/tloen/alpaca","github链接：https://github.com/pengxiao","github链接：https://github.com/scir","glm","googl","gpt","gpt3.5","gpt3.5接口围绕医学知识库构建问答数据，设置了多种prompt形式来充分利用知识。医学知识库围绕疾病、药物、检查指标等构建，字段包括并发症，高危因素，组织学检查，临床症状，药物治疗，辅助治疗等。知识库示例如下：","gpt4","gpt4和gpt4在ground","gpt4是在gpt","gpt4的性能超过了13b","gpt与知识图谱","gpt（生成式预训练变压器）模型。gpt模型在大量文本上进行了预训练，然后在各种任务上进行了微调，例如语言建模，问答和摘要。经过微调的模型在这些任务上取得了最先进的性能。","gpu","gpu。","gpu。lamini","gpu版本的模型部署很简单，上述两个步骤完成之后即可运行。代码如下：","gpu，并且生成的数据是商业可用的。用户可以自定义最初的","gradient","gradient_accumulation_step","gsm","guid","hc3：一个包含37k个指令的数据集，由chatgpt和人类生成，涉及中英文。","head","hf","hf'","hf/tree/main","hh","hi/huatuo","histori","history=[])","homepag","http://www.","https://arxiv.org/pdf/2106.09685.pdf","https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1","https://github.com/huggingface/peft/blob/main/examples/conditional_generation/peft_lora_seq2seq.ipynb","https://github.com/huggingface/peft/blob/main/examples/int8_training/finetune_opt_bnb_peft.ipynb","https://github.com/imclumsypanda/langchain","https://github.com/thudm/chatglm","https://github.com/tloen/alpaca","https://huggingface.co/blog/zero","https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer#transformers.trainin","https://huggingface.co/docs/transformers/v4.27.2/en/perf_train_gpu_one#gradi","https://huggingface.co/thudm/chatglm","https://pytorch.org/blog/introduc","https://pytorch.org/docs/stable/fsdp.html","https://qywu.github.io/2019/05/22/explor","https://repo.anaconda.com/miniconda/miniconda3","https://www.chatpdf.com","hub","hug","huggingfac","huggingface.co/decapoda","h：假设；q：问题；a：回答；c","ice_text.model","ic：一个包含8k个对话的数据集，涉及到小学数学问题和无关上下文。","imdb","iml这三个模型的回复进行评分，以训练奖励模型。","import","importautotokenizer,automodel","infer","init","input","input_id","instal","instruct","instructiontranslation：一个包含80k个多语言指令翻译任务的数据集，由m2m","instruction：通过提供具体的法律知识文本，先让chatgpt生成与该段法律知识内容与逻辑关系相关的若干问题，再通过“文本段","instruct的可靠性和安全性漏洞，使用了基于特定知识的reli","instruct自动生成微调数据","instruct：一个包含82k个指令输入输出实例的数据集。","int4","int4\",","int4\",trust_remote_code=true,","int4/tree/main","int4\\\\quantization_kernels.so\")","int4\\\\quantization_kernels.so\")一行手动加载的内容。","int4\\quantization_kernels_parallel.c","int4\\quantization_kernels_parallel.so","int4本地目录下进入cmd，运行如下两个编译命令：","int4目录下看到下面两个新的文件：","int4量化的预训练文件下载地址：https://huggingface.co/thudm/chatglm","int8","int8，llama","interact","intermediate_s","introduct","jieba","k,","kernel","kernel,","kernel_file=\"d:\\\\data\\\\llm\\\\chatglm","label","label_id","lamini","langchain:","languag","language”（2021）中提出。p","latest","law","lawgpt","layer","learning_r","learns,","lf","lfs，然后运行","linux","list","llama","llama、chatglm","llm","llm三种微调技术对比","llm三种训练技术对比","llm引擎学习","llm模型：","llm，以生成不同但相似的指令","llm，后续他们将发布执行此操作的功能和代码。","load","load_8bit","logging_step","lora","lora(羊驼模型):","lora)方法。","lora.git","lora/blob/main/data/trans_chinese_alpaca_data.json","lora:大型语言模型的低秩适配器;简单来说就是微调模型的另一种方式，来调试模型在具体场景下的准确度；假设模型适应过程中的权重变化也","lora_weight","lora（开源的中文数据集）","lora）","lora，链接开头已经给出，下载后放到项目根目录下。","lr","lr=2e","ls","l得分来看，alpaca优于llama","main","main.pi","master","matrix","max_source_length","max_step","max_target_length","mb","mechan","med","memori","merg","metal","metgen:","metgen论文学习笔记","metric","metrics：......","miniconda3","minlik/chines","mix","ml","model","model.chat(tokenizer,\"你好\",","model.eval()","model.half()","model.half().cuda()","model.quantize(bits=4,","model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)","model_nam","model_name_or_path","modeling_chatglm.pi","modul","mt0：","multipl","n","name","new_prefix_state_dict","new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]]","nlp","nltk","nohup","nohup.out","nq","num_hidden_lay","o","o3","oasst1：一个包含89k个多语言助理风格对话的数据集，由人类生成和标注。","occupied:","offload","offload【分布式】","once”序列到序列模型的启发，作者训练了三个基于","openai","openai的文本嵌入测量文本字符串的相关性。嵌入通常用于：","opt","optim","optimalscale/lmflow","optimizer.pt","org/books.\"","os","oung","output_dir","overwrite_cach","overwrite_output_dir","oxid","oxidized.","p","parallel","paralle（fsdp）和","paramet","pdf","peft","peft综述：scal","peft，使用","pengxiao","per_device_eval_batch_s","per_device_train_batch_s","pip","pipelin","pipeline，其灵感来自斯坦福的开源模型","plu","power","pre_seq_len","pre_seq_len=8","precis","predict_with_gener","prefix","prefix_state_dict","prefix_state_dict.items():","print(model.chat(tokenizer,","print(response)","print(torch.cuda.is_available())","print_gpu","process","prompt","prompt_column","prompt。","prompt）而非修改模型参数。这意味着预训练模型保持不变，只有输入提示被修改以适应下游的任务。通过设计和优化一组提示，可以使预训练模型执行特定任务。","prompt，以便于用户根据模型设置不同格式的","proofwrit","propag","pt","pthread","ptuning_checkpoint","public","py310_23.1.0","py39_4.12.0","python","python3","python=3.9","python环境","pytorch","pytorch_model.bin","qa","qa对","quantiz","quantization.pi","quantization_bit","quantization_kernels.c","quantization_kernels.so","quantization_kernels_parallel.c","quantization_kernels_parallel.so","quantization_kernels_parallel.so和quantization_kernels.so。说明编译成功，后面我们手动载入即可。","quantization：矢量量化","question","question:昨天把人家车刮了,要赔多少","question:朋友欠钱不还咋办","r","ram","ram）大概可以在","ram，大概","ram，进而通过估算设置","rank","read","reduc","reduced.","reduct","relationship","release下载安装即可，注意安装的时候直接选择全部安装就好。","requirements.txt","research/llama","response,","response_column","revision=\"\")","revision=\"\").float()","revision=\"\").half().cuda()","rlhf。","rlhf。lamini","rlhf：一个包含91k个对话的数据集，用于从人类反馈中进行强化学习。","rng_state.pth","roberta","rouge_chines","save_step","saylor","saylor.","scale","scalehttps://arxiv.org/abs/2208.07339*","scheduler.pt","scir","self","sh","shard","share","shot中表现更好！","shrinking)，它由kaplan等人于2020年引入。这种技术涉及在fin","simplified/nq","simplified/simplifi","sodium","soft","song/lawgpt","song/lawgpt/","sourc","special_tokens_map.json","std=c99","step","step=3000","step”","studio","such","suggest","summar","summari","sxm","sxm2","t5","t511b","t5）。","tail","tesla","test_fil","tgold","think","thought","thought介绍","thought方法训练一个更先进的gpt","thought是一种通过分解训练过程为较小的相互关联的任务来训练模型的方法。这种方法的目的是使模型能够理解和维护文本中的思维链，从而生成连贯的、上下文相关的响应。与其他方法不同，chain","thought的重点在于将训练过程分解为一系列逐步更复杂的任务，并使用注意机制来帮助模型集中于相关的部分。","thought训练中，将数据集中的输入分解为一系列任务是非常关键的一步。一般来说，这个过程需要根据特定的任务和数据集来进行定制。以下是一些通用的方法：","thought通常用于提高模型的生成能力和上下文理解能力。","thought都是用于训练大型语言模型的方法，它们都有助于提高模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。","thought，cot)，指的是一系列有逻辑关系的思考步骤，形成一个完整的思考过程。","thought：chain","thudm/chatglm","tiangong","todo——构建数据集：构建retrieval数据集；匹配模型优化——对比学习预训练、度量学习；大模型prompt【用户查询】","token","tokenization_chatglm.pi","tokenizer_config.json","torch","torch.cuda.is_available()","torch.load(os.path.join(checkpoint_path,","torch.ones((1，1)).to(\"cuda\")","torch实现：torch","train","train.json","train.jsonl.gz]、开发集[https://storage.cloud.google.com/natural_questions/v1.0","train.sh","train_fil","train_loss","train_results.json","train_runtim","train_sampl","train_samples_per_second","train_steps_per_second","trainer_state.json","training)，它由houlsby等人于2019年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。","training_args.bin","trainingargu","transform","transformers,","transformers：在","tree","trees论文学习笔记","triviaqa：一个问答数据集，包含65万多个问题和答案，基于维基百科和网络搜索结果。每个问题都是一个有趣的事实，每个答案都是一个实体或数字。http://nlp.cs.washington.edu/triviaqa/","trust_remote_code=true)","trust_remote_code=true,","truth回复长度增加时逐渐表现得更好，最终在长度超过4时表现出更高的性能，意味着当场景更具创造性时，可以更好地遵循指令。","tsinghua","tune","tune、paramet","tune和prompt","tuning)","tuning:","tuning、instruct","tuning。","tuning。在训练过程中，模型将学习如何根据输入文本预测相应的情感标签。","tuning。如果两者不相似，则可能需要更多的fin","tuning介绍：更为详细流程化","tuning修改模型的权重，而prompt","tuning只修改模型的输入。因此，prompt","tuning和chain","tuning和instruct","tuning和prompt","tuning和传统的fin","tuning微调gpt","tuning技术","tuning技术[peft]","tuning技术也随之流行，即将预训练模型的权重冻结，然后根据具体任务进行微调变得十分有效且被应用在很多场景。随着chatgpt的火热，paramet","tuning技术似乎也有替代传统fin","tuning技术包括：","tuning技术而非手工调整可能是未来很重要的方向。毕竟在文本摘要、代码debug等需要大量的输入来让模型认识问题的场景，如何有效的将过长的输入prompt给模型是一个很重要的问题，现在的大模型在长输入方面推理成本很高且有很大限制，因此这种技术也是未来很重要的一个方向！","tuning方法包括将预训练模型与少量特定任务数据一起继续训练。在这个过程中，预训练模型的权重被更新，以更好地适应任务。所需的fin","tuning方法更少。","tuning是一种使用自然语言提示（prompt）的方法，以指导模型生成特定的输出。这种方法的目的是通过对模型进行定向训练，使其在特定任务上表现出更好的性能。与其他方法不同，prompt","tuning是一种更近期的精调预训练语言模型的方法，重点是调整输入提示（input","tuning是一种通过为模型提供任务相关的指令来指导模型学习的方法。这种方法的目的是使模型更好地理解任务的要求，并提高其生成能力和上下文理解能力。instruct","tuning最著名的例子之一是由openai开发的openai","tuning期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。","tuning比精调更灵活，因为它允许创建特定任务的提示，可以适应各种任务。","tuning涉及训练可学习的称为“提示记号”的参数，这些参数与输入序列连接。这些提示记号是特定于任务的，在精调过程中进行优化，使得模型可以在保持原始模型参数不变的情况下在新任务上表现良好。","tuning的一种想法！","tuning的主要区别在于预训练模型被修改的程度。fin","tuning的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。","tuning的趋势，本篇论文将简单描述预训练模型领域这三种微调技术及其差别。","tuning的重点在于设计良好的提示，这些提示可以引导模型生成准确、上下文相关的响应。","tuning调整比精调的计算成本低，需要的资源和训练时间也更少。此外，prompt","tuning通常用于特定任务的优化，而chain","tuning通常需要较少的训练数据，并且可以提高模型的泛化性能。","tuning量取决于预训练语料库和任务特定语料库之间的相似性。如果两者相似，可能只需要少量的fin","tuning（前缀调整）：由li和liang在论文“prefix","tuning（微调）","tuning（微调）目前仅适用于以下基本型号：davinci、curie、babbage和ada，是预训练模型，一次训练终身受益，适合很久知识都不变且数据集较小的情况；你的训练示例越多越好。我们建议至少有几百个例子。一般来说，我们发现数据集大小的每一次翻倍都会导致模型质量的线性增加","tuning，gpt","tuning，简称peft，旨在在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。它是自然语言处理（nlp）中一组用于将预训练语言模型适应特定任务的方法，其所需参数和计算资源比传统的fin","tuning：instruct","tuning：prompt","tuning：加上“prompt”，变成填空题","tuning：由liu等人在论文“p","turk对模型生成结果进行人工评估。","t，近似为黄金蕴涵树","understands,","up:","url:","us","utilization()","v","v0.3.tgz","v100","v2","v2.0.json]","v2.0.json]；开发集[https://rajpurkar.github.io/squad","validation_fil","vicuna","v”测试是否成功即可。","webgpt：一个包含20k个对话的数据集，由webgpt项目生成。","webquestions：一个开放领域问答数据集，包含5,810个问题和答案，基于googl","west","wget","what?\",","windows+6gb显+cpu本地部署chatglm","windows+cpu部署方案","windows+gpu部署方案","wise","worldtre","x86_64.sh","yanqiangmiffy/chines","yum","yyf/cmekg_tools)，并利用","zero","zero零冗余优化器","zh","zh'","{","{\"content\":","{\"labels\":","{\"中心词\":","{'loss':","{'train_runtime':","{}","}","~/miniconda3/bin/conda","·","​","“|||”）分隔。如下所示：","•","①选取某一领域","②继续训练部分：无监督学习","③关键：指令微调部分：构建高质量的领域问答数据集。","④对齐微调：符合用户价值观和说话习惯等（主要借鉴lmflow项目尝试开展，不是必做项）","●","。","《精准学习》中提出，缓慢地、理智地、符号化地运作，是人脑的特权。它可以在任何可能的时候，提取具有普遍性、逻辑性的、明确的原则。","一、fine","一、hotpotqa：hotpotqa","一、memori","一、prompt","一、windows+gpu6g","一、天工chat：tiangong","一、摘要","一、本草医学gpt模型：基于中文医学知识的llama微调模型","一下；同样，cpu_offload","一些值得注意的prompt","一样，在每个","七、sciq","七、torch","七、实验","万条符合要求的指令，最终得到一个大型指令遵循数据集。","三、chain","三、fp16","三、natualquestions：https://ai.google.com/research/naturalquestions/visu","三、prompt","三、self","三、贡献","三个task：","上保留完整副本。","上平均划分参数、梯度和优化器状态，并为每个","上述文件全部下载之后保存到本地的一个目录下即可，我们保存在：d:\\\\chatglm","上，而非像","下就有模型生成了","下载int4量化后的预训练结果文件","下载llama基础模型：下载完成后放到根目录下/llama","下载miniconda，选择匹配的操作系统的版本，","下载代码&安装依赖","下载处理好的","下载模型需要先安装git","下载羊驼代码","不同点：","与prompt不同，instruction通常是一种更详细的文本，用于指导模型执行特定操作或完成任务。instruction可以是计算机程序或脚本，也可以是人类编写的指导性文本。instruction的目的是告诉模型如何处理数据或执行某个操作，而不是简单地提供上下文或任务相关信息。","与输出相关的tokens组成的上下文信息即可理解为是一个prompt。prompt通常是一种短文本字符串，用于指导语言模型生成响应。prompt提供上下文和任务相关信息，以帮助模型更好地理解要求，并生成正确的输出。","个qa问题","个专家标记、61.2k","个人工生成的","个句子（使用","个数据点生成","个未标记和","个样本变成超过","个样本，而不需要启动任何","个用于伴随","个答案选项","个节点和","个蕴涵步骤，包含","中使用","中使用这个数据类型，bitsandbyt","中使用：","中文instruct","中文langchain项目","中文法律知识模型","中检索","中的","中，将参数动态地从","为了在训练和","为这项任务定义和训练称为","主要特点：从提问中抽取出关键信息，然后进行知识库匹配。","主要的实现原理：将文章进行分割，然后与query进行查询匹配，将相关段落返回，输入到gpt中得到最后的答案。","之前解释qa的相关方法与技术：","之间的数据存储零重叠。在运行时，每个","九、chatgpt使用的训练数据集——来自b","也会占据一些","也只需要一行代码：","也提供了一个","二、","二、instruct","二、lawgpt","二、paramet","二、squad2数据集：斯坦福问答数据集","二、windows+cpu","二、估算模型所需的ram：参数个数","二、天工gpt：天宫","二、综述","二、解释","云端部署","五、gpt","五、lora：low","五、pubmedqa：医学问答数据集","五、数据集","产品定位：","亿参数。","亿参数的","仅对优化器状态和梯度执行分区（分片）。模型参数分片应该很快就会在deepspeed和fairscale中推出。","仅就gpt","从","从官网ttps://docs.conda.io/en/latest/miniconda.html下载。","以gpt","以instructgpt为例，其基本流程如下：","优化器参数：不同的优化器所储存的参数量不同。对于常用的","但实际上chatglm","但是需要下载支持cuda的torch，而不是默认的cpu版本的torch。","但是，除了这些cpu版本的安装还需要在本地的windows下安装好c/c++的编译环境。推荐安装tdm","作为查询从","作用","使有了思维链，大语言模型还是没有真正理解数学逻辑，不知道加减乘除的真实意义，只是通过更精细的叠加来“照葫芦画瓢”，所以，对于有精确要求的任务，还要进一步探索新的技术。","使用","使用gpt","使用kaggle部署模型，访问web交互","使用了两个方法最大程度地降低了其带来的误差：","使用了和","使用你的微调模型","使用准备好的数据集和拼接格式，对","使用展示","使用微调后的模型进行情感分类：","使用最先进的生成模型基线结果表明可以生成合理树，特别是当提供必要的原始事实作为模型输入时（导致","例如，为了训练模型理解上下文，可以定义一个损失函数，它评估模型生成的响应与上下文的相关性。","例如，可以将训练过程分解为理解语法和词汇、生成单词和短语、生成连贯的句子和段落、理解上下文等子任务。","例如，在自然语言生成任务中，可以将其分解为理解输入的语义、确定输出的语法结构、生成文本等子任务。","例如，在自然语言生成任务中，输入可能是一组与上下文相关的单词，输出可能是下一个单词或整个句子。","例如，如果目标任务是自然语言生成，那么数据集中的输入可能是一句话或一个段落，模型需要将其转化为自然语言响应。","例如：对于问答任务，instruction可以提供具体的指令，例如“请回答下列问题：谁是美国第一位总统？”，并将文本段落作为输入提供给模型。","例子：借助","借助","允许模型在多个步骤中生成连贯的回答，从而更好地解决问题或完成任务。通过思维链式方法训练大型语言模型需要将训练过程分解成较小、相互关联的任务，以帮助模型理解和生成连贯、上下文感知的响应。","全面的中文开源数据集合","八、其他公开领域的数据集链接：","六、gradient","六、qasper：卡斯珀","六、模型构建","其中","其中一种peft技术称为蒸馏(distillation)，它由hinton等人于2015年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。【教师","其他具体参数可以git链接","其次，考虑模型需要的","具有较低的“内在秩”，从而提出了低秩适应(low","内存。","再根据llama的架构（hidden_s","准备和上传培训数据","准备数据集","准备数据集：","分为两类：针对单篇事实性问题进行总结的问答数据集（bing等chatpdf工具进行文档提问）","分别是","分类（其中文本字符串按其最相似的标签进行分类）","则允许在一个","创建新环境","包含","包装一下即可，详见：","区别：prompt和instruction都是用于指导模型生成输出的文本，但它们的目的和使用方式是不同的。prompt更多地用于帮助模型理解任务和上下文，而instruction则更多地用于指导模型执行具体操作或完成任务。","医学知识图谱","千言（luge）|","即在上面下载的d:\\\\data\\\\llm\\\\chatglm","卸载（cpu）。此功能将一些处理和内存需求卸载到主机的","原理：fulli","原理：思维链(chain","参数高效的fine","参考论文：llm.int8():","参考链接：","参考链接：gpt进阶（二）:训练部署自己的chatgpt模型(羊驼","参考链接：【实战讲解】chatglm","参考链接：大模型微调技术：fine","参考链接：大语言模型三种训练技术及区别：prompt","参考链接：手把手教你本地部署清华大学keg的chatglm","参考链接：有哪些省内存的大语言模型训练/微调/推理方法？","发送它所缺少的信息来动态构建每一层的数据。","受","另一种技术称为适配器训练(adapt","另外，chatglm","只要我们把希望输出的部分删除掉，然后尽量构造与该输出有关的其它tokens即可。这就是prompt","可能患的是心肌梗塞，需要进行维拉帕米、依普利酮、硝酸甘油、ß阻滞剂、吗啡等药物治疗，并进行溶栓治疗、低分子量肝素、钙通道阻滞剂等辅助治疗。此外需要及时停用可卡因等药物，以防止病情加重。\"","名称，","和","和人工标记团队来运行","响应对。","四、int8","四、中文法律问答数据集：cail2019","四、对比总结","四、思维链——“let’","四、综述","回答:","因此建议全部从huggingface上下载所有文件到本地。","在","在chain","在github上下载requirements.txt即可。下载地址：https://github.com/thudm/chatglm","在nlp中，fine","在安装之前，除了上面需要安装好requirements.txt中所有的python依赖外，torch需要安装好正常的cpu版本即可。","在实际应用中，当你需要对给定的文本进行情感分类时，可以这样使用微调后的","在微调后，使用测试数据集（不包含在训练数据集中的数据）对模型进行测试。输入文本并观察模型生成的情感标签，然后与实际标签进行比较，计算准确率、召回率等性能指标。","在数据集上微调基础模型。","在段落上显示一个注意力地图","在经过微调的模型上运行","在这个可以查看","在部署时，可以考虑到模型的可用性、可扩展性和性能等因素。","地址：www.kaggle.com/model","垂直领域gpt微调模型介绍","多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设【转去看了看多前提蕴涵树的相关论文】","多条指令，以便生成的","多样性测量（分析相似性分布）","大模型“涌现”的思维链，究竟是一种什么能力？","大模型，可以通过prompt，来执行相应信息提取以及思维链的推理任务，形式化成不同形式的知识【例如三元组，多元组或者事件链条】。","大致分三个部分：","大致思路：在前向反馈","天工chat上新了","天工gpt调研","太大而无法直接输入到","奖励模型：研究人员使用gpt","如果以上代码输出的是true，那么恭喜你，你安装的是cuda版本的torch","如果你想要从本地加载模型，可以将","如果你运行上面的代码出现如下错误","如果在运行中遇到了如下错误提示：","学习从知识到预测答案的推理链—>帮助构建可解释的qa问答系统。【方法】用由多个隐含步骤组成的隐含树来解释答案。【现状】目前的工作建议使用端到端生成模型来生成蕴涵树，但生成的树中的步骤不受约束，而且可能不可靠。【方法/创新】本文提出了一个基于模块的蕴涵树生成枚举框架metgen，它具有“多个模块和一个推理控制器”。给定一个问题和一些支持知识，metgen可以通过对单独的模块进行单步隐含，用控制器选择推理流，迭代生成隐含树。由于每个模块都被引导去执行一种特定类型的隐含推理，因此由metgen生成的步骤更加可靠和有效。【结果】在标准基准测试上的实验结果表明，metgen仅使用9%的参数就可以优于以前的最先进的模型。","学习相关项目代码","学术问答数据集调研","学生】","它由卡内基梅隆大学、斯坦福大学和蒙特利尔大学的","安装依赖","安装依赖：","安装前说明","安装完在cmd中运行”gcc","完整的语料库。","官方两种解决方案：embeddings（嵌入）；fin","实例。","实测体验：速度较慢，生成效果如下，可以看到主要包括文本信息+相关扩展链接。","实现","对","对于","对于chatglm","对于需要推理的问题，本文的重点，有时将解释视为导致答案的步骤链（通常是句子）。因为众包这样的链很困难，现有的数据集通常会简化任务，例如，收集支持答案的句子而不是它们如何组合，和/或主要集中在单跳（长度为","对比数据（comparison","对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c)","对的多步蕴涵树，使用专家注释器构建，是同类数据集中的首个。","将","将微调封装成一种服务，使开发人员可以轻松将","将文本和情感标签转换为适用于","将模型转换为fp16。","将解释表述为多步骤、多前提的文本蕴涵。","局限：","左右","左右。","已经能生成相当符合人类偏好的回答。","帮助性（helpfulness）：是否能帮助人类实现他们的目标，一个能够准确回答问题的模型是有帮助的。","年）。这些方法主要设计用于“查找”问题的答案，以解释在语料库中何处/如何找到答案。","年），或用于定位答案的句法模式（ye","年；hancock","库中的几行代码，用户就能训练自己的大型语言模型（llm）及其权重，而无需使用任何","库中的默认超参数（包括优化器）对训练集上的模型进行微调。我们使用最大的","库来定义和调用","库版本必须是4.27.1及以上的版本才可以","库的","库让用户不再需要大型","库还提供了优化之后的正确","建议（其中建议包含相关文本字符串的项目）","异常检测（其中识别出相关性很小的离群值）","引擎，用户可以仅用几行代码就快速从","张","当模型训练和评估完成后，可以将它部署到适当的平台上。","微调","微调作用","微调成","微调数据链接：https://github.com/instruct","微调步骤","微调范式对比","思维链必须在模型规模足够大时才能涌现。","思维链提示会在给出答案之前，还会自动给出推理步骤","思维链暴露了它，依然是鹦鹉学舌，而非真的产生了意识。","思维链简介","总之，这些方法都有助于提高大型语言模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。prompt","总结","总结：将除了输出层以外的所有权重“冻结”（freeze）。然后随机初始化输出层参数，再以迁移学习的方式训练。仅仅更新全连接输出层，其它层的权重不变。","总结：就是把一个多步骤推理问题，分解成很多个中间步骤，分配给更多的计算量，生成更多的token，再把这些答案拼接在一起进行求解。【因式分解】","总结：当大模型开始涉及更加复杂和现实的问题时候，如果可以出现自动prompt","总结：通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。","成为一项比以前的","或","或其他模型进行","或者","所以lora","所以一张","所示，由单个多前提文本蕴涵","执行","技术框架整体图","把","指令微调数据集：qa数据集","指令微调的动机是提高语言模型对自然语言处理指令的响应能力。","推理直接使用","提供一个分区（也称为分片）。这导致","提供了一个托管数据生成器，只需几行代码即可将","提供了一种托管化的数据生成器，只需执行","提供快速调优功能，只需一行代码即可在","搜索（其中结果按与查询字符串的相关性进行排名）","支持使用自己的数据集进行微调，只需要按照./data/llama_data.json的格式构建自己的数据集，然后执行命令：","支持的模型：","改为你本地的模型路径。","改成你训练时的实际值，具体部署验证演示代码如下：","效果评估：人类评估3h标准。基于hhh对齐标准，研究人员使用众包平台amazon","数据描述：hotpotqa","数据描述：nq语料库包含来自真实用户的问题，它要求qa系统阅读和理解整个维基百科文章，其中可能包含也可能不包含问题的答案。包含真实的用户问题，以及解决方案应阅读整个页面以找到答案的要求，使","数据描述：pubmedqa的任务是使用相应的摘要回答是/否/也许的研究问题（例如：术前他汀类药物是否会减少冠状动脉旁路移植术后的心房颤动？","数据描述：stanford","数据描述：一个包含","数据描述：包含13679个关于物理，化学和生物学等的众包科学考试问题。这些问题采用多项选择题格式，每个选项有","数据描述：数据集是来自“中国裁判文书网”公开的法律文书，主要涉及民事和刑事的一审判决书，总共约1万份数据，并按比例划分训练、开发和测试。每份数据包括若干个问题，对于训练集，每个问题只包含一个标准回答，对于开发和测试集，每个问题包含3个标准回答。回答内容可以是案情片段，可以是yes或no，也可以拒答即回答内容为空。数据格式参考squad2.0的数据格式，整体为json格式的数据。并增设案由\"casename\"字段和领域\"domain\"字段，\"domain\"字段只有\"civil\"和\"criminal\"两种类型。\"context\"抽取自裁判文书的案情描述或原告诉称部分。【裁判文书网】【中文】","数据格式","数据格式：","数据点，而无需启动任何","数据生成器","数据规模：","数据规模：15万+","数据规模：30m左右","数据规模：41gb","数据规模：一个包含","数据规模：不大","数据规模：训练集535m，测试集46m，开发集100m","数据集","数据集更现实、更具挑战性的任务。【维基百科】【英文】","数据集链接：cail2019/阅读理解/data","数据集链接：http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json","数据集链接：https://ai2","数据集链接：https://qasper","数据集链接：pubmedqa","数据集链接：训练集[https://rajpurkar.github.io/squad","数据集链接：训练集[https://storage.cloud.google.com/natural_questions/v1.0","数据集，将解压后的","数据预处理：","文本1|||标签1","文本2|||标签2","文本3|||标签3","方便用户将模型部署到云端。","方法中，模型的输出被视为一个序列，每个部分都是一个独立的“思考链”或步骤。模型通过将先前的输出作为后续输入的一部分来迭代地生成这些部分，这样可以让模型在一定程度上模拟人类解决问题的过程。","方法会冻结全部的模型参数，可通过调整","无害性（harmlessness）：是否不会对人类造成伤害，一个产生仇恨言论或提倡暴力的模型不是无害的。","是","是一个开源的、支持中英双语的对话语言模型，基于","是一个问答数据集，具有自然的多跳问题，对支持事实进行强有力的监督，以实现更可解释的问答系统。","是一种微调大型预训练语言模型（如","是一种有效的技巧，可以帮助大型预训练语言模型在多步骤任务和复杂问题中生成连贯的输出。然而，在实际应用中，可能需要结合其他技巧来克服其局限性，以实现更好的性能。","是一系列基于中文法律知识的开源大语言模型，该系列模型在通用中文基座模型（如","是个很极端的数据类型，它最多只能表示","是微调","是经过中文医学指令精调/指令微调(instruct","更为宽泛、总结性的跨篇章问答数据集（gpt自生成）","更改为训练时保存的","最常用的省内存方法之一【低秩转换】","本地知识库问答","本地领域知识库部分：由于token长度限制问题，所以需要将多个pdf进行拆分成段落（segment），然后利用langchain+faiss向量库建立向量数据库和文档索引。","本文实现了基于","本次只是演示，使用部署脚本加载本地模型,并加载新的checkpoint。","本草","来加速，但是在更新参数时使用","来对给定的文本进行情感分析。我们的目标是根据文本内容，判断其情感是正面、负面还是中性。以下是一个简单的指南：","来被原始模型的量化等级，不加此选项则默认为","来说，需要储存两倍的模型参数","构建一个输入输出对的大型数据集。","构建了中文医学指令数据集，并在此基础上对llama进行了指令微调，提高了llama在医疗领域的问答效果。","构建虚拟环境","构造指令数据集结构，类似于instruct的方法，可参考使用开源的中文数据集：chines","架构，具有","标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62","根据参数量估计模型大致所需的","根据已有的样本，摘要喂给gpt4进行self","根据自己数据库让gpt作答","框架，使用","梯度计算","梯度：等于参数量*每个梯度参数所需内存。","棵树的完整数据集，包括一系列小型和大型多步蕴涵问题。","概述","概述：","概述：一个典型的chatpdf类似应用，类似相关项目很多如：","概述：主体是一个基于环境工程、生态学相关领域","概述：思维链将一个逻辑推理问题，分解成了多个步骤，来一步步进行，这样生成的结果就有着更加清晰的逻辑链路，提供了一定的可解释性，让人知道答案是怎么来的。","模型checkpoint路径","模型下载,","模型为例估算其大致需要的内存：","模型前缀长度","模型参数：模型参数：等于参数量*每个参数所需内存。","模型名","模型和数据准备","模型底座","模型微调","模型推理","模型测试和评估：","模型的格式。例如，将文本和情感标签拼接在一起，用特定的分隔符（如","模型能够根据输入文本生成对应的情感标签，从而实现情感分类任务。","模型训练【后续可参考】","模型训练与微调【后续进行微调可借鉴】","模型训练可以使用一些机器学习框架，pytorch。使用预训练模型来初始化chatglm","模型训练后，lora","模型评估","模型路径","模型输入是前面描述的三个任务的模型输入，除了插入检索步骤的任务3（语料库","模型进行","模型部分大致需要","模型部署","模型，针对","模型：","此外，项目组还收集了2023年关于肝癌疾病的中文医学文献，利用gpt3.5接口围绕医学文献多轮问答数据（1k条左右）。","步骤组成，尽管有许多可用的单步蕴涵数据集，但是目前不存在多步蕴涵数据集，","步骤：","步（批量大小","比即时设计更高质量的结果","比原来的代码多了model","毕设技术框架","没有量化的版本做推理需要13g的gpu显存，int8量化需要8gb的显存，而int4量化的版本需要6gb的显存。","注意需要将","注意，其实就是第三行代码最后的float()有差异：gpu版本后面是.half().cuda()，而这里是float()。","注意，目前chatglm","注意：模型量化会带来一定的性能损失，经过测试，chatglm","注：cpu版本的模型推理运行一次约1","注：安装这个主要是为了编译之前下载的文件中的quantization_kernels.c和quantization_kernels_parallel.c这两个文件。","激活环境","然后就可以在d:\\\\data\\\\llm\\\\chatglm","生成模型，采用早期技术来生成演绎证明。发现这些模型部分地解决了数据集，并具有泛化到其他领域的迹象。因此，的贡献是：","生成的结果保存在","用","用一个","用户提问部分：将用户提出的query进行同义词+历史信息扩充，然后选取目前词嵌入效果最佳的相关embedding模型进行词向量建模，将得到的词向量与本地知识库的向量数据库进行匹配检索，将匹配结果进行聚类，扩充得到与该问题相关的更全回答信息，并基于相似度进行排序得到喂给llm模型的信息。","由于更短的提示而节省令牌","电影评论数据集，也可以是你自己收集和标注的数据。","的","的llama","的上下文中，有多种解释/理由的概念，包括显示权威的、有答案的句子（perez","的作者根据这一特点将更新矩阵变成两个低秩矩阵的积积b","的启发，研究人员也选择用gpt","的多步蕴涵树数据集，支持基于蕴涵的解释。每棵树平均包含","的大致实现方法：","的完整流程：","的巧妙方法是在所有","的开源数据集。","的开源数据集上微调出一个","的性能是有效的；用gpt","的数字，并且完全没有精度。","的数据生成器是一个","的时候使用","的树的错误为零）。还提出迹象表明，entailmentbank","的模型和其他开源模型之间切换。lamini","的生成模型（每个任务一个），称为","的研究团队在其","的蕴涵树。","的训练/微调/推理方法，包括：","的设定下进行全参数训练【25.3+990/1024*50】。","的高效参数微调方法，通过实际动手操作，提升对大模型的理解和应用能力。","的高效参数微调进行训练。需要考虑到训练时间和硬件资源的因素","目前市场上出现的实时搜索基本也是先在网页搜索后将网页的内容提取出来后，一起打包发给gpt,让其回复，并没有真正的实现联网功能。","目录放到本目录下。","直接点击上述页面中tdm","相似的技术，针对中文问答和对话进行了优化。经过约","相关gpt调研","相关技术调研","相关链接：","相关链接：再谈知识图谱与chatgpt如何结合：参数化与形式化知识库的现实问题、结合要素和具体路线","相关链接：神奇llm引擎上线！帮你把gpt","相同点：知识图谱vs大语言模型本质上都是一种知识库；chatgpt遇到的事实性错误和时效性，知识图谱同样存在，知识图谱也需要解决知识更新的问题。","相当于让ai做分析题，而不是“填空题”，要把推理过程详细说清楚，按步骤得分，最后给出答案。","知识图谱vs大语言模型","知识图谱是一种知识的形式化表示方式，大语言模型(chatgpt)是参数化的知识。","知识图谱，可以利用prompt，参与到大模型的训练前的数据构造，训练中的任务，以及训练后推理结果的约束生成，提升大模型的性能。","知识类问答数据集资源对外开放：百万级百度知道、社区问答及六大领域级小规模语料概述","知识问答数据集包括针对self","研究人员团队收集。【英文】","研究人员基于llama","第一章：训练微调相关技术","第一阶段：扩充法律领域词表，在大规模法律文书及法典数据上预训练","第三种技术称为渐进收缩(progress","第三章：数据底座方法与调研","第二章：如何定制化gpt","第二阶段：构造法律领域对话问答数据集，在预训练模型基础上指令精调。","第四章：其他相关知识","等人，2016）、综合连接问题和答案的短语（rajani","等人，2018","等人，2019","等人，2019）、段落上的注意力图（seo","等人，2019），但它们很少从什么解释推理链已知答案，即在给出证据的情况下，答案是如何得出的——这项工作的目标。","等人，2020","等分布优化算法，减少内存的占用量。其将模型参数，梯度和优化器状态分布至多个","等）的基础上扩充法律领域专有词表、大规模中文法律语料预训练，增强了大模型在法律领域的基础语义理解能力。在此基础上，构造法律领域对话问答数据集、中国司法考试数据集进行指令精调，提升了模型对法律内容的理解和执行能力。","策略问题需要大量的世界知识，而小型模型没有足够的参数来记忆这些世界知识，所以也不太可能产生正确的推理步骤。","简介","简单总结就是说prompt就是利用语言模型的生成能力帮我们完成任务。","简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。","简而言之：在外面包了一层语义搜索，先搜索再打包，最后发给gpt回答。","简述原理：微调llm时，更新矩阵往往是低秩矩阵。（低秩矩阵是指矩阵中包含的信息可以用较低维度的子空间进行近似表示的矩阵，由于低秩矩阵在储存和计算方面都有优势，所以它们被广泛应用于压缩、降噪、特征提取、模型压缩等任务）（矩阵的秩是指矩阵中线性无关的行或列的最大数目）","篇论文的数据集，其中包含","类似，均通过","类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞","精度","精度加载。","精度的","精度，一个参数需要","精度；batch_siz","系列模型的训练过程分为两个阶段：","系统中的“all","经典的fine","结构化知识很难构建(因为要设计知识的结构体系)，但易于推理(因为有体系结构)，非结构化知识易于构建(直接存","结果显示：反馈数据和奖励模型对提高","给出一个文本证据的片段","给定一个假设（问题+答案），定义了三个越来越难的解释任务：为给定的","综合1、2、3步骤，int8","而openai在instructgpt中也是类似的想法！instructgpt就是chatgpt的前身！","聚类（其中文本字符串按相似性分组）","能够训练更多的例子比可以在提示","节省显存的微调推理技术对比","解决方案：矢量数据库","计算资源","训练","训练一个新的微调模型","训练完成后，需要进行模型评估和调整。可以使用一些指标来评估模型的性能。","训练技术：prompt","训练数据下载存放路径：","训练数据主要分为两个部分：1.律师和用户之间的情景对话；","训练数据示例：","训练模型","训练的模型可以推广到其他领域。","训练的相关句子排序器），并将它们输入到模型中。所有情况下的输出都是解释qa","训练部署自己的chatglm","训练部署自己的羊驼","训练集、1gb开发集","论文地址（github）:https://github.com/microsoft/lora","论文链接：https://arxiv.org/pdf/2304.03277.pdf","评估数据示例：","评测样本示例：","诚实性（honesty）：是否提供真实信息，并在必要时表达其不确定性以避免误导人类用户，一个提供虚假信息的模型是不诚实的。","该数据集将让模型理解它应如何响应其输入。使用","语料库加上注释器创建的所有其他科学事实；所需的输出都是有效的蕴涵树","语料微调训练得到的一个gpt模型，提供chat页面。","调整。","调研报告","起来就行)，但很难用于推理(没有体系结构)。","跟你训练的pre_seq_len一致","轻松打造家用版gpt","输入：这部电影的剧情令人惊叹，特效也非常出色，我非常喜欢。","输出：正面","运行以下指令进行模型推理和评测：bash","运行部署cpu版本的int4量化的chatglm","运行部署gpu版本的int4量化的chatglm","这个想法是，通过使用监督来教授语言模型执行通过指令描述的任务，模型将学会遵循指令，即使是对于未见过的任务也能如此。","这些子任务应该是相互关联的，每个子任务的输出都可以作为下一个子任务的输入。","这些目标和损失函数应该与任务相关，并帮助模型学习与该任务相关的知识。","这样的方式训练了出来的模型可以让模型更好地识别输入的意图，同时也在zero","这种步骤分解的方式用在提示学习中，就被称为思维链提示，将大语言模型的推理过程，分解成一个个步骤，直观地展现出来，这样开发人员可以在llm推理出现错误时，就及时地修复。","这篇博文解释了","进行转移，从而节省","选择支撑答案的句子","通常从最底部的叶节点开始，从它们中创作中间结论，然后逐步在树的更高层次上工作，直到他们创作出直接回答问题的结论。","通过","通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数。","通过以上步骤我们可以得到如下结果：gpu版本大约只需要1","通过提供以下功能，微调可让您从api提供的模型中获得更多信息：","通过要求参与的","那么就是前面说的编译文件出了问题，那么就必须做上面说的编译操作，得到那2个so文件，然后手动加载。新代码如下：","那么就是这两个文件编译出问题了。那么就需要我们手动去编译这两个文件：","部署gpu版本的chatglm","部署前安装环境","里声明","量化下仍然能够进行自然流畅的生成。","长度和训练的学习率，可以进行调节以取得最佳的效果。","问题”对的方式让chatgpt回答问题，从而使chatgpt能够生成含有法律信息的回答，保证回答的准确性。【后续可参考该方法构建问答数据集】","降低延迟请求","需要","需要检测自己的torch是否正确，可以通过如下命令检查（下面是python代码）：","需要注意的是，在github上，官方提供了模型在清华云上的下载地址，但是那个只包含预训练结果文件即bin文件，","非自然指令评估（unnatur","项目地址：https://lamini.ai/","项目组在一张a100","项目组采用了公开和自建的中文医学知识库方式，主要参考了cmekg","飞桨ai","首先考虑精度对所需内存的影响：","首先，你需要一个带有标签的文本数据集，以便在情感分类任务上微调模型。数据集应该包含多个实例，每个实例都有一段文本和一个对应的情感标签（正面、负面或中性）。数据集可以是开源的，如","首先，我们需要从github上下载chatglm的requirements.txt来帮助我们安装依赖的库。","（1）input：prompt[用户提问+相关检索信息]","（1）lamini","（1）lawgpt","（1）vector","（1）准备自然语言指令集：针对特定任务，准备一组自然语言指令，描述任务类型和任务目标，例如情感分类任务的指令可以是“该文本的情感是正面的还是负面的？”。","（1）收集大量的语料库，包括各种主题和风格的文本。可以从各种来源获取数据，如网站、社交媒体、新闻、书籍等。","（1）用","（1）首先，需要定义一个目标任务，即要求模型完成的最终任务。","（2）lamini","（2）mix","（2）output：带有标引信息的回答结果","（2）准备训练数据集：针对特定任务，准备一个标记化的数据集，其中每个数据样本都包含输入文本和标签，例如情感分类任务的标签可以是“正面”或“负面”。","（2）对语料库进行预处理，包括分词、标记化、去除停用词、处理语法结构等。","（2）然后，需要将目标任务分解为一系列子任务。","（3）垂直领域llm模型微调部分：根据已有的开源微调项目进行改动、参考","（3）定义一个上下文窗口，即模型需要考虑的前面和后面的文本内容。","（3）将自然语言指令和数据集转换为模型输入：将自然语言指令和数据集转换为模型输入，例如对于情感分类任务，将自然语言指令和文本拼接作为输入，例如：“该文本的情感是正面的还是负面的？这家餐厅的食物很好吃。”","（3）每个子任务的输入和输出都需要定义。","（4）在指令上进行微调：在指令上进行微调，以适应特定任务的需求，提高模型在任务上的性能。","（4）将训练过程分解为一系列逐步更复杂的子任务。","（4）每个子任务都需要为其定义一个训练目标和相应的损失函数。","（5）为每个子任务定义适当的训练目标和损失函数，并使用训练数据来训练模型。","（5）最后，需要将所有子任务组合起来，构建一个完整的模型。每个子任务的输出都将成为下一个子任务的输入，直到完成目标任务。","（6）在训练完成后，使用测试数据来评估模型的性能。例如，检查模型是否能够生成连贯的响应，以及是否能够维护文本中的思维链。","（7）迭代地对模型进行微调和优化。","（注意，有显卡也需要下载cuda和cudann安装成功才可以，这部分可以去网上找教程）。","（用来储存一阶和二阶momentum）。","，这是第一个包含多步蕴涵树的数据集。","：二次训练阶段耗时约"],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"Introduction","keywords":"","body":"调研报告\n\n天工GPT调研\n\n相关GPT调研\n\n相关技术调研\n\n第一章：训练微调相关技术\n\n节省显存的微调推理技术对比\nLLM三种微调技术对比\nLLM三种训练技术对比\n思维链简介\n\n\n第二章：如何定制化GPT\n\n根据自己数据库让GPT作答\n\n训练部署自己的羊驼 Alpaca-LoRA\n\n训练部署自己的ChatGLM-6B\n\nWindows+6GB显+CPU本地部署ChatGLM-6B.md\n\n\n\n第三章：数据底座方法与调研\n\nSelf-Instruct自动生成微调数据\n学术问答数据集调研\n\n\n第四章：其他相关知识\n\nLamini LLM引擎学习\nGPT与知识图谱\nEntailment Trees论文学习笔记\nMETGEN论文学习笔记\n\n\n\n\n毕设技术框架\n\n学习相关项目代码\n\n本地知识库问答\n\nyanqiangmiffy/Chinese-LangChain: 中文langchain项目\nhttps://github.com/imClumsyPanda/langchain-ChatGLM)\n\n\n模型微调\n\nOptimalScale/LMFlow\npengxiao-song/LaWGPT\nSCIR-HI/Huatuo-Llama-Med-Chinese\n\n\n模型底座\nminlik/chinese-alpaca-plus-7b-merged at main (huggingface.co)\nTHUDM/ChatGLM-6B: ChatGLM-6B\n\n\n\n\n\n"},"天工GPT调研/天工GPT调研.html":{"url":"天工GPT调研/天工GPT调研.html","title":"天工GPT调研","keywords":"","body":"天工GPT调研\n相关链接：\n天工Chat上新了\nTianGong GPT\n\n一、天工Chat：TianGong Chat【领域微调是重点】\n\n\n概述：主体是一个基于环境工程、生态学相关领域    语料微调训练得到的一个GPT模型，提供Chat页面。\n主要特点：从提问中抽取出关键信息，然后进行知识库匹配。\n \n\n实测体验：速度较慢，生成效果如下，可以看到主要包括文本信息+相关扩展链接。\n\n\n\n\n二、天工GPT：天宫 (tiangong.world)【开源ChatPDF套壳】\n \n\n概述：一个典型的ChatPDF类似应用，类似相关项目很多如：\nhttps://www.chatpdf.com\nAsk Your PDF - Interactive PDF Conversations powered by ChatGPT\n\n主要的实现原理：将文章进行分割，然后与query进行查询匹配，将相关段落返回，输入到GPT中得到最后的答案。\n \n\n\n"},"相关GPT调研/相关GPT调研.html":{"url":"相关GPT调研/相关GPT调研.html","title":"相关GPT调研","keywords":"","body":"垂直领域GPT微调模型介绍\n一、本草医学GPT模型：基于中文医学知识的LLaMA微调模型\ngithub链接：https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese\n\n概述\n本草 是经过中文医学指令精调/指令微调(Instruct-tuning) 的LLaMA-7B模型，由哈尔滨工业大学社会计算与信息检索研究中心健康智能组完成。项目组通过 医学知识图谱 和 GPT3.5 API 构建了中文医学指令数据集，并在此基础上对LLaMA进行了指令微调，提高了LLaMA在医疗领域的问答效果。\n\n使用展示\n \n\n数据集\n\n\n项目组采用了公开和自建的中文医学知识库方式，主要参考了cMeKG (https://github.com/king-yyf/CMeKG_tools)，并利用 GPT3.5接口围绕医学知识库构建问答数据，设置了多种Prompt形式来充分利用知识。医学知识库围绕疾病、药物、检查指标等构建，字段包括并发症，高危因素，组织学检查，临床症状，药物治疗，辅助治疗等。知识库示例如下：\n{\"中心词\": \"偏头痛\", \"相关疾病\": [\"妊娠合并偏头痛\", \"恶寒发热\"], \"相关症状\": [\"皮肤变硬\", \"头部及眼后部疼痛并能听到连续不断的隆隆声\", \"晨起头痛加重\"], \"所属科室\": [\"中西医结合科\", \"内科\"], \"发病部位\": [\"头部\"]}\n\n指令微调数据集：QA数据集\n\"问题：一位年轻男性长期使用可卡因，突然出现胸痛、呕吐、出汗等症状，经检查发现心电图反映心肌急性损伤，请问可能患的是什么疾病？治疗方式是什么？\"\n回答: 可能患的是心肌梗塞，需要进行维拉帕米、依普利酮、硝酸甘油、ß阻滞剂、吗啡等药物治疗，并进行溶栓治疗、低分子量肝素、钙通道阻滞剂等辅助治疗。此外需要及时停用可卡因等药物，以防止病情加重。\"\n\n此外，项目组还收集了2023年关于肝癌疾病的中文医学文献，利用GPT3.5接口围绕医学文献多轮问答数据（1k条左右）。\n\n模型训练与微调【后续进行微调可借鉴】\n\n\n支持使用自己的数据集进行微调，只需要按照./data/llama_data.json的格式构建自己的数据集，然后执行命令：\nbash ./scripts/finetune.sh\n项目组在一张A100-SXM-80GB显卡上进行了训练，训练总轮次10轮，耗时大约2h17m。batch_size=128的情况下显存占用了40G左右。也可以使用3090/4090显卡，显存在24GB以上时，可以获得较好的效果。\n\n二、LaWGPT 中文法律知识模型\ngithub链接：https://github.com/pengxiao-song/LaWGPT/\n\n概述：\nLaWGPT 是一系列基于中文法律知识的开源大语言模型，该系列模型在通用中文基座模型（如 Chinese-LLaMA、ChatGLM 等）的基础上扩充法律领域专有词表、大规模中文法律语料预训练，增强了大模型在法律领域的基础语义理解能力。在此基础上，构造法律领域对话问答数据集、中国司法考试数据集进行指令精调，提升了模型对法律内容的理解和执行能力。\n\n数据集\n\n\n​    训练数据主要分为两个部分：1.律师和用户之间的情景对话； 2.对特定法律知识的问答。\nquestion:朋友欠钱不还咋办\nanswers: ['欠款金额是多少 ', '多少钱呢', '律师费诉讼费都非常少都很合理，一定要起诉。', '大概金额多少？', '需要看标的额和案情复杂程度，建议细致面谈']\n*******************************************************\nquestion:昨天把人家车刮了,要赔多少\nanswers: ['您好，建议协商处理，如果对方告了你们，就只能积极应诉了。', '您好，建议尽量协商处理，协商不成可起诉']\n*******************************************************\n\n知识问答数据集包括针对Self-Instruct的可靠性和安全性漏洞，使用了基于特定知识的Reliable-Self-Instruction：通过提供具体的法律知识文本，先让ChatGPT生成与该段法律知识内容与逻辑关系相关的若干问题，再通过“文本段-问题”对的方式让ChatGPT回答问题，从而使ChatGPT能够生成含有法律信息的回答，保证回答的准确性。【后续可参考该方法构建问答数据集】\n\n模型训练【后续可参考】\n（1）LawGPT 系列模型的训练过程分为两个阶段：\n\n第一阶段：扩充法律领域词表，在大规模法律文书及法典数据上预训练 Chinese-LLaMA\n第二阶段：构造法律领域对话问答数据集，在预训练模型基础上指令精调。\n\n\n计算资源\n8 张 Tesla V100-SXM2-32GB ：二次训练阶段耗时约 24h / epoch，微调阶段耗时约 12h / epoch\n\n\n"},"Chapter2/微调范式对比.html":{"url":"Chapter2/微调范式对比.html","title":"节省显存的微调推理技术对比","keywords":"","body":"微调范式对比\n参考链接：有哪些省内存的大语言模型训练/微调/推理方法？\n一、Memory-Efficient 的 LLMs 的训练/微调/推理方法，包括：\n● fp16\n● int8\n● LoRA\n● Gradient checkpointing\n● Torch FSDP\n● CPU offloading\n二、估算模型所需的RAM：参数个数  精度  4 + CUDA内核1.3  + [(hidden_size+intermediate_size)context_length\\num_hidden_layers]/1024 G * batch数\n根据参数量估计模型大致所需的 RAM，进而通过估算设置 batch_size，设置模型精度，选择微调方法和参数分布方法等。\n（1）用 LLaMA-6B 模型为例估算其大致需要的内存：\n1. 首先考虑精度对所需内存的影响：\n● fp32 精度，一个参数需要 32 bits, 4 bytes.\n● fp16 精度，一个参数需要 16 bits, 2 bytes.\n● int8 精度，一个参数需要 8 bits, 1 byte.\n2. 其次，考虑模型需要的 RAM 大致分三个部分：\n● 模型参数：模型参数：等于参数量*每个参数所需内存。\n    对于 fp32，LLaMA-6B 需要 6B*4 bytes = 24GB内存\n    对于 int8，LLaMA-6B 需要 6B*1 byte = 6GB\n● 梯度：等于参数量*每个梯度参数所需内存。\n● 优化器参数：不同的优化器所储存的参数量不同。对于常用的 AdamW 来说，需要储存两倍的模型参数    （用来储存一阶和二阶momentum）。\n    fp32 的 LLaMA-6B，AdamW 需要 6B*8 bytes = 48 GB\n    int8 的 LLaMA-6B，AdamW 需要 6B*2 bytes = 12 GB\n3. CUDA kernel 也会占据一些 RAM，大概 1.3GB 左右\n    torch.ones((1，1)).to(\"cuda\")\n    print_gpu utilization()\n    GPU memory occupied: 1343 MB\n4. 综合1、2、3步骤，int8 精度的 LLaMA-6B 模型部分大致需要 6GB+6GB+12GB+1.3GB = 25.3GB 左右。\n再根据LLaMA的架构（hidden_size = 4096, intermediate_size =11008, num_hidden_layers = 32, context_length = 2048）计算中间变量内存。\n \n5. 所以一张 A100（80GB RAM）大概可以在 int8 精度；batch_size = 50 的设定下进行全参数训练【25.3+990/1024*50】。\n\n三、Fp16-mixed precision\n \n\n大致思路：在前向反馈 和 梯度计算 的时候使用 fp16 来加速，但是在更新参数时使用 fp32。\ntorch实现：torch fp16 推理直接使用 model.half() 将模型转换为fp16。\n\nmodel.half()\n\n使用 Huggingface Transformers：在 TrainingArguments 里声明 fp16=True\n\n\n四、Int8-bitsandbytes量化方法\n参考论文：LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scalehttps://arxiv.org/abs/2208.07339*\n\nInt8 是个很极端的数据类型，它最多只能表示 - 128～127 的数字，并且完全没有精度。\n\n为了在训练和 inference 中使用这个数据类型，bitsandbytes 使用了两个方法最大程度地降低了其带来的误差：\nA Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes (huggingface.co)\n（1）vector-wise quantization：矢量量化\n（2）mixed precision decompasition：混合精度反编译\n \n\n借助 Huggingface PEFT，使用 int8 训练 opt-6.5B 的完整流程：\nhttps://github.com/huggingface/peft/blob/main/examples/int8_training/Finetune_opt_bnb_peft.ipynb\n\n\n\n五、LoRA：Low-Rank Adaptation 是微调 LLMs 最常用的省内存方法之一【低秩转换】\nhttps://arxiv.org/pdf/2106.09685.pdf\n \n简述原理：微调LLM时，更新矩阵往往是低秩矩阵。（低秩矩阵是指矩阵中包含的信息可以用较低维度的子空间进行近似表示的矩阵，由于低秩矩阵在储存和计算方面都有优势，所以它们被广泛应用于压缩、降噪、特征提取、模型压缩等任务）（矩阵的秩是指矩阵中线性无关的行或列的最大数目）\n \n所以LoRA 的作者根据这一特点将更新矩阵变成两个低秩矩阵的积积B . A 。\n \n例子：借助 Huggingface PEFT 框架，使用 LoRA 微调 mt0：\nhttps://github.com/huggingface/peft/blob/main/examples/conditional_generation/peft_lora_seq2seq.ipynb\n\n六、Gradient Checkpointing\n在 torch 中使用 - 把 model 用一个 customize 的 function 包装一下即可，详见：\nExplore Gradient-Checkpointing in PyTorch\nhttps://qywu.github.io/2019/05/22/explore-gradient-checkpointing.html\n在 Huggingface Transformers 中使用：\nhttps://huggingface.co/docs/transformers/v4.27.2/en/perf_train_gpu_one#gradient-checkpointing\n\n七、Torch FSDP+CPU offload【分布式】\n\n原理：Fully Sharded Data Paralle（FSDP）和 DeepSpeed 类似，均通过 ZeRO 等分布优化算法，减少内存的占用量。其将模型参数，梯度和优化器状态分布至多个 GPU 上，而非像 DDP 一样，在每个 GPU 上保留完整副本。\nCPU offload 则允许在一个 back propagation 中，将参数动态地从 GPU -> CPU, CPU -> GPU 进行转移，从而节省 GPU 内存。\n\nHuggingface 这篇博文解释了 ZeRO 的大致实现方法：\n\nhttps://huggingface.co/blog/zero-deepspeed-fairscale\n\n\nZeRO零冗余优化器 的巧妙方法是在所有 GPU 上平均划分参数、梯度和优化器状态，并为每个 GPU 提供一个分区（也称为分片）。这导致 GPU 之间的数据存储零重叠。在运行时，每个 GPU 通过要求参与的 GPU 发送它所缺少的信息来动态构建每一层的数据。\nFairScale 和 DeepSpeed 仅对优化器状态和梯度执行分区（分片）。模型参数分片应该很快就会在DeepSpeed和FairScale中推出。\nZeRO 卸载（CPU）。此功能将一些处理和内存需求卸载到主机的 CPU，从而允许更多内容适应 GPU。\n\n借助 torch 实现 FSDP，只需要将 model 用 FSDPwarp 一下；同样，cpu_offload 也只需要一行代码：\n\nhttps://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/\n\n在这个可以查看 FSDP 支持的模型：\n\nhttps://pytorch.org/docs/stable/fsdp.html\n\n在 Huggingface Transformers 中使用 Torch FSDP：\n\nhttps://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer#transformers.Trainin\n\n\n"},"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html":{"url":"Chapter2/大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune.html","title":"LLM三种微调技术对比","keywords":"","body":"微调范式对比\n参考链接：大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune \nBERT出现之后，fine-tuning技术也随之流行，即将预训练模型的权重冻结，然后根据具体任务进行微调变得十分有效且被应用在很多场景。随着ChatGPT的火热，parameter-efficient fine-tuning和prompt-tuning技术似乎也有替代传统fine-tuning的趋势，本篇论文将简单描述预训练模型领域这三种微调技术及其差别。\n一、fine-tuning技术\n\nFine-tuning的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。\n\n经典的fine-tuning方法包括将预训练模型与少量特定任务数据一起继续训练。在这个过程中，预训练模型的权重被更新，以更好地适应任务。所需的fine-tuning量取决于预训练语料库和任务特定语料库之间的相似性。如果两者相似，可能只需要少量的fine-tuning。如果两者不相似，则可能需要更多的fine-tuning。\n\n在NLP中，fine-tuning最著名的例子之一是由OpenAI开发的OpenAI GPT（生成式预训练变压器）模型。GPT模型在大量文本上进行了预训练，然后在各种任务上进行了微调，例如语言建模，问答和摘要。经过微调的模型在这些任务上取得了最先进的性能。\n\n总结：将除了输出层以外的所有权重“冻结”（freeze）。然后随机初始化输出层参数，再以迁移学习的方式训练。仅仅更新全连接输出层，其它层的权重不变。\n\n\n二、parameter-efficient fine-tuning技术[PEFT]\n\n参数高效的fine-tuning，简称PEFT，旨在在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。它是自然语言处理（NLP）中一组用于将预训练语言模型适应特定任务的方法，其所需参数和计算资源比传统的fine-tuning方法更少。\n\n通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数。\n\n其中一种PEFT技术称为蒸馏(distillation)，它由Hinton等人于2015年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。【教师-学生】\n另一种技术称为适配器训练(adapter training)，它由Houlsby等人于2019年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。\n第三种技术称为渐进收缩(progressive shrinking)，它由Kaplan等人于2020年引入。这种技术涉及在fine-tuning期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。\nPEFT综述：Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning\n\n\n三、prompt-tuning技术\n\nprompt-tuning是一种更近期的精调预训练语言模型的方法，重点是调整输入提示（input prompt）而非修改模型参数。这意味着预训练模型保持不变，只有输入提示被修改以适应下游的任务。通过设计和优化一组提示，可以使预训练模型执行特定任务。\n\nprompt-tuning和传统的fine-tuning的主要区别在于预训练模型被修改的程度。fine-tuning修改模型的权重，而prompt-tuning只修改模型的输入。因此，prompt-tuning调整比精调的计算成本低，需要的资源和训练时间也更少。此外，prompt-tuning比精调更灵活，因为它允许创建特定任务的提示，可以适应各种任务。\n\n\n一些值得注意的prompt-tuning技术包括：\n\nPrefix tuning（前缀调整）：由Li和Liang在论文“Prefix-Tuning: Optimizing Continuous Prompts for Generation”（2021）中提出。前缀调整涉及学习特定任务的连续提示，在推理过程中将其添加到输入之前。通过优化这个连续提示，模型可以适应特定任务而不修改底层模型参数，这节省了计算资源并实现了高效的精调。\nP-Tuning：由Liu等人在论文“P-Tuning: GPT Understands, Learns, and Generates Any Language”（2021）中提出。P-Tuning涉及训练可学习的称为“提示记号”的参数，这些参数与输入序列连接。这些提示记号是特定于任务的，在精调过程中进行优化，使得模型可以在保持原始模型参数不变的情况下在新任务上表现良好。\n\n\n总结：当大模型开始涉及更加复杂和现实的问题时候，如果可以出现自动prompt-tuning技术而非手工调整可能是未来很重要的方向。毕竟在文本摘要、代码debug等需要大量的输入来让模型认识问题的场景，如何有效的将过长的输入prompt给模型是一个很重要的问题，现在的大模型在长输入方面推理成本很高且有很大限制，因此这种技术也是未来很重要的一个方向！\n"},"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html":{"url":"Chapter2/Prompt-Tuning、Instruction-Tuning和Chain-of-Thought.html","title":"LLM三种训练技术对比","keywords":"","body":"训练技术：Prompt-Tuning、Instruction-Tuning和Chain-of-Thought\n参考链接：大语言模型三种训练技术及区别：Prompt-Tuning、Instruction-Tuning和Chain-of-Thought\n一、Prompt-Tuning：加上“prompt”，变成填空题\n只要我们把希望输出的部分删除掉，然后尽量构造与该输出有关的其它tokens即可。这就是prompt-tuning的一种想法！\n与输出相关的tokens组成的上下文信息即可理解为是一个prompt。Prompt通常是一种短文本字符串，用于指导语言模型生成响应。Prompt提供上下文和任务相关信息，以帮助模型更好地理解要求，并生成正确的输出。\n简单总结就是说Prompt就是利用语言模型的生成能力帮我们完成任务。\n\n二、Instruction-Tuning介绍：更为详细流程化\n与Prompt不同，Instruction通常是一种更详细的文本，用于指导模型执行特定操作或完成任务。Instruction可以是计算机程序或脚本，也可以是人类编写的指导性文本。Instruction的目的是告诉模型如何处理数据或执行某个操作，而不是简单地提供上下文或任务相关信息。\n区别：Prompt和Instruction都是用于指导模型生成输出的文本，但它们的目的和使用方式是不同的。Prompt更多地用于帮助模型理解任务和上下文，而Instruction则更多地用于指导模型执行具体操作或完成任务。\n指令微调的动机是提高语言模型对自然语言处理指令的响应能力。\n这个想法是，通过使用监督来教授语言模型执行通过指令描述的任务，模型将学会遵循指令，即使是对于未见过的任务也能如此。\n而OpenAI在InstructGPT中也是类似的想法！InstructGPT就是ChatGPT的前身！\n例如：对于问答任务，Instruction可以提供具体的指令，例如“请回答下列问题：谁是美国第一位总统？”，并将文本段落作为输入提供给模型。\n以InstructGPT为例，其基本流程如下：\n（1）准备自然语言指令集：针对特定任务，准备一组自然语言指令，描述任务类型和任务目标，例如情感分类任务的指令可以是“该文本的情感是正面的还是负面的？”。\n（2）准备训练数据集：针对特定任务，准备一个标记化的数据集，其中每个数据样本都包含输入文本和标签，例如情感分类任务的标签可以是“正面”或“负面”。\n（3）将自然语言指令和数据集转换为模型输入：将自然语言指令和数据集转换为模型输入，例如对于情感分类任务，将自然语言指令和文本拼接作为输入，例如：“该文本的情感是正面的还是负面的？这家餐厅的食物很好吃。”\n（4）在指令上进行微调：在指令上进行微调，以适应特定任务的需求，提高模型在任务上的性能。\n这样的方式训练了出来的模型可以让模型更好地识别输入的意图，同时也在zero-shot中表现更好！\n\n三、Chain-of-Thought介绍\n允许模型在多个步骤中生成连贯的回答，从而更好地解决问题或完成任务。通过思维链式方法训练大型语言模型需要将训练过程分解成较小、相互关联的任务，以帮助模型理解和生成连贯、上下文感知的响应。\n在 chain-of-thought 方法中，模型的输出被视为一个序列，每个部分都是一个独立的“思考链”或步骤。模型通过将先前的输出作为后续输入的一部分来迭代地生成这些部分，这样可以让模型在一定程度上模拟人类解决问题的过程。\n \n以GPT-3为例，以下是一些步骤，可以用Chain-of-thought方法训练一个更先进的GPT-3模型：\n（1）收集大量的语料库，包括各种主题和风格的文本。可以从各种来源获取数据，如网站、社交媒体、新闻、书籍等。\n（2）对语料库进行预处理，包括分词、标记化、去除停用词、处理语法结构等。\n（3）定义一个上下文窗口，即模型需要考虑的前面和后面的文本内容。\n（4）将训练过程分解为一系列逐步更复杂的子任务。\n    例如，可以将训练过程分解为理解语法和词汇、生成单词和短语、生成连贯的句子和段落、理解上下文等子任务。\n（5）为每个子任务定义适当的训练目标和损失函数，并使用训练数据来训练模型。\n    例如，为了训练模型理解上下文，可以定义一个损失函数，它评估模型生成的响应与上下文的相关性。\n（6）在训练完成后，使用测试数据来评估模型的性能。例如，检查模型是否能够生成连贯的响应，以及是否能够维护文本中的思维链。\n（7）迭代地对模型进行微调和优化。\n在Chain-of-thought训练中，将数据集中的输入分解为一系列任务是非常关键的一步。一般来说，这个过程需要根据特定的任务和数据集来进行定制。以下是一些通用的方法：\n（1）首先，需要定义一个目标任务，即要求模型完成的最终任务。\n     例如，如果目标任务是自然语言生成，那么数据集中的输入可能是一句话或一个段落，模型需要将其转化为自然语言响应。\n（2）然后，需要将目标任务分解为一系列子任务。\n    这些子任务应该是相互关联的，每个子任务的输出都可以作为下一个子任务的输入。\n    例如，在自然语言生成任务中，可以将其分解为理解输入的语义、确定输出的语法结构、生成文本等子任务。\n（3）每个子任务的输入和输出都需要定义。\n    例如，在自然语言生成任务中，输入可能是一组与上下文相关的单词，输出可能是下一个单词或整个句子。\n（4）每个子任务都需要为其定义一个训练目标和相应的损失函数。\n    这些目标和损失函数应该与任务相关，并帮助模型学习与该任务相关的知识。\n（5）最后，需要将所有子任务组合起来，构建一个完整的模型。每个子任务的输出都将成为下一个子任务的输入，直到完成目标任务。\nchain-of-thought 是一种有效的技巧，可以帮助大型预训练语言模型在多步骤任务和复杂问题中生成连贯的输出。然而，在实际应用中，可能需要结合其他技巧来克服其局限性，以实现更好的性能。\n\n四、对比总结\nPrompt-tuning、instruction-tuning和chain-of-thought都是用于训练大型语言模型的方法，它们都有助于提高模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。\n\nPrompt-tuning：Prompt-tuning是一种使用自然语言提示（prompt）的方法，以指导模型生成特定的输出。这种方法的目的是通过对模型进行定向训练，使其在特定任务上表现出更好的性能。与其他方法不同，Prompt-tuning的重点在于设计良好的提示，这些提示可以引导模型生成准确、上下文相关的响应。\nInstruction-tuning：Instruction-tuning是一种通过为模型提供任务相关的指令来指导模型学习的方法。这种方法的目的是使模型更好地理解任务的要求，并提高其生成能力和上下文理解能力。Instruction-tuning通常需要较少的训练数据，并且可以提高模型的泛化性能。\nChain-of-thought：Chain-of-thought是一种通过分解训练过程为较小的相互关联的任务来训练模型的方法。这种方法的目的是使模型能够理解和维护文本中的思维链，从而生成连贯的、上下文相关的响应。与其他方法不同，Chain-of-thought的重点在于将训练过程分解为一系列逐步更复杂的任务，并使用注意机制来帮助模型集中于相关的部分。\n\n总之，这些方法都有助于提高大型语言模型的生成能力和上下文理解能力，但是它们的方法和目的略有不同。Prompt-tuning和instruction-tuning通常用于特定任务的优化，而Chain-of-thought通常用于提高模型的生成能力和上下文理解能力。\n\n五、GPT-4生成的使用Instruction-Tuning微调GPT-4的案例\nInstruction-tuning 是一种微调大型预训练语言模型（如 GPT-4）的方法，可以让模型根据特定任务提供指令来执行任务。在这个具体的情感分类案例中，我们将使用 instruction-tuning 来对给定的文本进行情感分析。我们的目标是根据文本内容，判断其情感是正面、负面还是中性。以下是一个简单的指南：\n\n准备数据集：\n首先，你需要一个带有标签的文本数据集，以便在情感分类任务上微调模型。数据集应该包含多个实例，每个实例都有一段文本和一个对应的情感标签（正面、负面或中性）。数据集可以是开源的，如 IMDB 电影评论数据集，也可以是你自己收集和标注的数据。\n\n数据预处理：\n将文本和情感标签转换为适用于 GPT-4 模型的格式。例如，将文本和情感标签拼接在一起，用特定的分隔符（如 “|||”）分隔。如下所示：\n文本1|||标签1\n文本2|||标签2\n文本3|||标签3\n\n微调 GPT-4 模型：\n使用准备好的数据集和拼接格式，对 GPT-4 模型进行 instruction-tuning。在训练过程中，模型将学习如何根据输入文本预测相应的情感标签。\n\n模型测试和评估：\n在微调后，使用测试数据集（不包含在训练数据集中的数据）对模型进行测试。输入文本并观察模型生成的情感标签，然后与实际标签进行比较，计算准确率、召回率等性能指标。\n\n使用微调后的模型进行情感分类：\n在实际应用中，当你需要对给定的文本进行情感分类时，可以这样使用微调后的 GPT-4 模型：\n输入：这部电影的剧情令人惊叹，特效也非常出色，我非常喜欢。\n输出：正面\n通过 instruction-tuning，GPT-4 模型能够根据输入文本生成对应的情感标签，从而实现情感分类任务。\n\n\n"},"Chapter2/思维链.html":{"url":"Chapter2/思维链.html","title":"思维链简介","keywords":"","body":"四、思维链——“Let’s think step by step”\n大模型“涌现”的思维链，究竟是一种什么能力？\n\n概述：思维链将一个逻辑推理问题，分解成了多个步骤，来一步步进行，这样生成的结果就有着更加清晰的逻辑链路，提供了一定的可解释性，让人知道答案是怎么来的。\n\n原理：思维链(Chain-of-thought，CoT)，指的是一系列有逻辑关系的思考步骤，形成一个完整的思考过程。\n这种步骤分解的方式用在提示学习中，就被称为思维链提示，将大语言模型的推理过程，分解成一个个步骤，直观地展现出来，这样开发人员可以在LLM推理出现错误时，就及时地修复。\n相当于让AI做分析题，而不是“填空题”，要把推理过程详细说清楚，按步骤得分，最后给出答案。\n\n思维链提示会在给出答案之前，还会自动给出推理步骤\n\n总结：就是把一个多步骤推理问题，分解成很多个中间步骤，分配给更多的计算量，生成更多的token，再把这些答案拼接在一起进行求解。【因式分解】\n\n局限：\n\n思维链必须在模型规模足够大时才能涌现。\n\n策略问题需要大量的世界知识，而小型模型没有足够的参数来记忆这些世界知识，所以也不太可能产生正确的推理步骤。\n\n使有了思维链，大语言模型还是没有真正理解数学逻辑，不知道加减乘除的真实意义，只是通过更精细的叠加来“照葫芦画瓢”，所以，对于有精确要求的任务，还要进一步探索新的技术。\n\n思维链暴露了它，依然是鹦鹉学舌，而非真的产生了意识。\n\n\n\n《精准学习》中提出，缓慢地、理智地、符号化地运作，是人脑的特权。它可以在任何可能的时候，提取具有普遍性、逻辑性的、明确的原则。\n\n\n"},"Chapter1/根据自己数据库让GPT作答.html":{"url":"Chapter1/根据自己数据库让GPT作答.html","title":"根据自己数据库让GPT作答","keywords":"","body":"根据自己数据库让GPT作答\n\napi的token的最大是4096\n官方两种解决方案：Embeddings（嵌入）；Fine-tuning（微调）\n\nFine-tuning（微调）\n\n\n通过提供以下功能，微调可让您从API提供的模型中获得更多信息：\n1 比即时设计更高质量的结果\n2 能够训练更多的例子比可以在提示\n3 由于更短的提示而节省令牌\n4 降低延迟请求\n微调步骤\n步骤：\n1 准备和上传培训数据\n2 训练一个新的微调模型\n3 使用你的微调模型\n微调作用\nFine-tuning（微调）目前仅适用于以下基本型号：davinci、curie、babbage和ada，是预训练模型，一次训练终身受益，适合很久知识都不变且数据集较小的情况；你的训练示例越多越好。我们建议至少有几百个例子。一般来说，我们发现数据集大小的每一次翻倍都会导致模型质量的线性增加\n\nEmbeddings（嵌入）\n\n\nOpenAI的文本嵌入测量文本字符串的相关性。嵌入通常用于：\n1 搜索（其中结果按与查询字符串的相关性进行排名）\n2 聚类（其中文本字符串按相似性分组）\n3 建议（其中建议包含相关文本字符串的项目）\n4 异常检测（其中识别出相关性很小的离群值）\n5 多样性测量（分析相似性分布）\n6 分类（其中文本字符串按其最相似的标签进行分类）\nembedding作用\nEmbeddings（嵌入）无需训练模型，是将自己的预设Pormpt+数据+问题打包，当作一整段话发送给GPT。让GPT根据这个预设的Prompt和灌给的数据再加问题做回答。适合数据量超大且实时更新的一些数据。\n简而言之：在外面包了一层语义搜索，先搜索再打包，最后发给gpt回答。\n目前市场上出现的实时搜索基本也是先在网页搜索后将网页的内容提取出来后，一起打包发给gpt,让其回复，并没有真正的实现联网功能。\n\n解决方案：矢量数据库\n\n\n \n"},"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html":{"url":"Chapter1/训练部署自己的羊驼 Alpaca-LoRA.html","title":"训练部署自己的羊驼 Alpaca-LoRA","keywords":"","body":"训练部署自己的羊驼 Alpaca-LoRA\n参考链接：Gpt进阶（二）:训练部署自己的ChatGPT模型(羊驼 Alpaca-LoRA）\nAlpaca-LoRA(羊驼模型):\n    github.com/tloen/alpaca-lora\nChinese-alpaca-lora（开源的中文数据集）\n    github.com/LC1332/Chinese-alpaca-lora/blob/main/data/trans_chinese_alpaca_data.json\nlora:大型语言模型的低秩适配器;简单来说就是微调模型的另一种方式，来调试模型在具体场景下的准确度；假设模型适应过程中的权重变化也      具有较低的“内在秩”，从而提出了低秩适应(low - rank adaptation, LoRA)方法。\n    论文地址（github）:https://github.com/microsoft/LoRA\n\n\npython环境\n\n\n#网址：https://conda.io/en/latest/miniconda.html\nwget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.1.0-1-Linux-x86_64.sh #下载脚本\nsh Miniconda3-py39_4.12.0-Linux-x86_64.sh     # 执行\n~/miniconda3/bin/conda init                 #初始化Shell，以便直接运行conda\nconda create --name alpaca python=3.9         #关启shell，创建虚拟环境\nconda activate alpaca                         #激活\n\n2 下载羊驼代码\ngit clone https://github.com/tloen/alpaca-lora.git #下载源代码\ncd alpaca-lora\npip install -r requirements.txt                    #安装依赖\n                                                   #测试pytorch\nimport torch\ntorch.cuda.is_available()\n\n3 准备数据集\n构造指令数据集结构，类似于instruct的方法，可参考使用开源的中文数据集：Chinese-alpaca-lora，链接开头已经给出，下载后放到项目根目录下。\n \n4 下载LLaMA基础模型：下载完成后放到根目录下/llama-7b-hf\nhuggingface.co/decapoda-research/llama-7b-hf/tree/main\n5 训练模型\npython finetune.py \\\n    --base_model 'llama-7b-hf' \\\n    --data_path './trans_chinese_alpaca_data.json' \\\n    --output_dir './lora-alpaca-zh'\n\n其他具体参数可以git链接\n模型训练后，lora-alpaca-zh 下就有模型生成了\n6 模型推理\nInference (generate.py)\npython generate.py \\\n    --load_8bit \\\n    --base_model 'decapoda-research/llama-7b-hf' \\\n    --lora_weights 'tloen/alpaca-lora-7b'\n\n7 云端部署\n使用kaggle部署模型，访问web交互\n地址：www.kaggle.com/models\n \n"},"Chapter1/训练部署自己的ChatGLM-6B.html":{"url":"Chapter1/训练部署自己的ChatGLM-6B.html","title":"训练部署自己的ChatGLM-6B","keywords":"","body":"训练部署自己的ChatGLM-6B\n参考链接：【实战讲解】ChatGLM-6B模型训练完整流程详解\n本文实现了基于 P-Tuning v2 的高效参数微调方法，通过实际动手操作，提升对大模型的理解和应用能力。\nChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。\n\n\nconda环境\n\n\n下载miniconda，选择匹配的操作系统的版本，\n从官网ttps://docs.conda.io/en/latest/miniconda.html下载。\n$ sh Miniconda3-latest-***.sh\n\n构建虚拟环境\n$ conda create -n chatglm   --clone base      # 创建新环境\n$ source activate chatglm                      # 激活环境\n$ conda env list                                #显示环境列表\n\n2 下载代码&安装依赖\n$ git clone https://github.com/THUDM/ChatGLM-6B.git\n$ cd ChatGLM-6B\n\n安装依赖\n$ pip install -r requirements.txt\n$ pip install rouge_chinese nltk jieba datasets\n\n3 模型和数据准备\n对于ChatGLM-6B模型的训练，需要准备相应的数据集。使用ADGEN数据集，其任务为根据输入（content）生成一段广告词（summary）。下载ADGEN数据集，从 Google Drive 或者 Tsinghua Cloud 下载处理好的 ADGEN 数据集，将解压后的 AdvertiseGen 目录放到本目录下。\n模型下载, 从 Hugging Face Hub 下载模型需要先安装Git LFS，然后运行\n$ yum install git-lfs\n$ cd /data/pre_model/chatglm\n$ git clone https://huggingface.co/THUDM/chatglm-6b\n\n训练数据下载存放路径：\n$ cd /data/train_data/ChatGLM-6B/ptuning \n$ wget https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1\n\n训练数据示例：\n$ head train.json\n{\"content\": \"类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤\", \"summary\": \"宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。\"}\n\n评估数据示例：\n$ head dev.json\n{\"content\": \"类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞\", \"summary\": \"简约而不简单的牛仔外套，白色的衣身十分百搭。衣身多处有做旧破洞设计，打破单调乏味，增加一丝造型看点。衣身后背处有趣味刺绣装饰，丰富层次感，彰显别样时尚。\"}\n\n5 训练模型\n模型训练可以使用一些机器学习框架，PyTorch。使用预训练模型来初始化ChatGLM-6B，然后通过P-Tuning v2 的高效参数微调进行训练。需要考虑到训练时间和硬件资源的因素\ntrain.sh 中的 PRE_SEQ_LEN 和 LR 分别是 soft prompt 长度和训练的学习率，可以进行调节以取得最佳的效果。\nP-Tuning-v2 方法会冻结全部的模型参数，可通过调整 quantization_bit 来被原始模型的量化等级，不加此选项则默认为 FP16 精度加载。\n如果你想要从本地加载模型，可以将 train.sh 中的 THUDM/chatglm-6b 改为你本地的模型路径。\n\n1、训练脚本train.sh如下：\n$ cat train.sh\nPRE_SEQ_LEN=8\nLR=2e-2\nCUDA_VISIBLE_DEVICES=0 python3 main.py \\\n    --do_train \\\n    --train_file AdvertiseGen/train.json \\\n    --validation_file AdvertiseGen/dev.json \\\n    --prompt_column content \\\n    --response_column summary \\\n    --overwrite_cache \\\n    --model_name_or_path ../../../pre_model/chatglm/chatglm-6b \\\n    --output_dir ./output/adgen-chatglm-6b-pt-$PRE_SEQ_LEN-$LR \\\n    --overwrite_output_dir \\\n    --max_source_length 64 \\\n    --max_target_length 64 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 16 \\\n    --predict_with_generate \\\n    --max_steps 3000 \\\n    --logging_steps 10 \\\n    --save_steps 1000 \\\n    --learning_rate $LR \\\n    --pre_seq_len $PRE_SEQ_LEN \\\n    --quantization_bit 4\n\n2、开始训练,后台执行：\n$ nohup  sh train.sh &\n\n3、训练结束，查看结果，max_steps 3000，训练40分钟完成 \n$ tail nohup.out\n{'loss': 7.1214, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.42}\n{'loss': 7.088, 'learning_rate': 0.0, 'epoch': 0.42}\n{'train_runtime': 2402.1329, 'train_samples_per_second': 19.982, 'train_steps_per_second': 1.249, 'train_loss': 8.597134847005208, 'epoch': 0.42}\n\n***** train metrics *****\n  epoch                    =       0.42\n  train_loss               =     8.5971\n  train_runtime            = 0:40:02.13\n  train_samples            =     114599\n  train_samples_per_second =     19.982\n  train_steps_per_second   =      1.249\n\n4、查看训练生成的模型文件及模型结果\n$ ls  /data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2\nall_results.json  checkpoint-1000  checkpoint-2000  checkpoint-3000  trainer_state.json  train_results.json\n\n$ cat  all_results.json\n{\n    \"epoch\": 0.42,\n    \"train_loss\": 8.597134847005208,\n    \"train_runtime\": 2402.1329,\n    \"train_samples\": 114599,\n    \"train_samples_per_second\": 19.982,\n    \"train_steps_per_second\": 1.249\n}\n\n$ cat train_results.json\n{\n    \"epoch\": 0.42,\n    \"train_loss\": 8.597134847005208,\n    \"train_runtime\": 2402.1329,\n    \"train_samples\": 114599,\n    \"train_samples_per_second\": 19.982,\n    \"train_steps_per_second\": 1.249\n}\n\n$ ls  /data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2/checkpoint-3000\nconfig.json generation_config.json  modeling_chatglm.py  pytorch_model.bin  rng_state.pth  special_tokens_map.json  tokenizer_config.json  training_args.bin\nconfiguration_chatglm.py  ice_text.model optimizer.pt quantization.py \n1、训练脚本train.sh如下：\n$ cat train.sh\nPRE_SEQ_LEN=8\nLR=2e-2\n\nCUDA_VISIBLE_DEVICES=0 python3 main.py \\\n    --do_train \\\n    --train_file AdvertiseGen/train.json \\\n    --validation_file AdvertiseGen/dev.json \\\n    --prompt_column content \\\n    --response_column summary \\\n    --overwrite_cache \\\n    --model_name_or_path ../../../pre_model/chatglm/chatglm-6b \\\n    --output_dir ./output/adgen-chatglm-6b-pt-$PRE_SEQ_LEN-$LR \\\n    --overwrite_output_dir \\\n    --max_source_length 64 \\\n    --max_target_length 64 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --gradient_accumulation_steps 16 \\\n    --predict_with_generate \\\n    --max_steps 3000 \\\n    --logging_steps 10 \\\n    --save_steps 1000 \\\n    --learning_rate $LR \\\n    --pre_seq_len $PRE_SEQ_LEN \\\n    --quantization_bit 4\n\n2、开始训练,后台执行：\n$ nohup  sh train.sh &\n\n3、训练结束，查看结果，max_steps 3000，训练40分钟完成 \n$ tail nohup.out\n{'loss': 7.1214, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.42}\n{'loss': 7.088, 'learning_rate': 0.0, 'epoch': 0.42}\n{'train_runtime': 2402.1329, 'train_samples_per_second': 19.982, 'train_steps_per_second': 1.249, 'train_loss': 8.597134847005208, 'epoch': 0.42}\n***** train metrics *****\n  epoch                    =       0.42\n  train_loss               =     8.5971\n  train_runtime            = 0:40:02.13\n  train_samples            =     114599\n  train_samples_per_second =     19.982\n  train_steps_per_second   =      1.249\n\n4、查看训练生成的模型文件及模型结果\n$ ls  /data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2\nall_results.json  checkpoint-1000  checkpoint-2000  checkpoint-3000  trainer_state.json  train_results.json\n\n$ cat  all_results.json\n{\n    \"epoch\": 0.42,\n    \"train_loss\": 8.597134847005208,\n    \"train_runtime\": 2402.1329,\n    \"train_samples\": 114599,\n    \"train_samples_per_second\": 19.982,\n    \"train_steps_per_second\": 1.249\n}\n\n$ cat train_results.json\n{\n    \"epoch\": 0.42,\n    \"train_loss\": 8.597134847005208,\n    \"train_runtime\": 2402.1329,\n    \"train_samples\": 114599,\n    \"train_samples_per_second\": 19.982,\n    \"train_steps_per_second\": 1.249\n}\n\n$ ls  /data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2/checkpoint-3000\nconfig.json generation_config.json  modeling_chatglm.py  pytorch_model.bin  rng_state.pth  special_tokens_map.json  tokenizer_config.json  training_args.bin\nconfiguration_chatglm.py  ice_text.model optimizer.pt  quantization.py scheduler.pt   tokenization_chatglm.py  trainer_state.json\n\n6 模型评估\n训练完成后，需要进行模型评估和调整。可以使用一些指标来评估模型的性能。\n将 evaluate.sh 中的 CHECKPOINT 更改为训练时保存的 checkpoint 名称，\n运行以下指令进行模型推理和评测：bash evaluate.sh。\n生成的结果保存在 ./output/adgen-chatglm-6b-pt-8-1e-2/generated_predictions.txt。\n\n1、模型文件\n/data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2/checkpoint-3000\n\n2、执行评测脚本， sh evaluate.sh\n评测样本示例：\nQuantized to 4 bit\ninput_ids [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 65421, 61, 75898, 32, 68554, 61, 77257, 64555, 32, 65107, 61, 66268, 32, 65347, 61, 71689, 32, 69768, 61, 85428, 32, 65173, 73942, 61, 70984, 32, 65173, 70936, 61, 64703, 65509, 130001, 130004]\n\ninputs 类型#上衣*材质#牛仔布*颜色#白色*风格#简约*图案#刺绣*衣样式#外套*衣款式#破洞\nlabel_ids [5, 71689, 66561, 67061, 77257, 70984, 6, 72194, 65173, 64290, 64622, 81549, 63823, 65173, 64290, 83343, 63832, 63912, 65209, 64703, 65509, 64051, 6, 69418, 78598, 87019, 6, 64257, 71319, 66069, 74197, 63823, 65173, 72265, 64880, 64131, 63832, 73416, 85428, 66261, 6, 65594, 87834, 6, 73412, 105145, 65388, 63823, 130001, 130004]\n\nlabels 简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。\n\n3、查看评测脚本\n$ cat evaluate.sh\nPRE_SEQ_LEN=8\nCHECKPOINT=adgen-chatglm-6b-pt-8-2e-2\nSTEP=3000\nCUDA_VISIBLE_DEVICES=0 python3 main.py \\\n    --do_predict \\\n    --validation_file AdvertiseGen/dev.json \\\n    --test_file AdvertiseGen/dev.json \\\n    --overwrite_cache \\\n    --prompt_column content \\\n    --response_column summary \\\n    --model_name_or_path ../../../pre_model/chatglm/chatglm-6b \\\n    --ptuning_checkpoint ./output/$CHECKPOINT/checkpoint-$STEP \\\n    --output_dir ./output/$CHECKPOINT \\\n    --overwrite_output_dir \\\n    --max_source_length 64 \\\n    --max_target_length 64 \\\n    --per_device_eval_batch_size 1 \\\n    --predict_with_generate \\\n    --pre_seq_len $PRE_SEQ_LEN \\\n    --quantization_bit 4\n\n4、查看评测结果：\n$ cd /data/train_data/ChatGLM-6B/ptuning/output/adgen-chatglm-6b-pt-8-2e-2\n$ cat generated_predictions.txt\n{\"labels\": \"简约而不简单的牛仔外套,白色的衣身十分百搭。衣身多处有做旧破洞设计,打破单调乏味,增加一丝造型看点。衣身后背处有趣味刺绣装饰,丰富层次感,彰显别样时尚。\", \"predict\": \"修身修身的UNK>,这款UNK>感感,加上加上性感的面料,展现气质,整体整体整体性感,展现彰显修饰修饰的UNK>。加上加上气质,让简约设计,穿着穿着设计,搭配搭配。\"}\n\n7 模型部署\n当模型训练和评估完成后，可以将它部署到适当的平台上。\n在部署时，可以考虑到模型的可用性、可扩展性和性能等因素。\n本次只是演示，使用部署脚本加载本地模型,并加载新的Checkpoint。\n注意需要将 pre_seq_len 改成你训练时的实际值，具体部署验证演示代码如下：\n\n1、执行部署脚本\n$ python deploy.py\n\n2、查看部署脚本\n$ cat deploy.py\n\nimport os\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nimport torch\nmodel_name = \"../../../pre_model/chatglm/chatglm-6b\"                     # 模型名 或 模型路径\ncheckpoint_path = \"./output/adgen-chatglm-6b-pt-8-2e-2/checkpoint-3000\" # 模型checkpoint路径\npre_seq_len = 8                                                         # 模型前缀长度 跟你训练的PRE_SEQ_LEN一致\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nconfig = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\nconfig.pre_seq_len = pre_seq_len\nmodel = AutoModel.from_pretrained(model_name, config=config, trust_remote_code=True)\nprefix_state_dict = torch.load(os.path.join(checkpoint_path, \"pytorch_model.bin\"))\nnew_prefix_state_dict = {}\nfor k, v in prefix_state_dict.items():\n    new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]] = v\nmodel.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)\nmodel.half().cuda()\nprint(model.chat(tokenizer, \"你是谁\"))\n\n"},"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html":{"url":"Chapter1/Windows+6GB显卡版本和CPU版本的本地部署ChatGLM-6B.html","title":"Windows+6GB显+CPU本地部署ChatGLM-6B.md","keywords":"","body":"训练部署自己的ChatGLM-6B\n参考链接：手把手教你本地部署清华大学KEG的ChatGLM-6B模型——Windows+6GB显卡版本和CPU版本的本地部署 \n安装前说明\n部署前安装环境\n    1、下载官方代码，安装Python依赖的库\n    2、下载INT4量化后的预训练结果文件\nWindows+GPU部署方案\n    1、Windows+GPU方案的必备条件\n    2、运行部署GPU版本的INT4量化的ChatGLM-6B模型\nWindows+CPU部署方案\n    1、Windows+CPU方案的必备条件\n    2、运行部署CPU版本的INT4量化的ChatGLM-6B模型\n总结\n\n一、windows+GPU6G\n\n部署前安装环境\n\n\n部署前安装环境\n首先，我们需要从GitHub上下载ChatGLM的requirements.txt来帮助我们安装依赖的库。\n在GitHub上下载requirements.txt即可。下载地址：https://github.com/THUDM/ChatGLM-6B\n\n安装依赖：\npip install -r requirements.txt\n其中 transformers 库版本必须是4.27.1及以上的版本才可以\n\n另外，ChatGLM-6B依赖torch，如果你有GPU，且高于6G内存，那么建议部署GPU版本，\n但是需要下载支持cuda的torch，而不是默认的CPU版本的torch。\n\n2 下载INT4量化后的预训练结果文件\nINT4量化的预训练文件下载地址：https://huggingface.co/THUDM/chatglm-6b-int4/tree/main\n\n需要注意的是，在GitHub上，官方提供了模型在清华云上的下载地址，但是那个只包含预训练结果文件即bin文件，\n但实际上ChatGLM-6B的运行需要模型的配置文件，即config.json等。\n因此建议全部从HuggingFace上下载所有文件到本地。\n上述文件全部下载之后保存到本地的一个目录下即可，我们保存在：D:\\\\chatglm-6b-int4\n\n3 Windows+GPU部署方案\n对于ChatGLM-6B模型的训练，需要准备相应的数据集。使用ADGEN数据集，其任务为根据输入（content）生成一段广告词（summary）。下载ADGEN数据集，从 Google Drive 或者 Tsinghua Cloud 下载处理好的 ADGEN 数据集，将解压后的 AdvertiseGen 目录放到本目录下。\n部署GPU版本的ChatGLM-6B需要安装cuda版本的torch，\n需要检测自己的torch是否正确，可以通过如下命令检查（下面是python代码）：\nimport torch\nprint(torch.cuda.is_available())\n如果以上代码输出的是True，那么恭喜你，你安装的是cuda版本的torch\n（注意，有显卡也需要下载cuda和cudann安装成功才可以，这部分可以去网上找教程）。\n\n注意，目前ChatGLM-6B有3个版本可以使用，\n没有量化的版本做推理需要13G的GPU显存，INT8量化需要8GB的显存，而INT4量化的版本需要6GB的显存。\n注意：模型量化会带来一定的性能损失，经过测试，ChatGLM-6B 在 4-bit 量化下仍然能够进行自然流畅的生成。\n\n4 运行部署GPU版本的INT4量化的ChatGLM-6B模型\nGPU版本的模型部署很简单，上述两个步骤完成之后即可运行。代码如下：\nfrom transformers importAutoTokenizer,AutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\", trust_remote_code=True, revision=\"\")\nmodel =AutoModel.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\", trust_remote_code=True, revision=\"\").half().cuda()\nmodel = model.eval()\nresponse, history = model.chat(tokenizer,\"你好\", history=[])\nprint(response)\n\n通过以上步骤我们可以得到如下结果：GPU版本大约只需要1-2秒即可获得结果\n \n\n二、windows+CPU\n1. GCC编译环境配置+kernel编译\nCPU版本的ChatGLM-6B部署比GPU版本稍微麻烦一点，主要涉及到一个kernel的编译问题。\n在安装之前，除了上面需要安装好requirements.txt中所有的Python依赖外，torch需要安装好正常的CPU版本即可。\n但是，除了这些CPU版本的安装还需要在本地的Windows下安装好C/C++的编译环境。推荐安装TDM-GCC，下载地址：https://jmeubank.github.io/tdm-gcc/\n直接点击上述页面中TDM-GCC 10.3.0 release下载安装即可，注意安装的时候直接选择全部安装就好。\n安装完在cmd中运行”gcc -v”测试是否成功即可。\n\n \n注：安装这个主要是为了编译之前下载的文件中的quantization_kernels.c和quantization_kernels_parallel.c这两个文件。\n如果在运行中遇到了如下错误提示：\nNo compiled kernel found.\nCompiling kernels : C:\\Users\\DuFei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm-6b-int4\\quantization_kernels_parallel.c\nCompiling gcc -O3 -fPIC -pthread -fopenmp -std=c99 C:\\Users\\DuFei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm-6b-int4\\quantization_kernels_parallel.c -shared -o C:\\Users\\DuFei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm-6b-int4\\quantization_kernels_parallel.so\nKernels compiled : C:\\Users\\DuFei\\.cache\\huggingface\\modules\\transformers_modules\\chatglm-6b-int4\\quantization_kernels_parallel.so\nCannot load cpu kernel, don't use quantized model on cpu.\nUsing quantization cache\nApplying quantization to glm layers\n\n那么就是这两个文件编译出问题了。那么就需要我们手动去编译这两个文件：\n即在上面下载的D:\\\\data\\\\llm\\\\chatglm-6b-int4本地目录下进入cmd，运行如下两个编译命令：\ngcc -fPIC -pthread -fopenmp -std=c99 quantization_kernels.c -shared -o quantization_kernels.so\ngcc -fPIC -pthread -fopenmp -std=c99 quantization_kernels_parallel.c -shared -o quantization_kernels_parallel.so\n\n \n然后就可以在D:\\\\data\\\\llm\\\\chatglm-6b-int4目录下看到下面两个新的文件：\nquantization_kernels_parallel.so和quantization_kernels.so。说明编译成功，后面我们手动载入即可。\n2. 运行部署CPU版本的INT4量化的ChatGLM-6B模型\nfrom transformers importAutoTokenizer,AutoModel\ntokenizer =AutoTokenizer.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\", trust_remote_code=True, revision=\"\")\nmodel =AutoModel.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\",trust_remote_code=True, revision=\"\").float()\nmodel = model.eval()\nresponse, history = model.chat(tokenizer,\"你好\", history=[])\nprint(response)\n\n注意，其实就是第三行代码最后的float()有差异：GPU版本后面是.half().cuda()，而这里是float()。\nmodel =AutoModel.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\", trust_remote_code=True, revision=\"\").float()\n\n3. 如果你运行上面的代码出现如下错误\nAttributeError:'NoneType'object has no attribute 'int4WeightExtractionFloat'\n那么就是前面说的编译文件出了问题，那么就必须做上面说的编译操作，得到那2个so文件，然后手动加载。新代码如下：\nfrom transformers importAutoTokenizer,AutoModel\ntokenizer =AutoTokenizer.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\", trust_remote_code=True, revision=\"\")\nmodel =AutoModel.from_pretrained(\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\",trust_remote_code=True, revision=\"\").float()\nmodel = model.quantize(bits=4, kernel_file=\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\\\\quantization_kernels.so\")\nmodel = model.eval()\nresponse, history = model.chat(tokenizer,\"你好\", history=[])\nprint(response)\n\n比原来的代码多了model = model.quantize(bits=4, kernel_file=\"D:\\\\data\\\\llm\\\\chatglm-6b-int4\\\\quantization_kernels.so\")一行手动加载的内容。\n \n注：CPU版本的模型推理运行一次约1-2分钟，实在是太慢了，基本不适合使用。有机会还是搞GPU版本吧！\n"},"Chapter3/Self-Instruct数据.html":{"url":"Chapter3/Self-Instruct数据.html","title":"Self-Instruct自动生成微调数据","keywords":"","body":"三、Self-Instruct\n参考链接：\n轻松打造家用版GPT-4！微软开源微调指令集：效果不输原版，中英双语都能用\n微调数据链接：https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\n论文链接：https://arxiv.org/pdf/2304.03277.pdf\n\n\n使用GPT-4模型来自动生成语言模型所需的微调指令数据。GPT-4生成的instruction-following数据表现出更强大的对齐性能。\n中文Instruction-Following Data：使用ChatGPT将5.2万条指令翻译成中文，并要求GPT-4用中文回答这些指令，并以此建立一个基于LLaMA的中文instruction-following模型，并研究指令调优的跨语言泛化能力。\n对比数据（Comparison Data）：要求GPT-4对自己的回复提供从1到10的评分，并对GPT-4, GPT-3.5和OPT-IML这三个模型的回复进行评分，以训练奖励模型。\n研究人员基于LLaMA 7B checkpoint有监督微调后训练得到了两个模型：LLaMA-GPT4是在GPT-4生成的5.2万条英文instruction-following数据上训练的；LLaMA-GPT4-CN是在GPT-4的5.2万条中文instruction-following数据上训练的。\n奖励模型：研究人员使用GPT-4创建了对比数据；为了评估数据质量，研究人员训练一个基于OPT 1.3B的奖励模型，以对不同的回复进行评分：对一个提示和K个回复，GPT-4为每个回复提供一个1到10之间的评分。\n效果评估：人类评估3H标准。基于HHH对齐标准，研究人员使用众包平台Amazon Mechanical Turk对模型生成结果进行人工评估。\n\n帮助性（helpfulness）：是否能帮助人类实现他们的目标，一个能够准确回答问题的模型是有帮助的。\n诚实性（honesty）：是否提供真实信息，并在必要时表达其不确定性以避免误导人类用户，一个提供虚假信息的模型是不诚实的。\n无害性（harmlessness）：是否不会对人类造成伤害，一个产生仇恨言论或提倡暴力的模型不是无害的。\n \nGPT-4自动评估：受 Vicuna 的启发，研究人员也选择用GPT-4来评估不同聊天机器人模型对80个未见过的问题所生成回答的质量，从 LLaMA-GPT-4(7B)和 GPT-4模型中收集回复，并从以前的研究中获得其他模型的答案，然后要求GPT-4对两个模型之间的回复质量进行评分，评分范围从1到10，并将结果与其他强竞争模型(ChatGPT 和 GPT-4)进行比较。\n结果显示：反馈数据和奖励模型对提高 LLaMA 的性能是有效的；用GPT-4对LLaMA进行指令调优，往往比用text-davinci-003调优（即Alpaca）和不调优（即LLaMA）的性能更高；7B LLaMA GPT4的性能超过了13B Alpaca和LLaMA，但和GPT-4等大型商业聊天机器人相比，仍有差距。\n \n非自然指令评估（Unnatural Instruction Evaluation）：从平均ROUGE-L得分来看，Alpaca优于LLaMA-GPT 4和GPT-4，可以注意到，LLaMA-GPT4和GPT4在ground truth回复长度增加时逐渐表现得更好，最终在长度超过4时表现出更高的性能，意味着当场景更具创造性时，可以更好地遵循指令。\n\n仅就GPT-4的结果而言，翻译后的回复比中文生成的回复表现得更好，可能是因为GPT-4是在比中文更丰富的英文语料库中训练的，所以具有更强的英文instruction-following能力。\n\n"},"Chapter3/学术问答数据集调研.html":{"url":"Chapter3/学术问答数据集调研.html","title":"学术问答数据集调研","keywords":"","body":"一、hotpotQA：HotpotQA Homepage\n\n数据集链接：http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json\n数据规模：训练集535M，测试集46M，开发集100M\n\n数据描述：HotpotQA 是一个问答数据集，具有自然的多跳问题，对支持事实进行强有力的监督，以实现更可解释的问答系统。\n它由卡内基梅隆大学、斯坦福大学和蒙特利尔大学的 NLP 研究人员团队收集。【英文】\n\n数据格式\n\n\n \n\n二、SQuAD2数据集：斯坦福问答数据集 (rajpurkar.github.io)\n\n数据集链接：训练集[https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json]；开发集[https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json]\n数据规模：15万+ QA对\n数据描述：Stanford Question Answering Dataset（SQuAD）是一个阅读理解数据集，由众包工作者在一组维基百科条目上提出的问题组成，其中每个问题的答案是相应阅读段落中的一段文本或跨度，或者问题可能无法回答。【英文】【维基百科】\n数据格式：\n\n \n\n三、NatualQuestions：https://ai.google.com/research/NaturalQuestions/visualization\n\n数据集链接：训练集[https://storage.cloud.google.com/natural_questions/v1.0-simplified/simplified-nq-train.jsonl.gz]、开发集[https://storage.cloud.google.com/natural_questions/v1.0-simplified/nq-dev-all.jsonl.gz]\n数据规模：41Gb 训练集、1GB开发集\n数据描述：NQ语料库包含来自真实用户的问题，它要求QA系统阅读和理解整个维基百科文章，其中可能包含也可能不包含问题的答案。包含真实的用户问题，以及解决方案应阅读整个页面以找到答案的要求，使 NQ 成为一项比以前的 QA 数据集更现实、更具挑战性的任务。【维基百科】【英文】\n\n数据格式：\n\n\n \n\n四、中文法律问答数据集：CAIL2019\n\n数据集链接：CAIL2019/阅读理解/data at master · china-ai-law-challenge/CAIL2019 · GitHub\n数据规模：30m左右\n数据描述：数据集是来自“中国裁判文书网”公开的法律文书，主要涉及民事和刑事的一审判决书，总共约1万份数据，并按比例划分训练、开发和测试。每份数据包括若干个问题，对于训练集，每个问题只包含一个标准回答，对于开发和测试集，每个问题包含3个标准回答。回答内容可以是案情片段，可以是YES或NO，也可以拒答即回答内容为空。数据格式参考SquAD2.0的数据格式，整体为json格式的数据。并增设案由\"casename\"字段和领域\"domain\"字段，\"domain\"字段只有\"civil\"和\"criminal\"两种类型。\"context\"抽取自裁判文书的案情描述或原告诉称部分。【裁判文书网】【中文】\n数据格式：\n\n\n\n五、PubMedQA：医学问答数据集\n\n数据集链接：PubMedQA Homepage\n数据规模： 1k 个专家标记、61.2k 个未标记和 211.3k 个人工生成的 QA 实例。\n数据描述：PubMedQA的任务是使用相应的摘要回答是/否/也许的研究问题（例如：术前他汀类药物是否会减少冠状动脉旁路移植术后的心房颤动？\n数据格式：\n\n\n\n六、Qasper：卡斯珀 (allenai.org)\n\n数据集链接：https://qasper-dataset.s3.us-west-2.amazonaws.com/qasper-train-dev-v0.3.tgz\n数据规模：一个包含 1585 篇论文的数据集，其中包含 5049 个QA问题\n数据描述：一个包含 1585 篇论文的数据集，其中包含 5049 个QA问题\n数据格式\n\n \n\n七、SciQ Dataset：科学问答数据集\n\n数据集链接：https://ai2-public-datasets.s3.amazonaws.com/sciq/SciQ.zip\n数据规模：不大\n数据描述：包含13679个关于物理，化学和生物学等的众包科学考试问题。这些问题采用多项选择题格式，每个选项有 4 个答案选项\n数据格式\n\n[\n    {\n        \"question\": \"Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\",\n        \"distractor3\": \"residues\",\n        \"distractor1\": \"antioxidants\",\n        \"distractor2\": \"Oxygen\",\n        \"correct_answer\": \"oxidants\",\n        \"support\": \"Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\"\n    }\n]\n\n八、其他公开领域的数据集链接：\n\n知识类问答数据集资源对外开放：百万级百度知道、社区问答及六大领域级小规模语料概述\n千言（LUGE）| 全面的中文开源数据集合\n\n \n\nDureader：一个大规模的中文阅读理解数据集，包含三个子任务：机器阅读理解、搜索式问答和多文档阅读理解。数据来源于百度搜索引擎和百度知道。【百度】【中文】Machine Reading Comprehension - 飞桨AI Studio (baidu.com)\n\nWebQuestions：一个开放领域问答数据集，包含5,810个问题和答案，基于Google Suggest API生成的问题和Freebase实体作为答案。WebQuestions Benchmark for Question Answering (codalab.org)\n\nTriviaQA：一个问答数据集，包含65万多个问题和答案，基于维基百科和网络搜索结果。每个问题都是一个有趣的事实，每个答案都是一个实体或数字。http://nlp.cs.washington.edu/triviaqa/\n\n\n九、ChatGPT使用的训练数据集——来自bing\nchatGPT是一个基于GPT-3的对话生成模型，使用了OpenAI API提供的数据集和模型来训练。根据OpenAI API的文档，chatGPT使用的训练数据集有：\n    cc_sbu_align：一个包含4K个对话的数据集，基于MiniGPT-4数据集。\n    blended_skill_talk：一个包含7K个对话的数据集，设计为展示多种对话模式，如展示个性、表达同理心和展示知识。\n    GSM-IC：一个包含8K个对话的数据集，涉及到小学数学问题和无关上下文。\n    ChatAlpaca：一个包含10K个对话的数据集，由ChatGPT生成。\n    Dolly：一个包含15K个对话的数据集，由Databricks员工生成，用于训练大型语言模型。\n    WebGPT：一个包含20K个对话的数据集，由WebGPT项目生成。\n    Code Alpaca：一个包含20K个代码生成任务的数据集。\n    HC3：一个包含37K个指令的数据集，由ChatGPT和人类生成，涉及中英文。\n    Alpaca Dataset：一个包含52K个指令的数据集，由OpenAI API提供。\n    Finance：一个包含69K个金融相关指令的数据集。\n    evol：一个包含70K个对话的数据集，是WizardLM的训练数据。\n    Vicuna Dataset：一个包含75K个对话的数据集，基于ShareGPT对话。\n    InstructionTranslation：一个包含80K个多语言指令翻译任务的数据集，由M2M 12B生成。\n    Self-Instruct：一个包含82K个指令输入输出实例的数据集。\n    OASST1：一个包含89K个多语言助理风格对话的数据集，由人类生成和标注。\n    HH-RLHF：一个包含91K个对话的数据集，用于从人类反馈中进行强化学习。\n\ntodo——构建数据集：构建retrieval数据集；匹配模型优化——对比学习预训练、度量学习；大模型prompt【用户查询】\n根据已有的样本，摘要喂给GPT4进行self-instruct\n"},"Chapter4/Lamini.html":{"url":"Chapter4/Lamini.html","title":"Lamini LLM引擎学习","keywords":"","body":"Lamini LLM引擎学习\n相关链接：神奇LLM引擎上线！帮你把GPT-3直接调成ChatGPT\n \n项目地址：https://lamini.ai/\n产品定位：\n（1）Lamini 将微调封装成一种服务，使开发人员可以轻松将 GPT-3 微调成 ChatGPT。供开发人员使用很多公司、机构的基础模型快速构建定制化模型。\n（2）Lamini 提供了一种托管化的数据生成器，只需执行 Lamini 库中的几行代码，用户就能训练自己的大型语言模型（LLM）及其权重，而无需使用任何 GPU。\n\n\n简介\n\n\n \n\n作用\n\n\n \n1. 对 ChatGPT 或其他模型进行 prompt 调整。\nLamini 库的 API 提供快速调优功能，只需一行代码即可在 OpenAI 的模型和其他开源模型之间切换。Lamini 库还提供了优化之后的正确 prompt，以便于用户根据模型设置不同格式的 prompt。\n\n2. 构建一个输入输出对的大型数据集。\n该数据集将让模型理解它应如何响应其输入。使用 Lamini 引擎，用户可以仅用几行代码就快速从 100 个数据点生成 50k 数据点，而无需启动任何 GPU。Lamini 也提供了一个 50k 的开源数据集。\n\n3. 在数据集上微调基础模型。\nLamini 的研究团队在其 50k 的开源数据集上微调出一个 LLM，后续他们将发布执行此操作的功能和代码。\n\n4. 在经过微调的模型上运行 RLHF。Lamini 库让用户不再需要大型 ML 和人工标记团队来运行 RLHF。\n\n5. 方便用户将模型部署到云端。\n\n数据生成器\n\n\nLamini 提供了一个托管数据生成器，只需几行代码即可将 100 个样本变成超过 50k 个样本，而不需要启动任何 GPU，并且生成的数据是商业可用的。用户可以自定义最初的 100 多条指令，以便生成的 5 万条符合要求的指令，最终得到一个大型指令遵循数据集。\nLamini 的数据生成器是一个 LLM pipeline，其灵感来自斯坦福的开源模型 Alpaca。这个生成 pipeline 使用 Lamini 库来定义和调用 LLM，以生成不同但相似的指令 - 响应对。\n"},"Chapter4/GPT与知识图谱.html":{"url":"Chapter4/GPT与知识图谱.html","title":"GPT与知识图谱","keywords":"","body":"Lamini LLM引擎学习\n相关链接：再谈知识图谱与ChatGPT如何结合：参数化与形式化知识库的现实问题、结合要素和具体路线\n  \n知识图谱，可以利用prompt，参与到大模型的训练前的数据构造，训练中的任务，以及训练后推理结果的约束生成，提升大模型的性能。\n大模型，可以通过prompt，来执行相应信息提取以及思维链的推理任务，形式化成不同形式的知识【例如三元组，多元组或者事件链条】。\n\n1. 知识图谱VS大语言模型\n相同点：知识图谱VS大语言模型本质上都是一种知识库；chatgpt遇到的事实性错误和时效性，知识图谱同样存在，知识图谱也需要解决知识更新的问题。 \n不同点：\n知识图谱是一种知识的形式化表示方式，大语言模型(ChatGPT)是参数化的知识。\n知识图谱是一种知识的形式化表示方式，大语言模型(ChatGPT)是参数化的知识。\n结构化知识很难构建(因为要设计知识的结构体系)，但易于推理(因为有体系结构)，非结构化知识易于构建(直接存 起来就行)，但很难用于推理(没有体系结构)。\n"},"Chapter4/Entailment Trees论文学习笔记.html":{"url":"Chapter4/Entailment Trees论文学习笔记.html","title":"Entailment Trees论文学习笔记","keywords":"","body":"Explaining Answers with Entailment Trees\n\n一、摘要\n1.在开放域文本问答的背景下，的目标是通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。\n2.的方法是以蕴涵树的形式生成解释，即多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设（即问题+答案）。\n3.为了用这种技能训练模型，创建了 ENTAILMENT BANK ，这是第一个包含多步蕴涵树的数据集。\n\n给定一个假设（问题+答案），定义了三个越来越难的解释任务：为给定的 QA 对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c) 完整的语料库。\n5.研究结果表明，强大的语言模型可以部分解决这些任务，特别是当相关句子包含在输入中时，并且有泛化到其他领域的迹象。这项工作意义重大，因为它提供了一种新型数据集（多步蕴涵）和基线，为社区提供了一条新途径，以产生更丰富、更系统的解释。\n\n\n二、 Introduction\n1.今天的解释系统擅长为答案提供一两句话的支持证据（“基本原理”）（DeY oung 等人，2019），但它们很少从什么解释推理链已知答案，即在给出证据的情况下，答案是如何得出的——这项工作的目标。\n2.本文方法是以多步蕴涵树的形式生成解释，如图 1 所示，由单个多前提文本蕴涵 (TE) 步骤组成，尽管有许多可用的单步蕴涵数据集，但是目前不存在多步蕴涵数据集，\n3.因此本文的一个重要贡献是构建了这样一个数据集，称为 ENTAILMENT BANK。 ENTAILMENT BANK 包含 1,840 个用于伴随 QA 对的多步蕴涵树，使用专家注释器构建，是同类数据集中的首个。\n4.本文还在这个数据集上定义了三个解释任务，即：为给定的 QA 对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c) 完整的语料库。\n5.研究重点是生成推理线，以显示证据如何生成的答案，而不是决定将哪些部分显示给用户。这使能够将两个解释要求，即推导的正确性与效用分开，使能够以更客观的度量评估推导。\n三、贡献\n为这项任务定义和训练称为 EntailmentWriters 生成模型，采用早期技术来生成演绎证明。发现这些模型部分地解决了数据集，并具有泛化到其他领域的迹象。因此，的贡献是：\n• 将解释表述为多步骤、多前提的文本蕴涵。\n• ENTAILMENT BANK，第一个用于 QA 的多步蕴涵树数据集，支持基于蕴涵的解释。每棵树平均包含 6.6 个节点和 2.7 个蕴涵步骤，包含 1,840 棵树的完整数据集，包括一系列小型和大型多步蕴涵问题。\n• 使用最先进的生成模型基线结果表明可以生成合理树，特别是当提供必要的原始事实作为模型输入时（导致 35% 的树的错误为零）。还提出迹象表明，ENTAILMENTBANK 训练的模型可以推广到其他领域。\n \n四、综述\n\n在 QA 的上下文中，有多种解释/理由的概念，包括显示权威的、有答案的句子（Perez 等人，2019）、段落上的注意力图（Seo 等人，2016）、综合连接问题和答案的短语（Rajani 等人，2019 年），或用于定位答案的句法模式（Ye 等人，2020 年；Hancock 等人，2018 年）。这些方法主要设计用于“查找”问题的答案，以解释在语料库中何处/如何找到答案。\n\n对于需要推理的问题，本文的重点，有时将解释视为导致答案的步骤链（通常是句子）。因为众包这样的链很困难，现有的数据集通常会简化任务，例如，收集支持答案的句子而不是它们如何组合，和/或主要集中在单跳（长度为 2）链上。在这里，推广到需要多步蕴涵树的任务。\n\n\n五、数据集\n\nThe ENTAILMENTBANK Dataset：用户首先填充“解释性工作表”，用少量特定类别（例如，“核心事实”、“基础事实”）标记他们预期将包含在树中的事实。然后，用户从该工作表开始构建蕴涵树-通常从最底部的叶节点开始，从它们中创作中间结论，然后逐步在树的更高层次上工作，直到他们创作出直接回答问题的结论。\n\n \n \n\n1840个随机选择的问题（ARC中的7787个问题）总共包括5881个离散蕴涵步骤。总的来说，大约600（带薪）工作小时用于构建数据集。平均而言，每个蕴涵树包括跨越3.2个蕴涵步骤的7.6个节点，其中每个蕴涵步骤通常涉及3个事实（两片叶子，组合起来得出一个结论）。\nDataset Analysis：确定了6种常见的高级推理类别：替代类型是指需要模型来执行分类、子项或其他形式的链接的蕴涵，这些链接将一个输入句子中的一个实体替换为另一个实体。从规则蕴涵中进行推理需要将指定为一个输入句子的特定规则应用于另一个输入句子。分析表明，大约三分之一（33%）的所有蕴涵需要应用特定领域的规则才能完成。进一步的规范或连接蕴涵需要一个模型将两个输入事实的细节合并到单个输出事实中。不太常见的类型需要从对象的属性推断对象的类、继承对象的属性或确定顺序推理的顺序。总的来说，该分析表明，要成功完成蕴涵库中的蕴涵步骤，需要多种形式的推理。\n \n\n\n六、模型构建\n\n三个task：\n\n \n\nH：假设；Q：问题；A：回答；C 是 WorldTree 语料库加上注释器创建的所有其他科学事实；所需的输出都是有效的蕴涵树 T，近似为黄金蕴涵树 Tgold\n受 ProofWriter 系统中的“All-at-once”序列到序列模型的启发，作者训练了三个基于 T5 的生成模型（每个任务一个），称为 EntailmentWriters。使用 T5 库中的默认超参数（包括优化器）对训练集上的模型进行微调。我们使用最大的 T511B 模型，针对 40k 步（批量大小 8）进行微调，选择开发分数最高的检查点。\n\n七、实验\n\n模型输入是前面描述的三个任务的模型输入，除了插入检索步骤的任务3（语料库 C 太大而无法直接输入到 T5）。\n使用 QA 作为查询从 C 中检索 25 个句子（使用 RoBERTa 训练的相关句子排序器），并将它们输入到模型中。所有情况下的输出都是解释QA 的蕴涵树。\nEvaluation Metrics：......\n\n"},"Chapter4/METGEN论文学习笔记.html":{"url":"Chapter4/METGEN论文学习笔记.html","title":"METGEN论文学习笔记","keywords":"","body":"METGEN: A Module-Based Entailment Tree Generation Framework for Answer Explanation\n\n一、摘要\n学习从知识到预测答案的推理链—>帮助构建可解释的QA问答系统。【方法】用由多个隐含步骤组成的隐含树来解释答案。【现状】目前的工作建议使用端到端生成模型来生成蕴涵树，但生成的树中的步骤不受约束，而且可能不可靠。【方法/创新】本文提出了一个基于模块的蕴涵树生成枚举框架METGEN，它具有“多个模块和一个推理控制器”。给定一个问题和一些支持知识，METGEN可以通过对单独的模块进行单步隐含，用控制器选择推理流，迭代生成隐含树。由于每个模块都被引导去执行一种特定类型的隐含推理，因此由METGEN生成的步骤更加可靠和有效。【结果】在标准基准测试上的实验结果表明，METGEN仅使用9%的参数就可以优于以前的最先进的模型。\n总结：通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。\n\n二、综述\n之前解释QA的相关方法与技术：\n\n在段落上显示一个注意力地图\n给出一个文本证据的片段\n选择支撑答案的句子\n\n多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设【转去看了看多前提蕴涵树的相关论文】\n"},"技术框架/技术框架.html":{"url":"技术框架/技术框架.html","title":"毕设技术框架","keywords":"","body":"技术框架整体图\n \n二、解释\n\n本地领域知识库部分：由于token长度限制问题，所以需要将多个pdf进行拆分成段落（segment），然后利用langChain+FAISS向量库建立向量数据库和文档索引。\n\n用户提问部分：将用户提出的query进行同义词+历史信息扩充，然后选取目前词嵌入效果最佳的相关embedding模型进行词向量建模，将得到的词向量与本地知识库的向量数据库进行匹配检索，将匹配结果进行聚类，扩充得到与该问题相关的更全回答信息，并基于相似度进行排序得到喂给LLM模型的信息。\n\nLLM模型：\n\n\n（1）input：Prompt[用户提问+相关检索信息]\n（2）output：带有标引信息的回答结果\n（3）垂直领域LLM模型微调部分：根据已有的开源微调项目进行改动、参考\n        ①选取某一领域\n        ②继续训练部分：无监督学习\n        ③关键：指令微调部分：构建高质量的领域问答数据集。\n                                        分为两类：针对单篇事实性问题进行总结的问答数据集（bing等ChatPDF工具进行文档提问）\n                                                            更为宽泛、总结性的跨篇章问答数据集（GPT自生成）\n        ④对齐微调：符合用户价值观和说话习惯等（主要借鉴LMFlow项目尝试开展，不是必做项）\n"}}}