# Explaining Answers with Entailment Trees

---

##### 一、摘要

1.**在开放域文本问答的背景下，的目标是通过显示从已知到答案的推理线来解释答案，而不是简单地显示文本证据的片段。**
2.的方法是**以蕴涵树的形式生成解释**，即多前提蕴涵树，从已知的事实，通过中间结论，到感兴趣的假设（即问题+答案）。
3.为了用这种技能训练模型，创建了 **ENTAILMENT BANK** ，这是第一个包含多步蕴涵树的数据集。
4. 给定一个假设（问题+答案），定义了三个越来越难的解释任务：为给定的 QA 对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c) 完整的语料库。
5.研究结果表明，强大的语言模型可以部分解决这些任务，特别是当相关句子包含在输入中时，并且有泛化到其他领域的迹象。这项工作意义重大，因为它提供了一种新型数据集（多步蕴涵）和基线，为社区提供了一条新途径，以产生更丰富、更系统的解释。

----

##### 二、 Introduction

1.今天的解释系统擅长为答案提供一两句话的支持证据（“基本原理”）（DeY oung 等人，2019），但它们很少从什么解释推理链已知答案，即在给出证据的情况下，答案是如何得出的——这项工作的目标。
2.本文方法是以**多步蕴涵树**的形式生成解释，如图 1 所示，由单个多前提文本蕴涵 (TE) 步骤组成，尽管有许多可用的单步蕴涵数据集，但是目前不存在多步蕴涵数据集，
3.因此本文的一个重要贡献是构建了这样一个数据集，称为 **ENTAILMENT BANK**。 ENTAILMENT BANK 包含 1,840 个用于伴随 QA 对的多步蕴涵树，使用专家注释器构建，是同类数据集中的首个。
4.本文还在这个数据集上定义了三个解释任务，即：为给定的 QA 对生成一个有效的蕴涵树，给定（a）所有相关的句子（黄金蕴涵树的叶子），（b）所有相关的和一些干扰语句，或(c) 完整的语料库。

5.**研究重点是生成推理线**，以显示证据如何生成的答案，而不是决定将哪些部分显示给用户。这使能够将两个解释要求，即推导的正确性与效用分开，使能够以更客观的度量评估推导。

##### 三、贡献

为这项任务定义和训练称为 **EntailmentWriters** 生成模型，采用早期技术来生成演绎证明。发现这些模型部分地解决了数据集，并具有泛化到其他领域的迹象。因此，的贡献是：

• 将解释表述为多步骤、多前提的文本蕴涵。
• ENTAILMENT BANK，第一个用于 QA 的多步蕴涵树数据集，支持基于蕴涵的解释。每棵树平均包含 6.6 个节点和 2.7 个蕴涵步骤，包含 1,840 棵树的完整数据集，包括一系列小型和大型多步蕴涵问题。
• 使用最先进的生成模型基线结果表明可以生成合理树，特别是当提供必要的原始事实作为模型输入时（导致 35% 的树的错误为零）。还提出迹象表明，ENTAILMENTBANK 训练的模型可以推广到其他领域。

<img src="pics/Entailment Trees论文学习笔记/image-20230508153902295.png" alt="image-20230508153902295" style="zoom:40%;" /> 

##### 四、综述

1. 在 QA 的上下文中，有多种解释/理由的概念，包括显示权威的、有答案的句子（Perez 等人，2019）、段落上的注意力图（Seo 等人，2016）、综合连接问题和答案的短语（Rajani 等人，2019 年），或用于定位答案的句法模式（Ye 等人，2020 年；Hancock 等人，2018 年）。这些方法主要设计用于“查找”问题的答案，以解释在语料库中何处/如何找到答案。

2. 对于需要推理的问题，本文的重点，有时将解释视为导致答案的步骤链（通常是句子）。因为众包这样的链很困难，现有的数据集通常会简化任务，例如，收集支持答案的句子而不是它们如何组合，和/或主要集中在单跳（长度为 2）链上。在这里，推广到需要多步蕴涵树的任务。

##### 五、数据集

1. The ENTAILMENTBANK Dataset：用户首先填充“解释性工作表”，用少量特定类别（例如，“核心事实”、“基础事实”）标记他们预期将包含在树中的事实。然后，用户从该工作表开始构建蕴涵树-通常从最底部的叶节点开始，从它们中创作中间结论，然后逐步在树的更高层次上工作，直到他们创作出直接回答问题的结论。

<img src="pics/Entailment Trees论文学习笔记/image-20230508155256923.png" alt="image-20230508155256923" style="zoom:40%;" /> 

<img src="pics/Entailment Trees论文学习笔记/image-20230508155323967.png" alt="image-20230508155323967" style="zoom:33%;" /> 

2. 1840个随机选择的问题（ARC中的7787个问题）总共包括5881个离散蕴涵步骤。总的来说，大约600（带薪）工作小时用于构建数据集。平均而言，每个蕴涵树包括跨越3.2个蕴涵步骤的7.6个节点，其中每个蕴涵步骤通常涉及3个事实（两片叶子，组合起来得出一个结论）。
3. Dataset Analysis：确定了6种常见的高级推理类别：替代类型是指需要模型来执行分类、子项或其他形式的链接的蕴涵，这些链接将一个输入句子中的一个实体替换为另一个实体。从规则蕴涵中进行推理需要将指定为一个输入句子的特定规则应用于另一个输入句子。分析表明，大约三分之一（33%）的所有蕴涵需要应用特定领域的规则才能完成。进一步的规范或连接蕴涵需要一个模型将两个输入事实的细节合并到单个输出事实中。不太常见的类型需要从对象的属性推断对象的类、继承对象的属性或确定顺序推理的顺序。总的来说，该分析表明，要成功完成蕴涵库中的蕴涵步骤，需要多种形式的推理。

 <img src="pics/Entailment Trees论文学习笔记/image-20230508172033674.png" alt="image-20230508172033674" style="zoom:33%;" /> 

##### 六、模型构建

1. 三个task：

<img src="pics/Entailment Trees论文学习笔记/image-20230508172153812.png" alt="image-20230508172153812" style="zoom:33%;" /> 

2. H：假设；Q：问题；A：回答；C 是 WorldTree 语料库加上注释器创建的所有其他科学事实；所需的输出都是有效的蕴涵树 T，近似为黄金蕴涵树 Tgold
3. 受 ProofWriter 系统中的“All-at-once”序列到序列模型的启发，作者训练了三个基于 T5 的生成模型（每个任务一个），称为 EntailmentWriters。使用 T5 库中的默认超参数（包括优化器）对训练集上的模型进行微调。我们使用最大的 T511B 模型，针对 40k 步（批量大小 8）进行微调，选择开发分数最高的检查点。

##### 七、实验

1. 模型输入是前面描述的三个任务的模型输入，除了插入检索步骤的任务3（语料库 C 太大而无法直接输入到 T5）。
   使用 QA 作为查询从 C 中检索 25 个句子（使用 RoBERTa 训练的相关句子排序器），并将它们输入到模型中。所有情况下的输出都是解释QA 的蕴涵树。
2. Evaluation Metrics：......

