# 微调范式对比

参考链接：[大模型微调技术：fine-tune、parameter-efficient fine-tune和prompt-tune ](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247616263&idx=1&sn=092a7e80ec9fa8bc87922c443177e97c&chksm=96ebd887a19c519190cc432c28f076b180f83a29d1643c05c0fe98b47c3535838bf97cb5411b&scene=21#wechat_redirect)

```
BERT出现之后，fine-tuning技术也随之流行，即将预训练模型的权重冻结，然后根据具体任务进行微调变得十分有效且被应用在很多场景。随着ChatGPT的火热，parameter-efficient fine-tuning和prompt-tuning技术似乎也有替代传统fine-tuning的趋势，本篇论文将简单描述预训练模型领域这三种微调技术及其差别。
```

#### 一、fine-tuning技术

1. Fine-tuning的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。

2. 经典的fine-tuning方法包括将预训练模型与少量特定任务数据一起继续训练。在这个过程中，预训练模型的权重被更新，以更好地适应任务。所需的fine-tuning量取决于预训练语料库和任务特定语料库之间的相似性。如果两者相似，可能只需要少量的fine-tuning。如果两者不相似，则可能需要更多的fine-tuning。

3. 在NLP中，fine-tuning最著名的例子之一是由OpenAI开发的OpenAI GPT（生成式预训练变压器）模型。GPT模型在大量文本上进行了预训练，然后在各种任务上进行了微调，例如语言建模，问答和摘要。经过微调的模型在这些任务上取得了最先进的性能。

4. ##### 总结：将除了输出层以外的所有权重“冻结”（freeze）。然后随机初始化输出层参数，再以迁移学习的方式训练。仅仅更新全连接输出层，其它层的权重不变。

#### 二、parameter-efficient fine-tuning技术[PEFT]

1. 参数高效的fine-tuning，简称PEFT，旨在在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。它是自然语言处理（NLP）中一组用于将预训练语言模型适应特定任务的方法，其所需参数和计算资源比传统的fine-tuning方法更少。

2. 通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数通过仅训练一小组参数来解决传统微调技术需要大量资源的问题，这些参数可能是现有模型参数的子集或新添加的一组参数。
3. 其中一种PEFT技术称为**蒸馏(distillation)**，它由Hinton等人于2015年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。**【教师-学生】**
4. 另一种技术称为**适配器训练(adapter training)**，它由Houlsby等人于2019年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。
5. 第三种技术称为**渐进收缩(progressive shrinking)**，它由Kaplan等人于2020年引入。这种技术涉及在fine-tuning期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。
6. PEFT综述：Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning

----

#### 三、prompt-tuning技术

1. prompt-tuning是一种更近期的精调预训练语言模型的方法，重点是**调整输入提示（input prompt）而非修改模型参数**。这意味着预训练模型保持不变，只有输入提示被修改以适应下游的任务。通过设计和优化一组提示，可以使预训练模型执行特定任务。

2. prompt-tuning和传统的fine-tuning的主要区别在于预训练模型被修改的程度。**fine-tuning修改模型的权重，而prompt-tuning只修改模型的输入**。因此，prompt-tuning调整比精调的计算成本低，需要的资源和训练时间也更少。此外，prompt-tuning比精调更灵活，因为它允许创建特定任务的提示，可以适应各种任务。

##### 一些值得注意的prompt-tuning技术包括：

1. **Prefix tuning（前缀调整）**：由Li和Liang在论文“Prefix-Tuning: Optimizing Continuous Prompts for Generation”（2021）中提出。前缀调整涉及学习特定任务的连续提示，在推理过程中将其添加到输入之前。通过优化这个连续提示，模型可以适应特定任务而不修改底层模型参数，这节省了计算资源并实现了高效的精调。
2. **P-Tuning**：由Liu等人在论文“P-Tuning: GPT Understands, Learns, and Generates Any Language”（2021）中提出。P-Tuning涉及训练可学习的称为**“提示记号”**的参数，这些参数与输入序列连接。这些提示记号是特定于任务的，在精调过程中进行优化，使得模型可以在保持原始模型参数不变的情况下在新任务上表现良好。

----

总结：当大模型开始涉及更加复杂和现实的问题时候，如果可以出现自动prompt-tuning技术而非手工调整可能是未来很重要的方向。毕竟在文本摘要、代码debug等需要大量的输入来让模型认识问题的场景，**如何有效的将过长的输入prompt给模型是一个很重要的问题**，现在的大模型在长输入方面推理成本很高且有很大限制，因此这种技术也是未来很重要的一个方向！

